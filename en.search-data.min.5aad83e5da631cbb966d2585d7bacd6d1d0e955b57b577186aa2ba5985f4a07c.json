[{"id":0,"href":"/posts/acm/bit-%E5%8C%BA%E9%97%B4%E6%B1%82%E5%92%8C/","title":"多棵树状数组处理区间问题","section":"Acm","content":" 单点修改，区间求和 # 区间求和可以优化为前缀和之差。因此问题转换为如何求前缀和。\n当我们对$a_i$ 做 加x 操作时，只需要在树状数组上add(i, x); 对于一个$j(j \u0026gt;= i)$， 我们执行getSum(j) 时，会求出所有小于等于j位置的修改的总和，因此也就获得了前x项的修改总和。这个问题就这样解决了。\n区间修改，区间求和 # 对于一个区间整体+x的操作，我们的处理方式是add(L, x); 和 add(R+1, -x);,此时getSum(j) 求前缀和getSum(j)时得到的结果正是作用于（影响了）j 位置的总和。换言之，只得到了x对于j位置的贡献，并没有计算x对于一整段的贡献。\n我们单独来看x的贡献，对于前j项和来说，x贡献了(j-i)次，因为每个位置都+x了。此时我们独立考虑+x和-x的影响，因此不需要关注x的真正持续范围，因为考虑-x的时候会反向抵消这部分贡献。\n前x项和可以写成公式：$A_1 + A_2 + A_3 + \\cdots + A_j + (j-i_1)x_1 + (j-i_2)x_2 \u0026hellip;$，这个式子前半部分是A的前缀和，是固定值，可以直接计算的到。对于后一半，我们做简单的合并同类项的处理：$j\\cdot (x_1+x_2 +\u0026hellip;) - (i_1\\cdot x_1 + i_2\\cdot x_2 + \u0026hellip;.) = j\\cdot getSum(j) - (i_1\\cdot x_1 + i_2\\cdot x_2 + \u0026hellip;.)$\n那么对于$(i_1\\cdot x_1 + i_2\\cdot x_2 + \u0026hellip;.)$ 我们可以用另外一个树状数组来维护出来: add(i * x);\n总结 # 此类问题的解决方法非常固定。\n从本质出发，计算每一个数据在总结果中的贡献次数，写出一个极其本质的表达式。 将式子中固定的值部分忽略不考虑，对于剩下的部分，将查询变量j和其他变量尽量剥离，找出一些与查询项无关的部分。 这类与查询j无关的部分，都可以使用各种数据结构来维护。 "},{"id":1,"href":"/posts/acm/atcoder/abc-256-f/","title":"ABC-256-F 题解","section":"Atcoder","content":" 题意 # 已知A序列为一个整数序列，B序列是A的前缀和序列，C序列是B的前缀和序列，D序列是C的前缀和序列。\n有两种操作：\n单点修改A序列。 单点查询D序列。 分析 # 我们可以计算每个A对\n对B的后缀序列每个都贡献$x$。 对C的后缀序列，每个位置j都贡献$(j-i+1)x$ 对D的后缀序列，每个位置j都贡献$\\sum_{1}^{j-i+1} x$ 因此可以得到表达式：\n$$\nD_i = $$\n"},{"id":2,"href":"/posts/acm/atcoder/abc-255_e/","title":"Lucky Number 题解","section":"Atcoder","content":" 题意 # Lucky Number\n对于序列A，S序列是A序列的相邻两项之和的序列: $S_i = A_i + A_{i+1}$, S序列已知\n给定一个X序列，请你确定一个A序列，使得X序列中的数字出现的次数仅可能的多，输出最多的次数。\n分析 # 我们可以很容易的写出A序列：\n$$ \\begin{aligned} A_1 \u0026amp;= A_1 \\\\ A_2 \u0026amp;= S_1 - A_1 \\\\ A_3 \u0026amp;= S_2 - A_2 = S_2 - S_1 + A_1 \\\\ A_4 \u0026amp;= S_3 - A_3 = S_3 - S_2 + S_1 - A_1 \\\\ A_5 \u0026amp;= S_4 - A_4 = S_4 - S_3 + S_2 - S_1 + A_1 \\\\ \\end{aligned} $$\n引入一个B序列，我们可以将上面的式子简写为:\n$$ \\begin{aligned} B_1 \u0026amp;= 0 \\\\ A_1 \u0026amp;= B_1 + A_1 \\\\ A_2 \u0026amp;= B_2 - A_1 \\\\ A_3 \u0026amp;= B_3 + A_1 \\\\ A_4 \u0026amp;= B_4 - A_1 \\\\ A_5 \u0026amp;= B_5 + A_1 \\\\ \\end{aligned} $$\n可知B序列是已知序列，可由S序列计算得出。对于一个确定的$A_1$, 则序列A是确定的。\n若$A_i = X_j$ 则: $A_i = B_{i} + (-1)^{i+1}A_1 = X_j$, 可知$A_1 = (-1)^{i+1}(X_j - B_i)$。\n由此可知，每一对$A_i = X_j$都对应了一个$A_1$, 因此只需要统计哪一种$A_1$出现的次数最多就可以了。\n"},{"id":3,"href":"/posts/rocksdb/skip-list/","title":"skip list原理与实现","section":"Rocks Db","content":" 原理 # 跳表作为一个没有被正规教材收录的数据结构，在工业场景下的用途非常广泛，常常用来媲美红黑树等一系列平衡二叉查找树。其核心的原理是通过多级索引层层二分构建一个支持二分查找的有序链表。\n有序链表无法进行二分查找的原因在于无法随机访问，一个完美的跳表应该类似一个平衡二叉树的模样。\n我们通过间隔一个选一个点复制出来，构成一个一级索引，针对一级索引链表，再通过间隔一个的方式构建二级索引，以此类推，最多$$log_2 n$$层就可以只剩两个点，这就是一个极其类似平衡二叉查找树的结构。查询的复杂度必然也是$$$log_2 n$$$。\n但是上述的结构在insert和delete的时候动态调整的代价非常大，甚至无法通过log级别的复杂度完成。因此在实现的时候，并没有按照这个完美的结构来实现。而是采用了一个随机化抽点的方式来构建索引。事实验证的效率是令人满意的。\n顺带提一下空间复杂度，虽然复制了一些点，但是依然是$O(n)$的复杂度，计算方式非常简单。并且索引部分并不需要记录完整的数据，只需要记录用于比较大小的score即可，因此索引与数据节点之间的空间比起来微不足道了。\n实现原理 # 我们定义最底层的链表是原始的有序链表，向上一层为一级索引，再上一层为二级索引，以此类推。\n我们基于完美形态的跳表可以发现，一级索引的点数为$n$， 二级索引点数为$n/2$, 三级索引的点数为$n/4$, 换个角度来看，一个点出现在一级索引中的概率是1， 出现在二级索引中的概率是1/2， 出现在三级索引中的概率是1/4。因此在插入数据的时候，我们只要按照概率分布，随机出这个点需要出现在哪几级索引中，然后按照索引层去查找和插入即可。\n如何随机出一个点需要被插入的索引层？直接看代码：\n// 该 randomLevel 方法会随机生成 1~MAX_LEVEL 之间的数，且 ： // 1/2 的概率返回 1 // 1/4 的概率返回 2 // 1/8 的概率返回 3 以此类推 private int randomLevel() { int level = 1; // 当 level \u0026lt; MAX_LEVEL，且随机数小于设定的晋升概率时，level + 1 while (Math.random() \u0026lt; 0.5 \u0026amp;\u0026amp; level \u0026lt; MAX_LEVEL) level += 1; return level; } 代码的逻辑非常简单：\n第一次循环有1/2的概率退出，则level=1 的概率是1/2； 第二次循环有1/2的概率退出，则level=2 的概率是1/2 * 1/2 = 1/4； \u0026hellip; 针对返回的结果，有一点需要说明：\n当函数返回1的时候，我们只需要添加原始节点即可； 当函数返回2的时候，我们需要将其添加到一级索引中，但是此刻的概率是1/4；与我们前文讲的1/2概率作为一级索引不符。 上述问题是一个不容易发现的隐藏bug，如果不是这样实现或许会导致跳表的体积膨大，索引膨胀一倍。\n原因很简单，因为如果当我们返回1的时候，我们要构建一级索引，当我们返回2的时候，我们构建二级索引的同时也会新增一级索引节点，因此导致当返回值\u0026gt;=1 的时候都会出现一级索引点。则一级索引的实际概率是1， 而不是1/2.\n那么按照上述正确的方式来处理，只有当level \u0026gt; 1 的时候才会产生一级索引点，而这个概率是1/2， 满足设计需求。当level \u0026gt; 2 的时候会产生二级索引点，其概率是 1/2 - 1/4 = 1/4。\n由此，跳表的全部实现逻辑就结束了。\n性能对比 # 百万次随机写入与std::map对比， 速度降低为map的1/3， 但是空间占用是map的3倍\nmap: 1100 ms skipList: 380 ms "},{"id":4,"href":"/posts/python/python-type/","title":"python type","section":"Python","content":" type 的普通用法 # type一般的用法使用来获取一个变量的类型，但是，type并不适合用来获取一个变量的类型。\n想获取一个变量的类型，有其实类的实际类型要用isinstance\nisinstance # class A: pass class B(A): pass isinstance(A(), A) # returns True type(A()) == A # returns True isinstance(B(), A) # returns True type(B()) == A # returns False a = 111 isinstance(a, int) # True python中有一种old-style class 这些类用type直接取得到的都是instance， 也就是所有的类实例都是一样的。在后来的new-style class中，得到的会有区别但是，依然不能很好的判断子类的问题。\ntype 创建一个类型 # 这个用法我看到的时候反正是一脸懵逼，莫非是用来动态创建类用的？\n用法：\n#type(classname,(parents,...),{attribute}) #第一个参数classname是类名,第二个是一个父类元组，没有可填空元组，第三个参数是类属性字典。 #!/usr/bin/env python # coding=utf-8 class XA(object): a = 1 XB = type(\u0026#39;XC\u0026#39;, (object, ), dict(a=3)) Xa = XA() Xb = XB() # Xc = XC() # syntax error， there is no such a class named XC， only XB as a llegal class name. print(XA) print(XB) print(XB) print(Xa.a) print(Xb.a) #print(Xc.a) 总之这样可以动态的创建一个类。\n比较秀一点的用法：\nMonitorThread = type(\u0026#34;MonitorThread\u0026#34;, (BaseThread, ), dict(__init__=init_monitor_thread, working=work_monitor)) 用散的函数组装的类，还有这种。。。\npython早晚要完，写代码一时爽，维护火葬场。\n"},{"id":5,"href":"/posts/python/python-multithreaded/","title":"python 多线程和异步","section":"Python","content":"python 的多线程还有协程这种东西。\n线程池 # 关于多线程的实现，各种语言基本上都是一样的。\n一种是集成一个线程的基类，然后重写一个run()函数。这类写法比较好理解，非常直观就是创建一个线程交给操作系统。\n因为每个线程都有确定的程序起点、执行顺序、程序终点。因此这个函数就是起点。\n另外一种就略有区别，Java中就是实现一个接口，在python中没有接口就是直接传个函数去构造出一个线程。Java中的接口其实很不好理解，因为这个接口只是实现了一个逻辑在run()函数里， 实例化这个类的时候并没有创建这个线程，还要单独用这个类的实例去再实例化一个线程。然后在start这个线程。\n无论是那一种，在底层都是一样的。就是把一段逻辑写进一个函数中，作为一个起点用来生成一个线程资源。而这个工作，都是基类Thread来实现的。\n因此只要给Thread类一个程序入口就可以构造出一个线程了。\n线程的启动和设定都很好解决。有一个问题就是创建线程也是要话费时间的。因此就有线程池的思想。\n线程池的优点:\n避免线程的创建和销毁带来的性能开销。 避免大量的线程间因互相抢占系统资源导致的阻塞现象。 能够对线程进行简单的管理并提供定时执行、间隔执行等功能。 两个单词区分一下：async（异步）、 sync（同步）\n"},{"id":6,"href":"/posts/others/cuda/","title":"cuda","section":"Others","content":"任何事情都不是突然出现的，曾经有一段时间，关注了很多公众号，突然就发现有些框架和库突然就出现了并就非常热了。 但是后来渐渐发现，其实这个东西应该很早就出现了，只是那个时候还没有公众号做推力，只是在小范围内知名。 但是这突然的大热让我非常的惶恐，深深的感觉自己跟不上时代的脚步，当然实际上，我也确实没跟上。\nNVIDIA 在2006年就推出了CUDA，而我知道这个东西，是在2017年。 用于使用GPU进行并行计算。使得普通搭载Geforce显卡的笔记本也具有大规模并行处理的能力。 传统的并行计算基于大规模集群的CPU进行，成本高，而使用GPU进行并行计算的成本就小很多。 CUDA的开发并不难，其提供了一个编译器，和一些C语言的库。我们使用C语言结合库，编写代码，然后使用nvcc进行编译，得到可执行文件，然后运行就可以了。 封装了对GPU的操作。\nUbuntu安装Nvidia # 主要的安装须知都在这个文档里说明了：Nvidia Cuda Installation for Linux\n前期准备，下载cuda Toolkit\nDisabling Nouveau\nCreate a file at /etc/modprobe.d/blacklist-nouveau.conf with the following contents: blacklist nouveau options nouveau modeset=0 Regenerate the kernel initramfs: $ sudo update-initramfs -u 重启，进入命令终端启动cuda。 直接Alt + \u0026lt;F3\u0026gt;就进入了。然后找到cuda开始运行。按照提示一点一点装就可以了.\n重启。\n"},{"id":7,"href":"/posts/self/fight/","title":"创业者","section":"Self","content":"其实这一次算是第一次正式的作为一个创业者，在创业。\n我这个人 # 我的性格里埋藏着创业者基因。我终究会走上创业的路。 这是很久以前，当我还是个中学生的时候就有了的心理准备。当我开始思考以后要做什么工作的时候，我总是看不到我在什么岗位上会有比较好的表现。我对自己的认知好像一直都还算准确，一般都会有点超出自己的实际能力吗，不过也都是努力一下或者说，运气好一点就达成的高度。 因此我常常会从一个独立的从业者角度去思考问题，因为找不到自己的位置。并且对于家里面的找个稳定工作的想法也有些本能的排斥，所以我其实一直都准备好了去创业。\n刚上大学没多久，我在社团中的经历让我发现自己找不到一个合适的位置可能还有一个原因，就是我的实际能力在什么位置都有很多剩余。这些剩余会让我在考虑问题的时候超出我的岗位范围。一旦开始思考这些更大局一些的东西，就会感觉目前拥有的权利无法实践自己的想法，因此也不适合待在一个太小的位置上。 对市场经济学的了解、对心理学的把握和直觉、对基本规律的探察，等等这些，让我会思考很多，有思考，有结论，就会有决定，所以我应该是做决定的一个角色，否则会活着很压抑。\n我不认为创业一定要搞个几百亿的上市公司才算是创业。我理解的创业是开辟战场。相比较进入一个竞争激烈的行业并在其中立足，我更倾向于去开辟一个新的战场。或许很多资本都想要新的战场，但是没有这么多机会。 我对自己的定位差不多是个破局者，因为思维具有一点点创造性，性格中有冒险精神，勇气和风险把握，还有点固执，追求完美。最重要的是，无所牵挂。\n作为一个程序员，创业其实会简单点，因为自己可以做开发，这是笔不小的开销，省下了。 所以在学习计算机专业的过程中，我努力把自己打造成一个单兵作战能力很强的特种兵。学习使用各种装备，以期在需要的时候用最直接的方式解决需求。\n上帝送给创业者的一脚飞踹 # 创业的念头真正形成是今年的4月份，这种感觉越来越强烈，但是仅仅是感觉到自己要创业了，但是并不知道要做些什么，所以有一点点的焦虑，想尽快的做完手头的毕业设计然后来思考这件重大的事情。 等到5月份的时候，一切之前的铺垫都将创业的方向指向了一个我最熟知的领域。我好像也暂时想不出什么其他的东西。那就朝这个方向去吧。\n当方向确定以后，还是不知道具体怎么做，从哪开始，做什么？ 整天处于迷茫和乐观的辗转状态。这样又过了半个月，逐渐的放下了毕设的包袱，心情轻松很多，也更乐观了。仔细的分析了一下自己有什么，要付出什么。 结果很感人，就是自己什么都没有。除了不多的时间、开发能力、竞赛经验和知识。 足够了，这些东西不用，放着也是放着，用了，就算什么都没得到也不亏，至少自己的开发经验又得到了提升。\n做好了心理准备，接下来就是找个东西开始干吧。 市场在哪？从哪下手？什么周期？\n摆在我面前的选择，其实还是很少，甚至是没有选择，根本就没啥路能走。 思考了许久，掂量着徐州这个市场能不能受的了我的新模式。掂量来掂量去，也不确定。 时间就这么往前走，我选定了徐州这个市场，但是我不懂怎么打开它，我甚至还没有非常了解这个市场。我给自己定了个时间，6.4日，徐州邀请赛过后要解决这个问题。\n我直到比赛结束了，我还是不知道我接下来这一步该往哪里下脚。我只知道我明天就得有答案，明天得去一中一趟。 怎么有答案？去一中做什么？找谁？怎么说？ 不知道。\n那个傍晚和晚上，我站在徐州市中心，看着这个我生活了10几年的城市，太陌生了。 曾经我做为这个城市的一部分，在内部游走。现在我要站在这个城市的面前，打开他。忽然感觉这个城市太大了，根本无从下手。\n我跟一些人讲了自己要创业，但是具体的创业方案，也都是含糊其辞，往往都是“等到。。。时候就知道了。”这种答案，我也跟这些人说我明天就要解决一些问题，要确定下来了。 或许就是这些dead line起的心理作用，让我没有像以前一样退缩。虽然我都不知道今晚要住哪，下一步该往东还是该往西走。曾经只敢打打嘴炮，真到要硬着头皮往前走的时候基本都会退堂鼓震天响。\n找了个市中心比较便宜的宾馆，住下了。 下午比赛身体很不舒服，没睡好，被晒了一小时，特别困，已经无法思考了。肾结石也在今天突然痛起来。 勉强睡了半小时，受不了了。得去医院。 把自己收拾一下，不带多余的物品，出门，医院不远，穿过广场，对面就是。询问前台、挂号、做B超。。。突然特别的有礼貌，觉得自己跟这座城市有一点点不一样了。不像那么豪放了，倒是有很多苏州的从容和优雅。 从医院出来，大概也没那么疼了。华灯初上，徐州这座城市的节奏还是很慢的，毕竟故乡，触景生情。 大概是肾结石闹的，把精力转移了，没有过多的担心明天的事情，干脆鸵鸟心态，不管了，先逛逛以前常去的地方，真的很感慨。 把病历和检查单什么的都撕巴撕巴扔垃圾桶，手插裤兜走走吧。走着走着，当年高中的感觉又有点回来了，孤独、傲气、不屑，悲怆的英雄主义。\n走了一圈，回到了宾馆，睡吧。努力了半天，十点多，还没睡着。 算了，刚好楼下KTV，唱歌去吧。 开了个房间，专心的唱歌了。\n3点多，终于困意来了。睡到了10点。\n醒过来的时候，才是真的崩溃。 这次是真的没法躲了，说这明天，明天已经到了，而且都10点了，上午基本做不了什么了，如果不赶快安排，下午也做不了什么了。 硬是在床上坐了1个小时。 要不算了，回苏州吧，徐州就这样，什么城市，什么市场，自己心理没点B数吗。。 不行，啥都是自己分析的，没有实地接触过，不能这么搞。\n最后还是逼了自己一把，给高中班主任发消息，“老师，下午去学校找你。”\n只要没了后路，剩下的就好办了。准备去吧！ 想了1个小时，也没斟酌出该怎么开口自己创业的事情，怎么打听怎么问。都快走到学校门口了，才想起来两手空空啊。 路边买了两个最大的西瓜，拎着上五楼，手指差点都断了。\n来都来了，不知道怎么开口就不开吧，先叙叙旧。三心二意，有的没的。\n有的时候，就是运气好。同办公室居然是信息学老师。剩下的事情，就顺理成章了。\n1个小时，完全碰运气的一个小时，谈成了。\n创业者的兴奋剂 # 那个时候我还不能理解，为什么总说：“创业者都是幸福的”。 这句话是到今天我才刚刚能理解。 今天晚上，收到消息，报名不理想，也就意味着，今年的规模很小，基本不赚钱。突然一下我感觉我的兴奋剂就断了，一下子跌出了之前一个多月的高昂的士气。\n过去的这一个多月，我一个人，前端、后端、数据库、判题核心。夜以继日，根本不累好吧。什么是饿？什么是休息？不存在的。 我一天能在键盘上写13个小时代码，就是这么疯狂。 我系统的整理了react、redux、router、reduxApi这些前端的库，又搞了restful的jersey，然后是redis数据库。在此之前，我从未用其中任何一个写过完整的项目。从前到后，js、java、shell、node、redis。。。 这一个月，耗尽了我三年的工程知识，用尽了我在阿里学来的功夫，又自己打通了多少的小体系。我三年都在准备，结果三年的准备没抵过这一个月的成长。\n创业者都是幸福的，你完全没有痛苦，那个希望给你夜以继日，给你不知疲倦，连调整状态都不需要，就是这么强劲。\n创业者的乐趣 # 今晚听说不太理想，虽然短暂的跌出了兴奋状态，但是需要调整一下心态和战略，重新加入战局，继续战斗。 创业不是一锤子买卖，就是这样不断的把握市场，生生的撬开市场的脑袋。\n创业者的乐趣，勇敢者的福利。\n"},{"id":8,"href":"/posts/others/shadowsocks/","title":"shadowsocks 搭建","section":"Others","content":"正常的上网需要三个部分。\nserver local SwitchOmega shadowsocks server # 租一个境外的服务器vps，然后搭建如下：\nsudo apt install git python python-pip pyton3 python3-pip pip install git+https://github.com/shadowsocks/shadowsocks.git@master # 编辑配置文件： # sudo vim /etc/shadowsocks.json { \u0026#34;server\u0026#34;: \u0026#34;149.28.194.217\u0026#34;, # 服务器IP \u0026#34;server_port\u0026#34;: 8964, # 服务器上的服务端口 \u0026#34;local_address\u0026#34;: \u0026#34;127.0.0.1\u0026#34;, # 本地地址 \u0026#34;local_port\u0026#34;: 1080, # 本地需要代理的使用的端口 \u0026#34;password\u0026#34;: \u0026#34;www1964878036\u0026#34;, # 密码 \u0026#34;timeout\u0026#34;: 300, # 超时时间 \u0026#34;method\u0026#34;: \u0026#34;aes-256-cfb\u0026#34; # 加密方法： aes-256-cfb, 还有一种比较快的：salsa20 } # 直接启动： ssserver -c /etc/shadowsocks.json # 后台运行： ssserver -c /etc/shadowsocks.json -d start # 停止服务 ssserver -c /etc/shadowsocks.json -d stop # 添加开机启动 sudo vim /etc/rc.local ssserver -c /etc/shadowsocks.json -d start shadowsocks local # 同样的安装过程，启动略有不同 安装过程同上\n启动如下：\nsslocal -s \u0026lt;SERVER IP\u0026gt; -p \u0026lt;SERVER PORT\u0026gt; -b \u0026lt;LOCALHOST IP\u0026gt; -l \u0026lt;LOCAL PORT\u0026gt; -k \u0026lt;PASSWORD\u0026gt; -m aes-256-cfb -d start 浏览器Chrome # 去应用商店找SwitchOmega 插件，然后选项：\nproxy 默认: 代理协议： socks5 代理服务器：localhost 代理端口： 上面的LOCAL PORT 应用，然后选择auto switch 每个页面中有黄色的东西的数字提示的时候，点开插件，点开黄色内容，然后自动添加规则即可。\n"},{"id":9,"href":"/posts/self/self-2/","title":"再出发","section":"Self","content":" 永远都不要太乐观，也别放弃\n最近一段时间作为一个完整的开发工程师来做一个项目，一方便希望能经过一个完整的项目的锻炼把自己的工程底子建立一下，总不能一直飘在算法上，还是要掌握程序员的最低生存本钱的。\n这一次的工程算是一个比较熟悉的，依然是Online Judge，只是这次不再是以一个极客的思维来对待，而是以一个解决问题的工程师的身份。\n曾经用极客的思维去考虑这些部分，心里想的是怎么造出更好的轮子。在这个过程中其实需要学习很多底层的东西，尤其是对于Judge核心的设计和实现是要很多关于操作系统的交互。\n但是到最后也没能自己搞出来什么比较好的东西，只能说是搞了一些还不错的玩具出来了。同时对底层的一些机制有了个粗浅的理解。\n我本质是非常喜欢打通基本的原理的，有些东西没有搞懂总是不太想去动手，怕自己走歪了路，搞得不专业了。这样的追求是我的喜好，并不能作为一个常态存在，因为毕竟学无止境，更多的时候应该是做一个工程师存在。工程师是要 能够非常高效且优质的组织资源去解决问题的，而不是纠结在底层的原理如何如何。当然越是经验丰富、知识扎实的工程师的组织能力越强。\n这次我的主要尝试选择了两个我比较看好的，也处于中间状态的技术：\n前端： react、redux、node 后端： jerey、tomcat、redis、mysql、mybatis 前后端完全分离的架构 这样的技术选择其实是面有点大的，基本涵盖了整个前后端，因此这个项目的周期中会遇到许许多多的实际问题。 主要的会表现在：\n前端 # react体系的架构 项目结构的设计 UI操作 浏览器相关问题 异步请求 这其中前期已经基本能用起来的react体系，算是已经过了一关，后面的浏览器相关的异步请求让我感觉有点头大。 一方面用的不是传统的ajax，是新兴的fetch。在使用fetch的时候又使用了redux-api的库，这个库国内很少人使用，基本没有中文的文档也没有什么人踩坑的经验，所以在理解和使用的时候都很慢。 不过这个过程中也让我学会了怎么去接触一个新的库，其实看文档是一方面，更快速的方法是搭建起来，不断的输出一些东西，这些变量是什么，什么结构的，会比文档直观很多。这个也是在后期的理解的时候才想起来，所以导致前面的搞的还是很痛苦的。\n但是现在面临着一些问题，搞得我多线作战很是迷茫。\n问题是这样 ：\nfetch原生的操作会让浏览器自动的补全content-type， 但是不知道为什么，使用redux-api库的时候就无法补全这个项，导致一些请求的请求头有问题，需要手动编写。尤其是在上传文件上。 其次后台选取的java强类型语言，对请求的type要求非常严格，如果使用的是浏览器自动生成的type，可能会不匹配。同时后台也可以使用更原始的方式，就是直接接收context的内容，得到一个request自己再操作，其实这是以前的javaweb的操作方式。 现在就面临了一个选择的问题，到底是后端做出让步还是前端做出让步？ 虽然都是我在写，但是面临这样结构改动还是很纠结。\n~~ 出去吃了一顿饭。顿悟\n转变思维 # 不存在能解决一切问题的框架，所以不能一味的寻求框架解决方案。完美主义的人会比较痛苦。\n因为没有什么框架能解决你的所有问题，也不是什么问题都有正解的，所以要站的高才能获得好的设计。一定要站的足够高，如果不能高到技术之上，就高到需求之上，高到架构之上，才能在设计出合理的架构。\n抽出框架最优越的特性，用来实现一些需求，其他并不适合用这种框架来解决的问题就不要再死守在框架上了。\n问题迎刃而解。\n有的时候就是要跟自己多讲讲道理，就明白了。可能这就是分裂的好处吧。不是一个人在战斗。\n"},{"id":10,"href":"/posts/web/apache2/","title":"apache2 配置多端口服务","section":"Web","content":" 多端口多服务配置 # 个人服务器和一些低访问量的服务，使用apache2比较方便。 安装完以后打开默认的页面会看到有个介绍：\n/etc/apache2/ |-- apache2.conf | `-- ports.conf |-- mods-enabled | |-- *.load | `-- *.conf |-- conf-enabled | `-- *.conf |-- sites-enabled | `-- *.conf 这就是apache2的基本配置文件\n1. apache.conf # 这个文件基本不用动，是apache的总配置文件。我只修改一项：\n\u0026lt;Directory /var/www/\u0026gt; Options Indexes FollowSymLinks AllowOverride all # default is None, change to all. Require all granted \u0026lt;/Directory\u0026gt; 2. ports.conf # 这个文件用来添加监听的端口：\n# If you just change the port or add more ports here, you will likely also # have to change the VirtualHost statement in # /etc/apache2/sites-enabled/000-default.conf Listen 80 Listen 8088 Listen 4321 在这里添加了端口，还需要为每个端口配置各自的配置文件。\n3. sites-avaliable # 这个文件夹下是一些端口的配置文件。其中：\n000-default.conf 是默认访问的端口，如果更改其中的内容就更改了默认访问的内容：\n\u0026lt;VirtualHost *:80\u0026gt; # The ServerName directive sets the request scheme, hostname and port that # the server uses to identify itself. This is used when creating # redirection URLs. In the context of virtual hosts, the ServerName # specifies what hostname must appear in the request\u0026#39;s Host: header to # match this virtual host. For the default virtual host (this file) this # value is not decisive as it is used as a last resort host regardless. # However, you must set it for any further virtual host explicitly. #ServerName www.example.com ServerAdmin webmaster@localhost DocumentRoot /var/www/Paladnix.github.io # Available loglevels: trace8, ..., trace1, debug, info, notice, warn, # error, crit, alert, emerg. # It is also possible to configure the loglevel for particular # modules, e.g. #LogLevel info ssl:warn ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined # For most configuration files from conf-available/, which are # enabled or disabled at a global level, it is possible to # include a line for only one particular virtual host. For example the # following line enables the CGI configuration for this host only # after it has been globally disabled with \u0026#34;a2disconf\u0026#34;. #Include conf-available/serve-cgi-bin.conf \u0026lt;/VirtualHost\u0026gt; 目前配置的是80端口，对应的文件目录是: /var/www/Paladnix.github.io\n对于之前添加的端口，我们要添加一个配置文件，文件名： 端口.conf, 非必须。\n8088.conf:\n\u0026lt;VirtualHost *:8088\u0026gt; ServerAdmin webmaster@localhost DocumentRoot /var/www/html/ ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; 4 sites-enabled # 所有在avaliable中的配置文件，如果没有在enabled中有连接，也都是不可访问的。\n所以要开放某个端口，最后做一步：\ncd sites-enabled ln -s ../sites-avalibale/8088.conf ./8088.conf 5. 重启apache服务 # sudo service apache2 restart "},{"id":11,"href":"/posts/others/ngrok/","title":"ngrok服务端与客户端","section":"Others","content":" 自己搭建Ngrok服务器 # 使用平台：Ali云 Ubuntu 16.04 Go编译器版本： 1.9.1 依赖： gcc、cmake、build-essential、git 1. Ubuntu安装Go编译器 # wget https://dl.google.com/go/go1.9.7.linux-amd64.tar.gz tar -zxvf go1.9.7.linux-amd64.tar.gz mv go/ /usr/local/ # vim /etc/profile export GOROOT=/usr/local/go export GOPATH=$HOME/go export PATH=$PATH:$GOROOT/bin:$GOPATH/bin # save \u0026amp; exit vim source /etc/profile go version # 显示Go的版本即安装成功 2. 安装其他依赖 # sudo apt install -y git gcc cmake build-essential screen 3. 下载ngrok源码并编译 # git clone https://github.com/inconshreveable/ngrok.git ngrok cd ngrok # 生成ssl自签名证书， 需要被编译进最终可执行文件中 NGROK_DOMAIN=\u0026#34;tunnel.paladnix.top\u0026#34; # 注意域名换成你自己的 openssl genrsa -out base.key 2048 openssl req -new -x509 -nodes -key base.key -days 10000 -subj \u0026#34;/CN=$NGROK_DOMAIN\u0026#34; -out base.pem openssl genrsa -out server.key 2048 openssl req -new -key server.key -subj \u0026#34;/CN=$NGROK_DOMAIN\u0026#34; -out server.csr openssl x509 -req -in server.csr -CA base.pem -CAkey base.key -CAcreateserial -days 10000 -out server.crt # 将生成的证书文件拷贝到指定位置，替代默认证书 cp base.pem assets/client/tls/ngrokroot.crt cp server.crt assets/server/tls/snakeoil.crt cp server.key assets/server/tls/snakeoil.key # compile # 可以交叉编译客户端和服务端 # 可以编译出Linux、Mac、Windows三个平台上的可执行文件 # 如果是当前平台运行的直接： make release-server release-client # 如果客户端需要在不同的平台 # Mac GOOS=darwin GOARCH=amd64 make release-client # Linux GOOS=linux GOARCH=amd64 make release-client # arm GOOS=linux GOARCH=arm make release-client # Windows GOOS=windows GOARCH=amd64 make release-client # 编译完成后，在./bin目录下出现:ngrok(client)、ngrokd(server) 4. Server端运行 # # 直接执行命令 ./ngrokd -domain=\u0026#34;之前生成的证书中的域名或IP\u0026#34; -httpAddr=\u0026#34;:8081\u0026#34; -httpsAddr=\u0026#34;:8082\u0026#34; # 执行成功后会监听4443端口和client进行通讯 一般会开成后台运行，使用screen\nscreen -S ngrok-keeper ./ngrokd -domain=\u0026#34;之前生成的证书中的域名或IP\u0026#34; -httpAddr=\u0026#34;:8081\u0026#34; -httpsAddr=\u0026#34;:8082\u0026#34; # Ctrl + A + D 离开当前screen # screen -r 回到之前离开的screen 5. Client端运行 # 将对应平台的可执行文件下载下来，这里注意，自签名的证书是编译进可执行文件中的，因此要更换域名的时候要重新编译。\n先创建一个配置文件\n# vim ngrok.conf server_addr: \u0026#34;YOUR_DOMAIN/IP\u0026#34; trust_host_root_certs: false # save \u0026amp; exit vim # 将本机的TCP协议22端口暴露出去，用于ssh登录和scp ./ngrok -config=ngrok.conf -proto=tcp 22 # 将本机的http协议8080端口暴露出去， 用于访问本机网站 ./ngrok -config=ngrok.conf -proto=http 8080 执行成功以后会看到下面的信息：\nngrok (Ctrl+C to quit) Tunnel Status online Version 1.7/1.7 Forwarding tcp://tunnel.paladnix.com:35291-\u0026gt; 127.0.0.1:22 Web Interface 127.0.0.1:4040 # Conn 0 Avg Conn Time 0.00ms 接下来你就认为tunnel.paladnix.top:35291 就是你的内网主机就可以了。\nSSH \u0026amp; SCP 登录 # # 任何其他电脑 ssh -p 35291 paladnix@tunnel.paladnix.top # 其中用户名是你内网主机上的用户，密码是内网主机对应的密码 # 注意是小写的`-p` scp -P 35291 paladnix@tunnel.paladnix.top:/home/paladnix/a.cpp ./ # 注意是大写的`-P` 接下来就可以各种骚了。 ngrok是以tcp协议做基础的，所以理论上可以有很多用法。有待开发。\nngrok 配置文件 # ngrok开源的1.x 的版本默认的配置文件是：$HOME/.ngrok, 这里的HOME不是PATH中的HOME是机器指定的HOME，一般就是用户目录。\n# vim ~/.ngrok server_addr: \u0026#34;tunnel.paladnix.top:4443\u0026#34; trust_host_root_certs: false tunnels: ssh: remote_port: 54321 # 指定远程端口是54321， 避免每次都是随机端口 proto: tcp: 22 http: proto: http: 3000 # 启动方式，可以同时启动，也可以单独启动 ngrok start ssh http 补充 # 客户端机器需要安装ssh—server，开启sshd服务\nsudo apt install -y openssh-server ps -e | ack sshd # 查看是否有启动服务 # 如果没有启动就手动启动 sudo service ssh start ！解决断链接的问题 # 在使用的过程中总是频繁的断开连接，这个很影响游戏体验，主要就是ssh保持长连接的问题。 解决的办法也很简单\n1. 配置客户端的sshd # # sudo vim /etc/ssh/sshd_config # 添加下面代码在最后 ClientAliveInterval 10 ClientAliveCountMax 5 # 由于断开频繁，因此这里我的时间间隔很小只有10s 顺带配置客户端的ssh # 非必须\n# sudo vim /etc/ssh/ssh_config # 在末尾添加 TCPKeepAlive yes ServerAliveInteval 30 "},{"id":12,"href":"/posts/bash/bash/","title":"编写Bash脚本","section":"Bash","content":"作为一个Linux用户，不会自己写Bash脚本，简直太讽刺了，跟windows用户有什么区别，用鼠标点一点。 使用Bash脚本来解放生产力非常重要。不要做重复性的无意义的劳动。\nBash 脚本头（shebang） # 这个东西汉语里叫\u0026quot;蛇棒\u0026quot;，难听。 以#! 开头的，在没有指定解释器的情况下，使用后面路径的解释器运行。\n常用的bash命令解释器： #! /bin/bash\nCommand arguments # Variables About Example $# The number of arguments. while [[ $# -gt 0 ]] do \u0026hellip; done $1 The first argument. echo \u0026ldquo;$1\u0026rdquo;; KEY=\u0026quot;$1\u0026quot; $@ All arguments as a list. for i in \u0026ldquo;$@\u0026rdquo; shift Past one string of commands that splited by space. shift # one line "},{"id":13,"href":"/posts/others/tensorflow/","title":"tensorflow","section":"Others","content":" 引言 # Tensorflow究其本质还是一个编程框架，只是这个框架主要面向机器学习和深度学习领域。我们应该还是要使用学习框架的方法来学习他。\n很多时候我们要先分清楚问题的主要矛盾是什么。 在很久以前，我学习视频剪辑。那个时候我对于视频剪辑一窍不通，好不容易安装上pr又要开始漫长的学习怎么使用。 我看了很多的视频和博客，教我如何使用这个软件，面对错综复杂的按钮和组合操作，我不知道什么东西在哪，有什么作用。当我明白了什么工具在什么位置的时候，我发现我依然不会做视频。 后来，我想到了，我从来就不懂如何剪辑视频，而不是不会使用这个软件。 如果我清楚的明白调整alpha通道会产生什么效果等一系列参数的作用，我自然就会明白的当前需要做什么，需要改变什么值，去找对应的按钮，而找对应的按钮只要很简单的搜索一下就可以了。 所以，软件并非是为了我这样的小白设计的，而是为专业的人设计的，因此我才会看着琳琅满目的按钮不知所措。\n很多刚准备入门机器学习和深度学习的同学，大家的问题可能并不是不会使用Tensorflow这个框架，而是不会设计Model，不懂一个Model需要先做什么后做什么，在什么层次需要应用什么函数来达到效果。 换个角度来说，就算熟悉的掌握了Tensorflow的每个函数如何调用，也未必就能实现神经网络。 因此，Tensorflow做为一个框架，并不是让你对每个函数都了如指掌，而是当你想做什么动作的时候，知道框架中已经实现了这个功能，你知道要去寻找什么。而寻找对应的函数，就是很简单的问题了，然后再经过几次使用，你就完全可以记住了。\n学习框架就是要理解它的哲学 # 框架为我们提供了一些功能上的便利，为了实现功能的通用性和可扩展性，框架需要一些辅助机制，来确保可扩展性和通用性。\nTensorflow这类算法的框架，相比较复杂的业务工程类框架要简单很多。\nTensor: 张量 flow ： 流\n他的名字已经揭示了他的核心逻辑。Tensorflow 中的计算使用一个有向图(计算图)来表示。其中每个运算操作作为一个点，点与点之间连边，数据就是这里的Tensor，Tensor在其中流转，最终完成计算。\n一个计算图描述了一个计算的流程，没个点可以有任意多的输入和输出。有一些边并不是用来流转数据的，而是用来依赖控制，用来保持数据在正确的时间被运算。\n因此我们的代码中，大部分是在描述一个计算图，而当这个计算图被描述完毕后，需要触发一个Session来执行这个计算图。\n我们不能事无巨细的讲解框架中的设计逻辑。这里我们简要介绍比较重要的几个元素，是深入学习之前必须先搞透的东西。\nVariable # Variable是一类特殊的运算操作，每次执行计算图后，Variable中的数据tensor会被保存下来，同时在计算的过程中也会被更新，比如神经网络的系数，每次训练都会被更新，最后会被保存下来。\nSession # TensorFlow执行计算图需要实例化一个Session类来执行。调用Session的run方法，他可以自动计算所需计算的节点并按照依赖顺序计算他们，并且每个Session持有一些资源， 比如Variable，在计算结束的时候，我们要关闭Session以减少开销。\n小经验 # 学习框架有一些方法，是很多实践总结下来的经验，分享一下。\n过程 # 学习框架的过程大致是这样的：\n理解核心概念/理念 -------\u0026gt; 入门经典代码/项目 -------\u0026gt; 核心类的代码 （设计哲学） （加深理解） (这些代码会大体勾勒出整个框架的逻辑) | | V ----------\u0026gt; 更复杂的代码/项目 | （学习如何使用/最佳实践） | | | | | V |__________ 更多核心类的实现 (会让你对每个部分设计目的更清晰， 帮助你融会贯通) 方法 # 前期刚接触的时候，多看博客，开始接触代码后，学会用好源码。\n注意！这里的源码并不代码，而是源代码中的注释！\n框架的代码都是相对规范的，在核心的类中都有非常详细的注释，解释了该类的作用、调用方式、特点、注意事项等，还可以直观的看到参数的情况。很多框架的API文档其实就是这些注释换个地方给你而已。 因此与其看文档，有的时候源代码会更好用。当然你需要熟练的使用IDE和代码跳转。\n书目推荐 # 由于Tensorflow的框架逻辑并不难，难的是用那些模型本身，因此很少有非常基础的书籍。 这里推荐一个并不是针对小白的书，但是小白带着看也很好的，更高阶也更实用一些。 《TensorFLow实战》 黄文坚 唐源 著\n"},{"id":14,"href":"/posts/python/anaconda/","title":"Tutorial of anaconda \u0026 原生虚环境","section":"Python","content":" 什么是conda？ # anaconda是一个用于科学计算的python发行版。其中预置了一些用于科学计算的库，诸如numpy等。\n并且包含一个包管理系统，可以方便的安装相关的库。\n我使用conda主要是搭建机器学习的环境。\nInstall # 在conda的download页面找适合自己的安装包下载，在Ubuntu上会得到一个bash脚本文件。 也可以使用命令：\nwget https://repo.continuum.io/archive/Anaconda2-5.1.0-Linux-x86_64.sh 然后使用root权限运行就可以了。 在运行的过程中，会询问你一些设置方案，如安装的路径、是否要添加进入PATH等。\n检查是否安装成功 # 使用命令：\npython -V 出现：\nPython 2.7.14 :: Anaconda, Inc. 说明安装成功\n使用conda创建自己的开发环境 # 学过python的都知道，py的版本兼容实在太随意了。因此py为了解决同一台电脑上需要不同py环境的问题，设计了一个虚环境。也就是我们可以创建一个虚环境，然后进入这个虚环境安装我们需要的包，这些包的作用范围就是在这个环境中。\n因此也就实现了环境隔离。 一般我们在开始一个开发的时候，都会先创建一个虚环境。\n使用conda创建tenserflow训练环境 # # 创建名为:nlpcc-1.0 的虚环境 # 指定python版本为2.7, tensorflow版本为1.0的gpu版， # 需要安装anaconda conda create -n nlpcc-1.0 -c anaconda tensorflow-gpu=1.0 python=2.7 # 为当前环境安装包 conda install numpy # 升级包的版本 conda update numpy # 删除包 conda remove numpy # 列出当前环境的包 conda list # 删除一个环境 conda remove --name nlpcc-1.0 --all # 进入一个环境 source activate nlpcc-1.0 # 离开当前环境 deactivate 虚环境 # 很多时候如果是普通的工程开发的python项目conda并不能很好的找到需要包，所以还是要回到pip上来。但是依然有隔离生产环境的需求，因此就出现了虚环境。\n虚环境通过一个第三方程序实现，其实非常简单，就是一个库的复制。\n安装 sudo pip install virtualenv 创建虚环境 在任何文件夹下运行下面的命令就会产生一个对应的文件夹，关于这个环境的一切都在这里。 virtualenv my_project # 在当前文件夹下创建一个文件夹，并把python拷贝一份。 # 可以在创建虚环境的时候制定使用的python的版本。 virtualenv -p /usr/bin/python2.7 my_project 使用环境 首先就是激活一个环境\nsource my_project/bin/activate 此后安装的包都是安装在当前的环境中的，因此是完全隔离的。\n结束使用该环境\ndeactivate 删除一个环境就只要删除对应的文件夹即可。 环境保持 # 往往在开发的时候，我们使用的某个库的版本并不一定会被后来的版本完全兼容，python中这太常见了。\n因此为了方便我们在次还原环境，我们需要导出一份包的配置。\npip freeze \u0026gt; requirements.txt 这样就备份了一份，回头可以直接安装\npip install -r requirements.txt 更优雅的管理虚环境 # 这个可以使用：virtualenvwrapper的包来实现。\n"},{"id":15,"href":"/posts/others/vimium/","title":"Vimium - Google-Chrome-Plugin","section":"Others","content":" What\u0026rsquo;s this # Vimium 你可以认为这是一个Chrome下的快捷键设置集合。这个快捷键集合继承了Vim的快捷键方式，力图做到全键盘流畅使用浏览器。\nHow to use it # 这里介绍默认的快捷键设置，你也可以添加自己的快捷键。对于你的Chrome帐号，这些是会被同步的，也就是你在不同的电脑上使用登录了你的账户的Chrome浏览器都可以使用这个设置。\n可以打开这个插件，看到下面这个图片。\n快捷键 功能说明 j 向上滚动 k 向下滚动 h 向左滚动 l 向右滚动 gg 到达Top G 到达bottom d 向下滚动半页 u 向上滚动半页 r 重新加载这一页 yy 复制当前页的链接到粘贴板 p 在当前页打开粘贴板中的链接，如果复制的是文字直接使用默认搜索引擎搜索 P 在新的标签页做上一操作 gi 使当前焦点换到页面的第一个输入框中 f 显示当前页面所有可点击部分，并在当前页打开对应链接 F 在新的标签页打开 gf （没用过，也不知道有啥用，用来选择下一个结构?） o 出现一个输入框，用来打开history or bookmark 中的链接，备选与你输入的东西相匹配的 O In a new Tab b 同o差不多，只备选bookmark中的链接 B In a new Tab T 在你已经打开的Tab里面搜索，可以直接跳转 / 搜索 n/N 跳至下一个/上一个搜索到的点 H 历史后退 L 历史前进 J 跳到左边一个Tab K 跳到右边一个Tab t 打开新的Tab ^ 跳到上一次你停留的Tab x 关闭当前Tab X 重新打开关闭的标签页 "},{"id":16,"href":"/posts/linux/taskwarrior/","title":"Tutorial of Taskwarrior","section":"Linux","content":"Taskwarrior 是一款命令行的TODO应用，功能强大，且使用逻辑简单方便，命令行的操作非常适合程序员。 （基本上能在命令行解决的问题就不要用GUI， 能用键盘解决的就不要用鼠标。）\n目前我使用到的功能有：\n添加task 给task修改所属的project、截至日期 更改task的状态，如：start、done 修改task的priority 添加tags给task 给task添加task依赖关系 \u0026hellip; 基本使用 # 添加 task task add xxxx [project:xxx] [priority:xx] [due:xx] 修改task状态 task ID start task ID done 修改task信息\ntask ID modify [project:xx] [due:xx] [priority:xx] 其中due常用的选项有：\neom : end of month 添加tags\ntask ID modify +house +problem 其中有个特殊的tag是：next， 这回提升这个task的优先级。\ntask ID modify +next 添加依赖关系 task ID modify depends:OTHER_ID 命令格式 # task [filter] [command] [modifications | miscellaneous]\n如果将Task比作一个类，可以把每个task都理解成一个实例。我们将实例存储在一个文件中，task就是用来处理这个文件的改动、信息筛选的命令。\nfilter-筛选器 通过一些条件，筛选出我们每次操作的对象。 # 筛选所有pending的task，并计数 # task status:pending count # 筛选所有tag是work的，并计数 # task +work count # 筛选所有tag不包含work的，并计数 # task -work count 如果有多个条件，可以使and、or来进行连接\ntask project:home -work count # the same to task project:home and -work count (待续\u0026hellip;)\n配色 # calendar # burndown # timewarrior # 多机同步 # Reference # [1]. taskwarrior Docs [2]. laserx\u0026rsquo;s Blog\n"},{"id":17,"href":"/posts/acm/acm-collection/","title":"ACM-collection","section":"Acm","content":"汇总做过的题目：来源、类别、题意概括、难度等。使用\u0026lt;Ctrl\u0026gt; + F 的方式检索。\nTitle Link Tags Description Picking Strings CF 923-D 字典树 还没看 "},{"id":18,"href":"/posts/others/lucene-1/","title":"Lucene（一）","section":"Others","content":"Lucene 是apache基金会下的一个项目，用于匹配搜索的库。可以方便的集成进入各种应用中，并在不同的应用场景下有不同的衍生子项目。是基于Java的全文索引引擎。\n"},{"id":19,"href":"/posts/git/advanced-git-1/","title":"git 进阶一","section":"Git","content":"最近总是在沉迷游戏，而且笔记本太老了，开枪太卡。 这样下去太影响学习了。 决定组个台式机，顺畅的打游戏。\n工作进度保存与恢复 # 这个功能主要针对的是工作区和暂存区，版本库是不需要保存的，因为他本身就是一种保存进度。\n使用git stash 命令会将工作区和暂存区的状态进行保存。 其完整版的命令是这样的:git stash [save [--patch] [-k | --[no-] keep-index] [-q | --quiet] [\u0026lt;message\u0026gt;] ] 其中，-k 参数会保留当前的暂存区，默认会重置暂存区。 这个命令会将工作区和暂存区的内容都重置到上一次提交的状态！ 这个也很好理解，按照我们模块化开发的思路，当我们写某个东西写到一半的时候，突然需要中断，然后去写另外一个东西，这个时候，不能把这个一半的东西放到代码中，所以会被重置会上一个提交。\n使用git stash list 命令可以查看已经保存的工作进度。\n使用git stash pop [--index] [\u0026lt;stash\u0026gt;] 可以恢复进度，--index参数指暂存区也恢复，否则只恢复工作区。stash参数就是list中的选项，可以定点恢复，否则恢复最近的一次。\ngit stash clear\ngit stash drop delete the newest one.\ngit stash apply 恢复但是不删除。类似于pop;\ngit stash branch \u0026lt;branch\u0026gt; 基于进度创建分支。\n需要注意的是，还没有被跟踪的文件是没有办法被保存的。\nGit 忽略追踪 # 很多文件诸如编译出来的文件，我们不应该放在git仓库中，这个时候要避免这类文件被追踪到，我们可以写一个文档来标注这些文件。\n在仓库的目录下写一个.gitignore 的文件，文件每一行写一条规则，对应匹配到的文件就会被忽略。这个文件的有效范围是包含其子目录的。\ngitignore 语法 # #开始或空行都会被忽略 可以使用通配符， *, ?, [abc]等。 以/开头，表示要忽略的文件在本目录中，而不是在子目录中 以/结尾，表示忽略整个文件夹, 不以/结尾的，同名的文件和文件夹都忽略。 以！开头表示本文件或目录不忽略，尽管之前有相关规则匹配到。 如果我们将这个文件加入到版本库中就会被版本库共享，给这个文件自己加一个忽略规则就不会被加入到版本库。\n同时，需要注意的是！ 已经被追踪的文件无法被这个文件忽略，只有未被追踪的文件才可以。\nGit 里程碑 # "},{"id":20,"href":"/posts/git/advanced-git/","title":"git 进阶","section":"Git","content":" 仓库概念 # 在git中，仓库的概念十分简单，也是最核心的概念之一。 仓库用一个文件夹来存储和描述，这个文件夹就在你项目的那个目录下，是个隐藏文件.git/。除此以外没有其他的位置存储这个仓库想关的信息。 这种仓库的概念非常的简约，会有一个问题，就是不小心删除的话就丢失了。因此，git的一般使用要至少进行多机备份仓库，这个备份是很简单的，在git的系统中，只是一个命令。\n概念的简约，是Linus设计作品的一个特点，linux的操作系统的很多概念都非常简约。例如文件系统的概念，无论是文件夹还是设备，统一使用文件的概念去设计和使用。在这里，一个版本控制的单元使用仓库的概念，且没有那么多复杂的控制文件，就在一个小小的文件夹里，拷贝走也完全可以使用。\n这种分布式仓库的概念中，没有主从关系，也没有中心关系，彼此是独立的，可以做仓库同步和融合，但是都是可控制的。\n工作区 \u0026amp; 暂存区 \u0026amp; 版本库 # 这三个概念是git的核心逻辑。\n工作区 ： 就是你的实际的目录和文件。 暂存区 ： 就是中间的一个过渡区，连接了版本库和工作区。 版本库 ： 就是实际存放各个版本和分支的地方。\n其原理是这样的，暂存区维护一份目录树，没有实际的文件。这个目录树与工作区的目录树是不一样的。工作区的目录树是操作系统中文件系统的目录树。暂存区就是存了一些文件名，时间戳，文件长度等信息。\n很多时候我们会有这样的经历，我想把一些密码设置的东西，或是笔记放在我当前的目录下，但是我并不想把这部分放到仓库中，因为我会把仓库共享出去的嘛。这个时候，这个文件是存在我的工作区的，但是并不在我的暂存区，由于仓库的目录树必须由暂存区的内容来写入，所以在版本库中也不会有。\n当我们对一些问件做了修改之后，使用git status -s就可以查看我们的当前哪些文件被修改但是没有提交到暂存区。\n使用git add XXX 可以将当前在工作区修改的部分提交到暂存区，这个时候暂存区的目录树会做出修改，更新相关文件的时间戳等信息。 同时，我们的文件内容会被写入到对象库中，生成一个新的对象。并且这个对象会有和ID，这个ID会被写入到暂存区的目录树中。\n使用git commit 的时候，会把暂存区的目录树更新到版本库中对应的分支的目录树中。 这个时候才是真正的写到了版本库中。\n使用git reset HEAD 的时候，暂存区的目录树会被版本库中的目录树覆盖，也就是还原到了上次你提交的版本。但是此时工作区的修改是不会受到影响的。\n使用git rm --cache \u0026lt;file\u0026gt; 的时候，会直接把暂存区的目录中对应的文件删除，但是工作区不受影响，不加--cache会将工作区的一并删除。\n使用git checkout 或 git checkout -- \u0026lt;file\u0026gt; 命令的时候，会用暂存区中的文件去替换工作区的文件。 也就是当你写一个东西，写着写着发现不好，需要去掉，但是你已经修改了很多个文件的很多个部分，手动删除不可能做到，你可以使用这个命令来把你工作区的内容回退到你之前提交到暂存区的时候的样子。 因此，选择合适的时机进行提交操作十分重要。要在自己的开发节点上及时add，及时commit。这样可以方便回退。\n使用git checkout HEAD 或 git checkout HEAD \u0026lt;file\u0026gt;，会用版本库中的对应分支的文件来替换暂存区和工作区的文件，这个动作可以参考上面一条，都是十分危险的动作。\n有了这三个东西， 会发现，你好像什么都可以得到。 你可以历史查看你每次提交的改动，每个文件的每次提交后的样子你都可以得到。你拥有了一个结构合理，体积很小，速度很快的，无所不知的版本控制系统。 优秀的设计！\nGit 对象 # 贯穿在git的各个元素中，都有40位的SHA1字符串的ID。每个ID都标志了一个对象，每个对象其实都是一个文件。 在git仓库的/objects/ 文件夹下，有一堆两个字母命名的文件夹，打开这些文件夹，里面是一些38位字符命名的文件，所以就是这40位的用法。\n使用git log -1 --pretty=raw 命令可以查看我们上一次提交的时候都做有哪些东西 可以看到如下的内容： commit xxxxxx... tree xxxxxx... parent xxxxxx... author ... commiter ... 其中包含了三个对象：\n+ 一个是commit，这是本次提交的唯一ID标志。 + tree， 这是本次提交所对应的目录树 + parent， 这是本次提交上一次提交的ID 使用git cat-file -t \u0026lt;ID\u0026gt; 来查看每个ID指代的对象的类型，分别会是： commit, tree, commit。\n使用git cat-file -p \u0026lt;ID\u0026gt; 来查看每个对象的内容。\n查看一个commit，包含的信息有：tree， parent， author， committer, message. 查看一个tree， 会包含很多个blob对象的信息。每个blob对象是你这次修改的每个文件。 如果再对这个blob查看内容，就是文件的内容了。 通过这几个对象，就可以完整的描述一次提交，并且可以形成一个追踪链。\nGit reset # 在上面的记录中已经使用过这个命令。目前我们知道git有一个提交链的东西来记录提交历史，并且会记录HEAD为当前最新的一次提交。 reset就是可以进行版本回退的工具。\n使用git reset --hard HEAD^ 可以回退到上一个commit的时候。工作区会随之改变，如果存在没有提交的内容就会丢失。 HEAD^代表了Head的父提交。 这种重置，会将中间的一段历史记录丢掉。使提交的历史也改变了，当我们使用git log的时候，会只显示此前的commit，但是之后的就丢失了。\n下面是找回的方法。\nGit reflog # 由于这些丢失的commit的ID都已经不见了，我们要做的就是找到这些ID，所谓的丢失，并没有真正的删除。而是由于数据结构的需要，这部分不会直接出现在数据结构中，无法用正常的方式访问到，但是依旧存在于文件中。这个时候就相当于去修复数据结构。\ntail -5 .git/logs/refs/heads/master 可以查看到这个分支对应的log文件，这个文件记录了这个分支所有的commit信息。以文本的形式，并不是以数据结构的形式。\n使用git reflog show master | head -5 可以查看最新的5次commit，当然我们的reset操作也是在其中的。 其基本的数据格式是这样的：\nID master@{0}: type : message ID master@{1}: type : message 其中type会标注这个操作是什么类型的，正常的都是commit， 不正常的就如我们做reset操作。这个并不重要。重要的是这个命令给每个状态都有一个别称master@{1}，我们可以继续使用reset来恢复之前的reset。 git reset --hard master@{1}， 就可以跳跃到对应的状态，并且这之间的记录也会回来。\n总结git reset的使用 # git reset [-q] [\u0026lt;commit\u0026gt;] [--] \u0026lt;paths\u0026gt; 只恢复暂存区成为仓库最新提交的状态，不更改工作区。可以操作单个文件。 git reset [--soft | --hard | --mixed | --merge | --keep] [-q] [\u0026lt;commit\u0026gt;] --soft，只会更改head指向的commit，并不会更改暂存区和工作区 --mixed， 会更改暂存区，也是默认的方式。 --hard， 会更改暂存区和工作区。 举几个案例：\ngit reset: 清空暂存区的内容。 git reset HEAD: 同上。 git reset -- filename: 撤出暂存区add的某个文件，逆add操作。 git reset --soft HEAD^: 对上一次提交不满意，直接删掉上一次提交。比如你手快做了一次提交，但是这个小功能块并没有完成，不应该有一个commit出现，所以你把这个commit这样忽略掉，下次重新提交。 git reset HEAD^: 工作区不受影响，只将版本库和暂存区往前回退一次。 git reset --hard HEAD^: 工作区,版本库和暂存区往前回退一次。 如何自己摸索git的结构和原理 # 学会使用上面用到的常用命令就可以自己去摸索git的原理。 最主要的是git cat-file 来查看对应的ID中的内容，一切都在其中了。 其次就是git log，保存了很多信息。\n从此git不再神秘。\n"},{"id":21,"href":"/posts/linux/linux-timing/","title":"Linux 定时任务","section":"Linux","content":"很久以前就想找到一种定时执行任务的方法，下面介绍一种在Linux下通用的，也是最方便的方式。\ncron # 这是Linux内核自带的一个定时执行任务的服务。默认是不打开，可以设置成开机自动启动。\n要把cron设为在开机的时候自动启动，在 /etc/rc.d/rc.local 脚本中加入 /sbin/service crond start。\n这是一个周期性执行某个程序的服务，与at不同，at是一次性的服务。显然这个服务更常用一些。 很多周期性的任务，如定期清缓存，写磁盘，做备份等等。\n我用这个命令来自动更新我github.io上的博客代码。\ncrontab # 这是cron提供的一个命令，用来设定定时任务。 定时任务非常的简单，就是利用配置文件来描述什么时候执行什么动作，所以设定任务也就要写明白这些参数就可以了。\n配置文件的基本格式 # 配置文件可以有很多个，存放在固定的目录下。服务启动以后会一起读取然后执行。\n配置文件每行是一个定时任务的描述，包括6个字段：\n分(0-59), 小时(0-23), 天(1-31), 月(1-12), 星期(0-7,0和7都是周日) 要执行的命令 举个例子：\n0 8,22 * * 1-5 echo \u0026#34;Hello\u0026#34; // 在周一到周五的8点和22点的时候输出”Hello“ // // * 通配符 // 同一个字段多个值，用逗号隔开。 // 1-5表示一个区间 这个配置文件很好写，就不多举例子了。\n启动服务 # sudo /etc/init.d/cron start // start sudo /etc/init.d/cron stop // stop sudo /etc/init.d/cron restart // restart crontab 用法 # 使用：\ncrontab –e : 修改 crontab 文件，如果文件不存在会自动创建。 crontab –l : 显示 crontab 文件。 crontab -r : 删除 crontab 文件。 crontab -ir : 删除 crontab 文件前提醒用户。 其中，-e是编辑当前用户的配置文件，默认是存放在/var/spool/cron/crontabs/目录下。 只要服务启动着，编辑保存这个文件，定时任务就设定好了，有的时候可能真正执行会有1-2分钟的延时。\n注意事项 # 这个服务是一个后台运行的服务，所以像上面那个输出”Hello“的例子就是没用的，因为没有办法输出到你的终端。一般我们会把交互的部分放在文件里。\n因为是个后台的进程，所以要把环境变量写成绝对的路径，不要以你的当前目录做参考，因为执行的时候是没有当前目录的。任何路径都要写绝对路径。\n要被执行的命令可以直接写在这里，也可以写在脚本里，任务写你的脚本路径，就是执行脚本，注意脚本要有执行权限。\n解放劳动力的开始！ # "},{"id":22,"href":"/posts/linux/linuxprogramming-1/","title":"《Linux 编程实践教程》- 1","section":"Linux","content":"2018年恢复写博客的第一篇博客。\n「·最近在看书，主要是Linux相关的书，尽管即将要进行NLP的研究生阶段，但是回首自己的本科计算机编程经历其实非常浅薄。这两年的积淀在常用算法和数据结构上有一些，在一些基础理论上有一些，但是距离成为一个程序员还有很大的距离。综合各种因素，我选择将Linux学习更透彻作为程序员的落脚点。这是我作为程序员的自我修养。·」\n关于这本书 # 这是一本Linux的基础教材，2004翻译过来的。但是国内貌似很少用，作为了课外读物。\n这本书的落脚点是编程实践。其中贯穿着Linux的一些原理和使用，以及编程思维。\n包括：用户，文件系统，连接，事件驱动，进程通信，多线程，服务，协议等。以Linux的一些已经实现的功能为基础，进行讲解，再实现。 会涉及很多的编程细节的东西，这是上课不会讲到的。都非常的有意思。做到“知其然，知其所以然”。\n本书的风格和套路 # 此书适合初学者，但是任何初学者的书都不是完全适合初学者， 有很多概念和细节都需要读者有些了解才能更好读懂。 我在读本书之前的一天读了一部分《Linux系统编程》。这是一个偏底层概念和细节的书，主要在文件系统，I/O，进程，内存，信号，时间上去为Linux系统编程打细节基础，看起来没那么有趣，因为细节太多，但是确实把文件和I/O的概念给我打通了。 有了这些基础再看本书的第一章，并实现其中的more实例就省力很多。此前一个月左右我看过这一章，但是在写代码的时候还是非常不能理解一些细节。\n书中会给出全部的实现，但是并不是完整功能的实现，是一部分功能的完整实现。并将剩下的一些功能的实现作为扩展的作业。 在给出实现的时候，会讲相关的基础知识。\n比如在第二章讲Who命令的时候，会先告诉你man命令怎么用，以及文档各个部分是什么，怎么去看相关条目，从man手册的那些部分获得什么信息等。\n第一章：more命令的实现 # more命令比较简单的功能就是把文件的内容投射到终端上，并且可以向下翻页或翻行。要能从文件中读取也可以从管道中读取内容。\n在Linux一切皆文件的设计理念下，要知道各种I/O都可以作为文件来使用，也就是可以用打开文件的方式来打开。无论是文件、管道、设备(键盘)、重定向数据，都可以作为文件来打开读取。\n那么实现这样的功能就没有那么困难了。 整体逻辑就是：\n打开文件 读取一定的行数 提示翻页或下一行，接受键盘动作 作出反应，重复。 代码中用到了终端设置接口termios.h，让用户输入的操作不被显示，不用回车，直接进入程序。 用到了与终端用文件交互的方式tty。\nCode # #include \u0026lt;bits/stdc++.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;termios.h\u0026gt; using namespace std; const int PAGELEN = 24; const int LINELEN = 512; int see_more(FILE * cmd){ int c; printf(\u0026#34;\\033[7m more? \\033[m\u0026#34;); // 白色底色 while( (c = getc(cmd)) != EOF ){ if( c == \u0026#39;q\u0026#39; ){ return 0; } else if( c == \u0026#39; \u0026#39; ) return PAGELEN; else if(c == \u0026#39;\\n\u0026#39;){ return 1; } } return 0; } void do_more( FILE * fp ){ char line[LINELEN]; int num_of_lines = 0; FILE * fp_tty = fopen(\u0026#34;/dev/tty\u0026#34;, \u0026#34;r\u0026#34;); // 一切皆文件，这个文件标志就是与终端交互。 struct termios initial_settings, new_settings; tcgetattr(fileno(fp_tty), \u0026amp;initial_settings); new_settings = initial_settings; // clflag 局部模式，只在本程序中有效。 new_settings.c_lflag \u0026amp;= ~ICANON; // 关闭标准模式， 不允许使用特殊字符 EOF, EOL, EOL2, ERASE, KILL, LNEXT, REPRINT, STATUS, 和 WERASE，以及按行的缓冲。 new_settings.c_lflag \u0026amp;= ~ECHO; // 输入字符不回显 new_settings.c_cc[VMIN] = 1; // VMIN :非 canonical 模式读的最小字符数（MIN主要是表示能满足read的最小字元数）。 new_settings.c_cc[VTIME] = 0; // VTIME ：非 canonical 模式读时的延时，以十分之一秒为单位。 new_settings.c_lflag \u0026amp;= ~ISIG; // 当接受到字符 INTR, QUIT, SUSP, 或 DSUSP 时，不产生相应的信号。 if(tcsetattr(fileno(fp_tty), TCSANOW, \u0026amp;new_settings) != 0) { fprintf(stderr, \u0026#34;Could not set attributes\\n\u0026#34;); } if(fp_tty == NULL ) { exit(1); } int reply; while(fgets(line, LINELEN, fp)){ if(num_of_lines == PAGELEN){ reply = see_more(fp_tty); if( reply == 0 ) break; num_of_lines -= reply; } if( fputs(line, stdout) == EOF){ exit(1); } num_of_lines ++; } tcsetattr(fileno(fp_tty), TCSANOW, \u0026amp;initial_settings); } int main(int ac, char * av[]){ FILE * fp; if( ac == 1 ) do_more(stdin); // 一切皆文件，标准IO也是文件。 else { while( -- ac ) { if( (fp = fopen(* ++ av, \u0026#34;r\u0026#34;)) != NULL ){ do_more (fp); fclose(fp); } else exit (1); } } return 0; } 更多功能 # 完整的还有： 获取文件大小，行数，当前行数，百分比。 终端的行数。 more的提示不要跟着上移，要停留在底部。\n待完善。\n"},{"id":23,"href":"/posts/web/less/","title":"less 笔记","section":"Web","content":"作为CSS的一种扩展语言，使得CSS开发更便捷。\n变量 # less中的变量使用@开头。\n// LESS @color: #4D926F; #header { color: @color; } h2 { color: @color; } /* 生成的 CSS */ #header { color: #4D926F; } h2 { color: #4D926F; } 甚至可以用变量名定义为变量:\n@fnord: \u0026#34;I am fnord.\u0026#34;; @var: \u0026#39;fnord\u0026#39;; content: @@var; --\u0026gt; content: \u0026#34;I am fnord.\u0026#34;; 请注意 LESS 中的变量为完全的 ‘常量’ ，所以只能定义一次.\n字符串嵌入 # 变量可以用类似ruby和php的方式嵌入到字符串中，像@{name}这样的结构:\n@base-url: \u0026quot;http://assets.fnord.com\u0026quot;; background-image: url(\u0026quot;@{base-url}/images/bg.png\u0026quot;);\n作用域 # LESS 中的作用域跟其他编程语言非常类似，首先会从本地查找变量或者混合模块，如果没找到的话会去父级作用域中查找，直到找到为止.\n引入文件 # 你可以在main文件中通过下面的形势引入 .less 文件, .less 后缀可带可不带:\n@import \u0026#34;lib.less\u0026#34;; @import \u0026#34;lib\u0026#34;; 如果你想导入一个CSS文件而且不想LESS对它进行处理，只需要使用.css后缀就可以:\n@import \u0026#34;lib.css\u0026#34;; 打包重用 # #bundle { .button () { display: block; border: 1px solid black; background-color: grey; \u0026amp;:hover { background-color: white } } .tab { ... } .citation { ... } } 使用的时候这样使用：\n#header a { color: orange; #bundle \u0026gt; .button; } 混合 # 混合可以将一个定义好的class A轻松的引入到另一个class B中，从而简单实现class B继承class A中的所有属性。我们还可以带参数地调用，就像使用函数一样。\n// LESS .rounded-corners (@radius: 5px) { // 设置默认值 border-radius: @radius; -webkit-border-radius: @radius; -moz-border-radius: @radius; } #header { .rounded-corners; } #footer { .rounded-corners(10px); } /* 生成的 CSS */ #header { border-radius: 5px; -webkit-border-radius: 5px; -moz-border-radius: 5px; } #footer { border-radius: 10px; -webkit-border-radius: 10px; -moz-border-radius: 10px; } 任何 CSS class, id 或者 元素 属性集都可以以同样的方式引入.\n@arguments 变量 # @arguments包含了所有传递进来的参数. 如果你不想单独处理每一个参数的话就可以像这样写:\n.box-shadow (@x: 0, @y: 0, @blur: 1px, @color: #000) { box-shadow: @arguments; -moz-box-shadow: @arguments; -webkit-box-shadow: @arguments; } .box-shadow(2px, 5px); 嵌套 # 我们可以在一个选择器中嵌套另一个选择器来实现继承，这样很大程度减少了代码量，并且代码看起来更加的清晰。\n// LESS #header { h1 { font-size: 26px; font-weight: bold; } p { font-size: 12px; a { text-decoration: none; \u0026amp;:hover { border-width: 1px } } } } /* 生成的 CSS */ #header h1 { font-size: 26px; font-weight: bold; } #header p { font-size: 12px; } #header p a { text-decoration: none; } #header p a:hover { border-width: 1px; } 注意 \u0026amp; 符号的使用—如果你想写串联选择器，而不是写后代选择器，就可以用到\u0026amp;了. 这点对伪类尤其有用如 :hover 和 :focus.\n.bordered { \u0026amp;.float { float: left; } .top { margin: 5px; } } /* 输出 */ .bordered.float { float: left; } .bordered .top { margin: 5px; } 函数 \u0026amp; 运算 # 运算提供了加，减，乘，除操作；我们可以做属性值和颜色的运算，这样就可以实现属性值之间的复杂关系。LESS中的函数一一映射了JavaScript代码，如果你愿意的话可以操作属性值。\n// LESS @the-border: 1px; @base-color: #111; @red: #842210; #header { color: @base-color * 3; border-left: @the-border; border-right: @the-border * 2; } #footer { color: @base-color + #003300; border-color: desaturate(@red, 10%); } Color 函数 # lighten(@color, 10%); // return a color which is 10% *lighter* than @color darken(@color, 10%); // return a color which is 10% *darker* than @color saturate(@color, 10%); // return a color 10% *more* saturated than @color desaturate(@color, 10%); // return a color 10% *less* saturated than @color fadein(@color, 10%); // return a color 10% *less* transparent than @color fadeout(@color, 10%); // return a color 10% *more* transparent than @color fade(@color, 50%); // return @color with 50% transparency spin(@color, 10); // return a color with a 10 degree larger in hue than @color spin(@color, -10); // return a color with a 10 degree smaller hue than @color mix(@color1, @color2); // return a mix of @color1 and @color2 你还可以提取颜色信息:\nhue(@color); // returns the `hue` channel of @color saturation(@color); // returns the `saturation` channel of @color lightness(@color); // returns the \u0026#39;lightness\u0026#39; channel of @color Math 函数 # round(1.67); // returns `2` ceil(2.4); // returns `3` floor(2.6); // returns `2` percentage(0.5); // returns `50%` 模式匹配 # 类似于函数重载。\n.mixin (@s, @color) { ... } .class { .mixin(@switch, #888); } 如果想让.mixin根据不同的@switch值而表现各异，如下这般设置：\n.mixin (dark, @color) { color: darken(@color, 10%); } .mixin (light, @color) { color: lighten(@color, 10%); } .mixin (@_, @color) { display: block; } 变量可以匹配任意的传入值，而变量以外的固定值就仅仅匹配与其相等的传入值。\n我们也可以匹配多个参数：\n.mixin (@a) { color: @a; } .mixin (@a, @b) { color: fade(@a, @b); } 导引 # 当我们想根据表达式进行匹配，而非根据值和参数匹配时，导引就显得非常有用。Less不使用if-else的方式实现条件判断，而是使用导引。\n.mixin (@a) when (lightness(@a) \u0026gt;= 50%) { background-color: black; } .mixin (@a) when (lightness(@a) \u0026lt; 50%) { background-color: white; } .mixin (@a) { color: @a; } 可使用的运算符： =, \u0026gt;, \u0026lt;, \u0026gt;=, \u0026lt;=。 需要注意的是， 只有关键字true才是真，其余的任何东西都是假。 导引序列使用逗号‘,’—分割，当且仅当所有条件都符合时，才会被视为匹配成功。\n.mixin (@a) when (@a \u0026gt; 10), (@a \u0026lt; -10) { ... } 在导引序列中可以使用and关键字实现与条件：\n.mixin (@a) when (isnumber(@a)) and (@a \u0026gt; 0) { ... } 使用not关键字实现或条件\n.mixin (@b) when not (@b \u0026gt; 0) { ... } 导引可以无参数，也可以对参数进行比较运算：\n@media: mobile; .mixin (@a) when (@media = mobile) { ... } .mixin (@a) when (@media = desktop) { ... } .max (@a, @b) when (@a \u0026gt; @b) { width: @a } .max (@a, @b) when (@a \u0026lt; @b) { width: @b } 最后，如果想基于值的类型进行匹配，我们就可以使用is*函式：\n.mixin (@a, @b: 0) when (isnumber(@b)) { ... } .mixin (@a, @b: black) when (iscolor(@b)) { ... } 常用的有：\niscolor isnumber isstring iskeyword isurl 如果你想判断一个值是纯数字，还是某个单位量，可以使用下列函式：\nispixel ispercentage isem 避免编译 # 有时候我们需要输出一些不正确的CSS语法或者使用一些 LESS不认识的专有语法.\n要输出这样的值我们可以在字符串前加上一个 ~, 例如:\n.class { filter: ~\u0026#34;ms:alwaysHasItsOwnSyntax.For.Stuff()\u0026#34;; } 我们可以将要避免编译的值用 “”包含起来。输出的时候会去掉引号的。\nJavascript表达式 # @var: `\u0026#34;hello\u0026#34;.toUpperCase() + \u0026#39;!\u0026#39;`; 使用反引号包起来。 注意你也可以同时使用字符串插值和避免编译:\n@str: \u0026#34;hello\u0026#34;; @var: ~`\u0026#34;@{str}\u0026#34;.toUpperCase() + \u0026#39;!\u0026#39;`; 它也可以访问JavaScript环境:\n@height: `document.body.clientHeight`; "},{"id":24,"href":"/posts/web/react-2/","title":"react 设计概念","section":"Web","content":"react是一个前端库，着力在创造新的前端渲染的工作模式。 react单个可以做为开发库来单独使用，但是一般我们会将其与其他的相关库一起使用，在使用的时候，基本的react概念是不变的，只是在某些环节发生一些变化。\nreact 组件的生命周期 # 对于一个react的组件，其生命周期决定了其思维方式。 一个组件什么时候产生实例，在什么时候调用什么函数，决定了这个组件在什么时候做什么动作。\nreact严格的定义了组件的生命周期，分别是装载过程，更新过程，卸载过程。我们重点是要清楚，在装载和更新的过程中，react组件都要做哪些动作。\n装载过程 # 当组件第一次被装载的时候，一次被调用的分别是：\nconstructor componentWillMount render componentDidMount 这里我们使用的是ES6语法的方式来创建组建，所以有一些老的函数就没有被用到，也就不用再提了。\ncontructor # 并不是每个组件都需要构造函数，当有构造函数的时候，一定要先执行父类的构造函数。\nclass Sample extends React.Component{ contructor(props){ super(props); this.state = {foo: \u0026#39;bar\u0026#39;}; this.onClickSubmitButton = this.onClickSubmitButton.bind(this); // this.onClickSubmitButton = ::this.onClickSubmitButton; } } 在构造函数中，我们要：\n给内部数据初始化，也就是赋值state。 将函数绑定this，否则内部使用的数据会是错的，绑定以后使用的数据就是本组件中的数据。 componentWillMount \u0026amp; componentDidMount # 这是一组函数，分别在render之前和之后调用。 WillComponent这个函数其实有点多余，因为所有在这里做的事情我们都可以在构造函数中做，因此基本不会用到这个函数。 DidMount 就是在render函数过后调用，此时页面已经渲染出来。 在这个函数的执行时间上，还是比较有文章的。\n举个例子，组件A有三个子组件B，B都有实现这个函数，在A的render函数中，会执行B的render函数，但是当一个B的render函数执行完后，并不立即执行这个B的DidMount函数，而是等所有的B的render函数被调用完毕后才一起调用。当然也是按顺序的。 由于此时已经渲染出来，所以我们也就可以获得DOM树上的节点。因此我们可以在这时候请求服务器去填充数据。这在我们使用其他的一些前端库的时候比较方便。例如在使用jQuery的时候，jQuery只能对已经存在的元素进行操作，所以此时正是调用jquery的时候。\nrender # 但凡React组件都要实现这个函数，因为这个函数在Component中没有默认的实现。\nrender函数并不直接操作渲染，而是返回一个JSX语法的描述。最终的渲染动作由react来做。如过没有什么要渲染就可以返回一个null或者false。\nrender应该是一个纯函数，只接受state和props并产生返回值，没有其他任何的副作用。\n更新过程 # 要实现交互，就需要更新：\ncomponentWillReceiveProps shouldComponentUpdate componentWillUpdate render componentDidUpdate 在父组件发生Update调用render函数的时候，子组件就会经历更新过程。\ncomponentWillReceiveProps # 这个函数在使用this.setState更改数据的时候不会被调用。因为这个函数根据新props的值来计算是不是要更新内部状态state。更新内部状态使用setState，因此不会产生循环调用。 这个函数接受一个参数， 新传进来的nextProps。\nshouldComponentUpdate # 这是决定是否要刷新的函数，也是唯二需要返回值的函数，这个函数用于提高react的效率。 当我们使用this.setState去更改内部状态的时候，并不是直接更改的。而是直到执行到这里，还都没有更新。在这里可以做对比，然后决定是否有必要做更新。\ncomponentDidUpdate # 这个函数和之前的额装载过程一样，不用做很多解释。\n卸载过程 # 这个过程基本上只涉及一个函数，componentWillUnmount。一般我们在这里处理一些在componentDidMount中创建的元素，以免造成内存泄漏。\nreact 组件的数据传递 # 在前面几篇有关于数据传递的内容，无非就是Props和State。\n向子组件传递数据，就是在实例化的时候传递参数的方式。从组件向外传递数据的时候，是使用传递函数的方式。\n组件向外传递参数 # 组件要想对外传递参数，没有直接的这一动作，但是我们可以通过回调函数的思路来解决。\n对于父组件， 将数据处理的函数写好，作为参数传递给子组件。子组件在适当的时候调用这个函数就可以通过传递函数参数的方式将数据传递出去，而后的数据处理交给父组件的实现。 这样是组件的上下层级之间如何传递参数。\n"},{"id":25,"href":"/posts/web/mobx/","title":"mobx - redux的优秀替代品","section":"Web","content":"在使用react做大型开发的时候，我们习惯使用redux来做数据管控。但是redux实在是太过繁琐，流程很长，不利于快速开发。 mobx是redux作者非常推荐的一个替代产品。\n基本概念 # 与redux的长流程，严管控不同，mobx采用一种更直接的方式，和更自动化的方式管理应用的数据。\n状态驱动页面更新 # 应用的state也就是其中的数据，就是应用此时所在的状态，状态的改变驱动页面的改变，这是共识，问题就是怎么设计使状态的改变驱动页面更新。\n在mobx中，数据将被监视，当数据发生变化的时候，mobx会自动的知道哪些部分需要被刷新，而不需要程序员来指明更新什么。\n应用的状态分成两种， 一种是数据本身组成的基本状态。还有一种是在数据基础上计算得出的衍生状态。在下面我们会讨论这些。\nobservable # 对于需要被监视的数据，就将他用注解的方式注明，需要被监视。\nimport { observable, computed } from \u0026#34;mobx\u0026#34;; class OrderLine { @observable price = 0; @observable amount = 1; @computed get total() { return this.price * this.amount; } } 就这样简单的就将一个变量纳入mobx的观察体系中。 被观察的可以是几乎所有的javascript的数据结构，但是，对于对象，建议一律转成map来观察，因为对象只会观察此时有的字段，对于未来新添加的字段需要手动加入观察， 但是map就可以将添加进来的新key一并纳入观察。\nobserver # 有了被观察的，就要有观察者， 这里的观察者会是前端的组件。通常来说，每个组件都应该是可以观察自身数据的，响应式的应用。 一个观察者，会在数据发生变化的时候自动更新自己的视图。\nimport {observer} from \u0026#39;mobx-react\u0026#39;; @observer class TimerView extends React.Component { render() { return (\u0026lt;button onClick={this.onReset.bind(this)}\u0026gt; Seconds passed: {this.props.appState.timer} \u0026lt;/button\u0026gt;); } onReset () { this.props.appState.resetTimer(); } }; ReactDOM.render(\u0026lt;TimerView appState={appState} /\u0026gt;, document.body); action # 数据的改变会被捕获，那么由谁来该数据呢？ 理论上，mobx不会限制你怎么写代码，它支持让你便捷的开发。但是建议我们使用严格一点的方式，这种方式并没有特别复杂，但是让我们的代码更加清晰和利于管控。\n我们规定只在action中更改我们的数据。同样这也是一个注解：\n@action createRandomContact() { this.pendingRequestCount++; superagent .get(\u0026#39;https://randomuser.me/api/\u0026#39;) .set(\u0026#39;Accept\u0026#39;, \u0026#39;application/json\u0026#39;) .end(action(\u0026#34;createRandomContact-callback\u0026#34;, (error, results) =\u0026gt; { // 注意: 异步回调函数是单独的动作！ if (error) console.error(error); else { const data = JSON.parse(results.text).results[0]; const contact = new Contact(this, data.dob, data.name, data.login.username, data.picture) contact.addTag(\u0026#39;random-user\u0026#39;); this.contacts.push(contact); this.pendingRequestCount--; } })); } 其原理是会返回一个同名函数，在函数中间过程产生的数据并不会捕获并去刷新界面。只有在执行结束后才会被得到最终数据。 我们只在函数会更改组件状态的时候才使用这个注解。\n在上面的代码中，有两种使用方式，其实所有的这些都有不止一种的调用方式，这里我们使用的ES7的注解语法，在一些地版本的地方，我们还是可以使用函数的方式去调用，毕竟其本质上是一样的。\ncompute # 之前我们说到，状态分成两个部分，分别是原生状态和衍生状态。对于衍生的状态，我们通过@compute来标注，这个注解标注的表达式或是函数，必须只返回一个数据，而不会产生其他多余的动作。因为当这个表达式用到的数据发生变化的时候，这个表达式会自动计算一遍，当其中的数据被reaction使用到的时候。也就意味着衍生的数据也会一并更新。 但是我们在更新衍生数据的时候未必需要做诸如发送请求之类的动作，所以要保持这个表达式的纯净。\nreaction # 被称之为反应，在数据发生变化的时候，我们同时可能需要做一些附带的动作，比如发送请求，打印日志等。在反映中来做。\nautorun # 当你想创建一个响应式函数，而该函数本身永远不会有观察者时,可以使用 mobx.autorun。 这通常是当你需要从反应式代码桥接到命令式代码的情况，例如打印日志、持久化或者更新UI的代码。 当使用 autorun 时，所提供的函数总是立即被触发一次，然后每次它的依赖关系改变时会再次被触发。 相比之下，computed(function) 创建的函数只有当它有自己的观察者时才会重新计算，否则它的值会被认为是不相关的。 经验法则：如果你有一个函数应该自动运行，但不会产生一个新的值，请使用autorun。 其余情况都应该使用 computed。 Autoruns 是关于 启动效果 (initiating effects) 的 ，而不是产生新的值。 如果字符串作为第一个参数传递给 autorun ，它将被用作调试名。 传递给 autorun 的函数在调用后将接收一个参数，即当前 reaction(autorun)，可用于在执行期间清理 autorun。\n"},{"id":26,"href":"/posts/web/react-router-dom/","title":"react-router tutorial","section":"Web","content":"这是一个react router的V4版本。被广泛使用， 非常流行。\nInstallation # react router 被包含在三个包中： react-router, react-router-dom, react-router-native. 你几乎不会直接安装react-router这个包，因为这是一个核心包，提供的是基础的react应用的路由库。 另外的两个分别提供了特殊的使用环境，前者是浏览器端， 后者是在react-native中。他们都完全包含react-router这个包中的内容。\nnpm install --save react-router-dom\nThe Router # 在多页应用中，路由的设计尤为重要。 在react应用中，其实不存在真正的多页应用，而是使用一些浏览器操作来使得单页应用具备多页应用的功能。所谓的多页应用，应该是当你输入一个固定的链接时，得到的页面应该是一致的，并且具备后退的功能。但是在react应用中，页面并不会完全重新加载，而是以特殊的方式来组织，做局部加载，实现多页面的效果。\n在浏览器应用中，我们使用的是\u0026lt;BrowserRouter\u0026gt;和\u0026lt;HashRouter\u0026gt;组件。当我们的请求的网站是一个动态的页面（Know how to respond to any possible URI）的时候，我们使用前者；如果是个纯静态的页面，我们使用后者。很明显我们大多数使用前者。\nHistory # 每个router组件都有一个history的对象，用于记录浏览的记录，用于保持跟踪。 关于这一部分，暂时还没有研究。待研究。\nRendering a \u0026lt;Router\u0026gt; # \u0026lt;BrowserRouter\u0026gt; 只允许一个子组件的存在，所以跟react一个尿性的，我们可以将我们的应用封装成\u0026lt;App \\\u0026gt;的形式来使用。 For example:\nimport { BrowserRouter } from \u0026#39;react-router-dom\u0026#39; ReactDOM.render(( \u0026lt;BrowserRouter\u0026gt; \u0026lt;App /\u0026gt; \u0026lt;/BrowserRouter\u0026gt; ), document.getElementById(\u0026#39;root\u0026#39;)) The App # 在\u0026lt;App\u0026gt;中，我们就可以开始做布局的工作，我们可以不直接添加我们的路由体系，直接在\u0026lt;App\u0026gt;组件中添加一些组件。当我们添加我们的路由体系的时候，每个路由信息，都由一个\u0026lt;Route\u0026gt;组件来组织。\n\u0026lt;Switch\u0026gt; \u0026lt;Route exact path=\u0026#39;/\u0026#39; component={Home}/\u0026gt; {/* both /roster and /roster/:number begin with /roster */} \u0026lt;Route path=\u0026#39;/roster\u0026#39; component={Roster}/\u0026gt; \u0026lt;Route path=\u0026#39;/schedule\u0026#39; component={Schedule}/\u0026gt; \u0026lt;/Switch\u0026gt; 其中， \u0026lt;Switch\u0026gt;组件用于列表匹配，从上到下依次匹配，直到匹配成功退出。\n每个\u0026lt;Router\u0026gt;有三个参数，分别是：component, render, childern。 这三个只能出现一个。\ncomponent， 就是渲染对应的组件。 render， 是一个函数，返回一个react的组件，跟普通组件很相似，但是会很方便内联渲染和传递更多的参数。 childern， 是一个函数，返回一个组件，不像前面两个，这个无论是否匹配都会渲染这个组件。\n在上面的例子中，有使用exact修饰的path，需要完全精确匹配才会渲染对应的组件。\n嵌套的Router # 在同一个组件中，可能提供多个路由访问的内容，这个时候我们可以将路由信息嵌套起来使用。如上例中的 \u0026lt;Route path='/roster' component={Roster}/\u0026gt;， 如果我有一个路由是/roster/6， 就会去访问roster对应的组件，并在组件内继续匹配路由。\nPathparam # 在路径中中带有的参数，我们可以使用prop.match.xxx来获取，在\u0026lt;Route\u0026gt; 配置path的时候使用的是/roster/:number的形式来注册变量。\n路径中不支持GET的参数，也就是http://xxx.com?aaa=1\u0026amp;b=2, ？后面的的东西会被忽略。\nLink # 在页面中做链接，不能直接使用\u0026lt;a\u0026gt;， 这样会产生整个页面的刷新。这个包中使用\u0026lt;Link\u0026gt;组件来做，这个组件会修改浏览器的地址栏记录，产生新的页面，但是没有整个页面的刷新。\n在Link中的路径要写绝对路径，从根路径开始，不带host。\n"},{"id":27,"href":"/posts/others/raspberrypi/","title":"树莓派 - 入坑指南(1)","section":"Others","content":"我手里的是pi3。\n基础概念 # 树莓派作为一个微型电脑，基本具备冯诺依慢体系结构，其单机唯一不具备的就是硬盘，也就是我们插进去的tf卡。 除此以外，这用的是一个amd架构的处理器，所以在安装系统的时候我们需要选择支持amd架构的操作系统。\n树莓派没有开关， 换句话说，通电就是开，断电就是关。但是在关机的时候不能直接断电，要先停止操作系统才行，也就是先关机再拔电源。\n他可以做为一个性能不高的微型电脑，但是我们一般不将其作为个人电脑使用，而是用来运行一些程序使之成为实现特定功能的处理中心。 在此之前，我们要实现一个特定功能的产品或是设备，我们需要特别定制一个主控板来运行我们的程序，这些主控板具有特殊性，无法重用，并且设计成本高。 在有了这个微型电脑以后，其计算能力比一般板载处理器的性能要好，使用的是标准的冯诺依曼体系结构，使用的操作系统也以linux为主，因此可以运行几乎所有程序。 是一个低成本，可复用，灵活的硬件设备。同时其集成的网络模块、蓝牙模块，等，更适合改造成一个物联网设备的控制核心，对于实验和创新实践非常适合。\n安装操作系统 # 如果你不需要界面，可以安装Ubuntu Core。如果你需要界面，可以安装Ubuntu Mate。\n因为这两种都是linux系列的操作系统，我使用起来比较顺手，所以没有使用官方的那个系统。不过这都不重要。\n在安装Ubuntu Core这里有详细的安装过程。 如果你是ubuntu用户的话，下载下来镜像文件，直接右击用Disk manager writer 打开就可以写入TF卡，就算是安装好了。\n开机 # 安装好系统就装到板子上，然后通电。 这个时候你可能需要先接一个键盘和显示器， 因为等一下有直接操作的部分。\n开机后会正常的加载操作系统，随后会出现让你连接网络的部分。 你可以用有线连接，也可以开无线，不过我的板子开无线开不开，所以只能先用有线网。\n随后就会开机成功，让你用ubuntu one的帐号登录。 集体操作过程在上面的页面中有：\n申请帐号 将你的电脑的ssh key上传到ubuntu one网站上 在树莓派上验证帐号。 验证成功。 此时树莓派会给你他的内网地址和帐号，你用你的电脑远程登录就可以了。\n吐槽 # 就这一点， 我第一次拿到树莓派以后捣鼓了30多小时。\n这个过程会出现：\n内存卡写入系统树莓派加载不了，重新写。 不知道什么问题加载到一半卡住不动，重新写。 打开了错误关机，损坏数据，重写。 无线模块打不开，找网线。 。。。。 随后你获得的是通往新Ubuntu的大门。\nUbuntu Core是一个更新概念的操作系统组成方式。其系统本身跨平台，其应用打包方式跨平台，也就是snap。 既然你有意接触了新的事物，就别眷恋过往，勇敢的尝试新的东西，什么学习曲线陡峭，都不是问题。\n"},{"id":28,"href":"/posts/web/react-1/","title":"使用react开发的优秀实践","section":"Web","content":"如果想用react开发功能丰富，易于代码管理，易于扩展维护的项目，我们最好使用react的一整个体系。当然你单独使用react的部分也是可以的，写一些简单的应用也非常方便，没有必要把这个体系用上。\n这篇文章作为入门的一篇略深一些的介绍，在全面学习之前我们至少要知道我们学的每个部分是做什么，为什么要在这里用这个。所以本文不讲一些代码的细节，而是从整体上把握这个技术栈，帮助你快速理解整个体系。\n总结 # 一个比较好的实践是使用: react + redux + router, 来实现复杂的应用。 其中， react 承担了前端渲染控制的功能，redux承担了数据流转的控制功能，router则实现了路由控制的功能。\n这三项，基本上可以保证我们做出的项目，结构清晰，易于维护。 在初学这写东西的时候，可能会觉得比较痛苦，因为你需要记住太多的东西和条条框框来开发，这好像限制了你的自由发挥，但是对于一个大型应用来说，或者即便是小应用，没有清晰的结构，就连你自己可能都看不懂自己的代码，后期维护的时候就基本上没有多少好体验了。\n真正优秀的作品，都是在严格的限制下完成的，因为人的思维不应该去思考那些复杂的页面组成的逻辑关系，而是在实现自己的业务逻辑和计算算法上，那些结构，按照一个科学的方式来做就好。而react正是提供了这样一个科学的流程和方式。\nreact # 总的来说，在前端渲染方面，react非常出众， 一般我们将前端渲染的部分交给react来做。 react使用虚拟DOM的方式，来管理渲染。并且将一个页面分成多个组件进行管理，我们一般将组件按功能分开。当页面发生变化的时候，由react来决定哪里需要渲染，哪里不动，react来操纵浏览器的渲染。 与jQuery相比，更进一步， jQuery是将浏览器的一些操作封装出来，提供一组新的调用函数。但是react已经将浏览器的相关接口完全封装，并且屏蔽在react内部，提供了一种更自然和智能的方式来满足我们的需求。我们直接和react打交道，剩余的事情由react去和浏览器做。\nreact这个框架可以运行在浏览器端，也可以运行在服务器端， 我们称之为Universal渲染，这里的服务器端，就是Nodejs的平台了。我用的基本上都是浏览器端运行。只要将react的脚本发送到浏览器进行执行就可以了。 初的渲染是后端的事情，有了ajax后前端也可以进行渲染了。但是前端渲染会有个问题，就是搜索引擎不友好，因为搜索引擎并不会去跟js代码交互，只会爬取静态页面，所以使用后端渲染十分重要。这关乎你的网站被检索到的可能性。\n基本构造 # react的逻辑很简单，一切都是组件。一个页面是由多个组件堆砌而成，每个组件之间互相隔离，仅通过数据交互，而数据交互的接口是固定的。所以对于一个组件内部来说，与外界是完全隔离的。 一个组件包括，样式和数据。数据我们通过请求服务器去获得。 每个组件通过提供一个render函数来返回这个组件，这个render函数只能返回一个元素。如果有多个元素需要被包起来成为一个元素返回。 组件之间可以是嵌套关系，这个和类的概念有点像，在一个类中可以包含另一个类作为自己的成员。也就是方便我们做组件封装，功能划分。\n当我们写完一个react应用后，可以通过npm start的方式启动起来，当我们在浏览器访问对应的地址时，默认访问index.js, 所以我们的应用最终在这里组织起来。\nES6 \u0026amp; Javascript \u0026amp; JSX # 在写应用的时候，我们使用JSX 语法来写，JSX以ES6为基础，react提供了JSX解释器。在写完以后，JSX语法的代码会被编译成JS代码，最终在浏览器中运行的是Javascript的代码，关于webpack等工具，我暂时没有去学习，因为react提供了一个创建react应用的脚本，能够一键创建好这些配置文件，所以我就暂时直接使用了。\nnpm install --global create-react-app\n这个命令就可以安装这个脚本，然后我们执行： create-react-app myapp, 就可以创建一个文件夹， 里面已经配置了一个简单的react应用。 然后我们进入这个文件夹，使用npm start就可以启动服务。 start的过程中，代码就会被编译，并打包成webpack中配置的打包形式。\n如果此时我们改变代码，这个页面会动态更新。\nreact 原生的数据控制 # 在react中，数据主要有三个载体，分别是state、prop、context。其中state是组件内部状态数据，prop用于层层传递，context可以跨层传递。\nreact要实现各个组件独立，并且具有统一的结构，最重要的就是控制数据。在JS这种弱类型的语言中，这一点很好实现，重点就是设计一个接口形式。 react中的组件，都有两个变量，一个是prop， 一个是state。 其中，state是描述组件内部数据的，prop是对外的接口。也就是说，别人传过来的数据，会存在prop中。同时，prop是不可变的，组件自己不能更改prop的值， 只能改变state的值。\n这种数据控制的方式，比较原始，从接口统一的角度来看挺好的，也符合基本的思维方式。 但是这种控制方式也存在很多问题，不用去深究这个框架的细节，我们也可以提出很多问题：\n每个组件之间的数据冗余问题，很多数据统计的模块，该怎么存储数据？ 复制一份出来？当要更改数据的时候，是不是还要传参给另一个组件通知他改变数据？\n因此这样的数据控制肯定会让程序员自己想办法去解决，这样的解决方式很多，所以就会出现大家都用react，但是写出来的东西互相看不太懂。redux就是在这样的情况下，提供了一个统一的方式。\nredux # redux 对于数据做了如下的限制：\n数据源唯一 状态只读 数据改变只能通过纯函数完成 数据源唯一 唯一的数据源，是指所有的数据都存在一个地方Store，由redux做分发，这个数据呈树形分布。 状态只读 状态不能被更改，你需要有个接口，来返回新的数据，redux会自己将数据覆盖上去。 只能通过纯函数该变数据 所谓的纯函数就是指函数的输出完全取决于输入，没有其他的因素。\n在redux的限制下，在我们的流程中，需要多几个部分，来实现这个流程。\nStore # 这就是存放数据的地方，这是一个类。 其是数据中心，同样，也应该是各个部分联系的中，应用的变化，就体现在数据的变化上，所以store将其余的部分连接在一起了。\n一个Store中，定义了能够更新其数据的reducer，数据的初始值， 还有一些中间件。\n在每个组件中, 我们都可以通过dispatch函数，来触发相应的reducer去更新数据。当数据被更新的时候，Store会自动通知相应的组件去更新页面。\naction # 这是一个动作，准确来说，用来描述一个动作。一个action返回一个数据集， 这些数据描述了一个动作，随后这个动作会被分发给对应的reducer去产生新的数据。这样新的数据就会被redux得到并更新原有的数据。\n每个action都有一个字段叫type， 一般是个字符串，用来区分不同的action，同时其也是reducer针对不同action做不同操作的标志。action中定义的数据，我们可以理解为前端产生的数据，然后作为参数传给reducer。\nreducer # 同时传给reducer的还有当前该组件中的state。这两个参数作为输入，返回新的state作为输出。这就是reducer的作用。\nreact 和redux # 上面讲的是每个各自的一些东西，二者并不是必须同时使用的，都是可以分开使用的，redux只是一个数据控制方式，react只是一种前端渲染的方式。二者都可以被替代。\n在我们结合使用的过程中，react主要负责的就是渲染，redux就是负责组织数据，我们一般用的是react-redux。 这是专为react封装的一个redux库。\nrouter # 路由一样也可以与上面二者结合，可能更独立一些，因为router是作为一种组件的角色在其中出现。在其内部定义了路由匹配规则，如果你知道django的路由规则，router与之是一样的。\n真的总结 # 学习框架技术，在一定意义上，是学习一种思维方式，学会了思维的方式，剩余的就简单了。 接下来会写一些具体的技术细节， 以及各个库之间的联系，配合使用等。\nredux在后来的实践中太过繁琐，逐渐被mobx取代。\n"},{"id":29,"href":"/posts/self/self-1/","title":"阶段性总结","section":"Self","content":"从九月以来，我做的事情和状态在这里总结一下。\n值得xx的事 # 九月份我忘记了我在做一个什么事情，好像是一个项目。\n我从阿里回来苏州以后，先是5号要考科目三，于是就练车到了5号。 在5号过后，我在准备保研的事情，打印材料，复习一下C语言。这期间看了一多半的《C和指针》。然后貌似我还看了一个什么的文档，记不起来了，我操这记忆力。\n保研是在什么时候，貌似是在18号。然后就是等待结果。 我当时确实在忙一个什么东西。 然而找了半天并没有找到什么记录，我草，可能是被续掉了吧。害怕害怕。。。\n然后去了一趟北京，回来了。然后打打网络赛，然后收拾心情回家过了个国庆。 从国庆回来，然后开始尝试Node， react，做兼职。一直到去沈阳比赛。在沈阳打了个金牌回来，心情还不错。 去沈阳比赛回来就接了NOIP讲课的锅，到了现在。\n总之，这两个月过的异常的快，而且也异常的忙。突然从实习生回到学校里，没有了主业，也没有了方向。然后又突然从中科院的研究生回到了苏大的研究生，整个心境也就不一样了。\n这是一段心态转变的时间。之前总是有一点毕业生的感觉，所以做事的效率非常的额低，一点都没有实习工作时候的那种紧迫。过了几天好日子。休息够了，也给了自己一个大坑。整个人都清醒了起来。\n接下来要做的事情 # 这个接下来应该有长期有短期。\n短期来看 # 最近15天，我需要做的是NOIP和React并行，暂且将一些系统瞎搞的事情放一下。 然后OJ也要能运行，让对接的老师来尝试。\n再稍微长一点，可以借助这次NOIP的机会调整一下自己竞赛的思路，重新规划一下自己的知识点。重点转移到看白书上来，要形成一点章法。\n中期来看 # 最近三个月我的主要精力还是两个方面，一个是竞赛，一个是react和python的兼职。 两个的量都不小，我的键盘灵敏度也被我调的非常高，这样可以在一定程度上督促自己加快速度，保持兴奋。\n对于react和py，都需要系统一点的来搞。就以这个项目为基础吧。\n除了主流的技术，还有一些顺带的技术流： Git，Github，Node。\n长期一点 # 在上面两个能够处理好的情况下，继续处理一点系统的工作工具。\n这个真的很麻烦。\n待续\u0026hellip; # "},{"id":30,"href":"/posts/web/es6/","title":"ES 6","section":"Web","content":" 历史 # ECMA是个组织，国际标准化组织。 Javascript诞生于1996年，比我略小9个月。由Netscape公司研发，也就是曾经的网景公司。 次年开源交付给ECMA组织进行标准化，力图打造一个国际通用的语言。随后，ECMA发布了国际浏览器脚本语言标准，名称为ECMAScript，实际上就是Javascript的国际标准版。 由于商标等多种原因，名称为ECMAscript，而不是javascript，但我们基本上认为是一个东西。\n前者是标准，后者是标准下的实现。\n标准是个啥 # 所谓的语言标准，每个语言都有。 在语言不断发展的过程中，会给语言添加一些语法特性，比如以前js是不支持class的，在ES6的标准中就支持啦。\n这些标准每年都会变化，不断的有人提案新的语法特性，经由审核实现后发布。\nES6的发布有什么好处？ # 让js真正成为一个可以开发大型应用的语言。 不面向对象的程序设计，在开发逻辑复杂的大型企业级应用的时候非常鸡肋，超高的开发周期和人力投入，复杂的耦合关系，而且极难进行维护。 ES6引入了很多的面向对象的语法，以及函数编程的内容，使得js可以hold住大型开发的复杂度。\n但是ES6的class在ES5的时候就是可以实现的，只是语法上很别扭，跟传统的面向对象的语法差异很大，让人学起来很懵逼。\n语法细节 # 在细节的内容，推荐一个开源的书，所谓开源的书，就是有电子版的网站可以看，印刷版的要买。\n详细参考\n"},{"id":31,"href":"/posts/acm/cf855-c/","title":"Codeforces 855-C 树形DP","section":"Acm","content":" 题意 # 给一颗树， 每个结点可以标记一个type。 一共有m种type，分别是1-m。 其中有一种特殊的type，编号为k，要求：\n在这棵树中，最多出现x个type为k的点。 每个type为k的点，其相邻的点type必须小于k。 问，给定以上数据，求树的标记种类数有多少。\n数据范围： n \u0026lt;= 1e5, x \u0026lt;=10, m \u0026lt;=1e9\n分析 # 这是一个典型的树形DP，DP的维度应该至少是3维。\nDp[i][j][z] 表示： 以i为根的子树，用掉z个k时的种类数。 其中对于根结点的type选取，分三种情况，\n0：type \u0026lt; k (type \u0026gt;=1 ) 1：type = k 2：type \u0026gt; k (type \u0026lt;= m) Dp表示内容确定以后，就要来找转移方程了。 这种组合种类的问题，只要分清楚哪些量之间是相乘的关系，哪些量是相加的关系就好办了。\n思考一种普遍的情况，对于一个根节点和其儿子节点之间的关系，以及儿子之间的关系。 可以确定的是，各个儿子之间的关系是相乘的关系。因为儿子之间是没有约束的，不直接相连就没有type \u0026lt; k的约束。所以每个子树内的排列种类是直接乘到贡献中的。\n然后就是儿子与父亲节点的关系。 讨论一下，如果父亲的取值是0类型，也就是type \u0026lt; k。 对于任何一个儿子都可以任意选择type，并且这些选择之间是相加的关系。选择之和与父亲的选择种类之间是相乘关系。\n总上，父亲与儿子、儿子与儿子之间都是相乘的关系，儿子内部是相加关系。\n这个时候我们可以选择将父亲先放在一边，先合并各个儿子。最后把合并后的儿子与父亲合并。\n为什么不能直接把儿子合并到父亲上呢？\n因为对于一个固定的z来说，其对应的情况是z个k在所有子树中的全排列种情况。这些排列又是相加的关系，很显然我们不能去求这个排列，复杂度太大。\n我们要在处理每个儿子的时候，将其对不同的z的贡献都存起来，这个我们可以做到。\n以下的代码以根为0时举例，其他两个情况一样。\nfor(int j=0; j\u0026lt;=x ;j++){ for(int z = 0; z \u0026lt;= x; z++){ if(l+z \u0026gt; x) continue; Dp[u][0][j+z] += ta[0][j] * (Dp[v][0][z] + Dp[v][1][z] + Dp[v][2][z]); } } ta[0][j] 记录的是在当前儿子之前的所有儿子中，使用了j个k时，所有的种类数。 其中，Dp[u][0][j+z] 记录的是对于当前儿子结点v，使用了j+z 个k时，所有的种类数。\n在每次处理完一个儿子以后，就将ta数组更新一下。并将Dp[u]\u0026hellip;清空。\n最后再将结果和根结点合并。这个合并就比较简单了。\n附上代码： # #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; const int MAXN = 100005; const long long MOD = 1000000007; int cnt = 0, head[MAXN]; int n, m, k, x; typedef long long ll; ll Dp[MAXN][3][15], ta[3][15]; struct Edge{ int u, v, nxt; }edge[MAXN\u0026lt;\u0026lt;2]; void init(){ cnt = 0; memset(head, -1, sizeof(head)); } void add(int u, int v){ edge[cnt].u = u; edge[cnt].v = v; edge[cnt].nxt = head[u]; head[u] = cnt++; } void Dfs(int u, int pre){ int hasSon = 0; for(int i = head[u]; i!=-1; i = edge[i].nxt ){ int v = edge[i].v; if(v == pre) continue; hasSon = 1; Dfs(v, u); } if( !hasSon ) { Dp[u][0][0] = 1ll*k-1; Dp[u][1][1] = 1ll; Dp[u][2][0] = 1ll*m-k; return ; } memset(ta, 0, sizeof(ta)); ta[0][0] = ta[1][0] = ta[2][0] = 1ll; for(int j = 0; j\u0026lt;=x ; j++){ Dp[u][0][j] = Dp[u][1][j] = Dp[u][2][j] = 0; } for(int i = head[u]; i != -1 ; i = edge[i].nxt){ int v = edge[i].v; if(v == pre) continue; for(int j = 0; j \u0026lt;= x; j++ ){ for(int z = 0; z \u0026lt;= x; z++){ if(j+z\u0026gt;x) continue; Dp[u][0][j+z] += ta[0][j] * ( Dp[v][0][z] + Dp[v][1][z] + Dp[v][2][z] ) %MOD; Dp[u][1][j+z] += ta[1][j] * Dp[v][0][z] %MOD; Dp[u][2][j+z] += ta[2][j] * ( Dp[v][0][z] + Dp[v][2][z] ) %MOD; } } for(int j = 0; j \u0026lt;=x; j++) { ta[0][j] = Dp[u][0][j]%MOD; ta[1][j] = Dp[u][1][j]%MOD; ta[2][j] = Dp[u][2][j]%MOD; Dp[u][0][j] = 0; Dp[u][1][j] = 0; Dp[u][2][j] = 0; } } for(int i=0;i\u0026lt;=x; i++){ Dp[u][0][i] = 1ll*(k-1)*ta[0][i]%MOD; if(i\u0026gt;0) Dp[u][1][i] = 1ll*ta[1][i-1]%MOD; Dp[u][2][i] = 1ll*(m-k)*ta[2][i]%MOD; } } int main(){ init(); cin \u0026gt;\u0026gt; n \u0026gt;\u0026gt; m; int u, v; for(int i=1;i\u0026lt;n;i++){ cin \u0026gt;\u0026gt; u \u0026gt;\u0026gt; v; add(u, v); add(v, u); } cin \u0026gt;\u0026gt; k \u0026gt;\u0026gt; x; memset(Dp, 0, sizeof(Dp)); Dfs(1, 0); ll ans = 0; for(int i=0;i\u0026lt;3;i++){ for(int j = 0; j \u0026lt;=x; j++) ans = (ans + Dp[1][i][j])%MOD; } printf(\u0026#34;%lld\\n\u0026#34;, ans%MOD); return 0; } "},{"id":32,"href":"/posts/c++/effectivec-1/","title":"Effective C++ 读书笔记","section":"C","content":"从北京回来，决定花三天时间把这本书看掉。有两个原因，第一个是我希望主要精通的语言还是选择C++，因为其功能强大，且速度快；优秀的程序员就应该精通C++才可以。其次是在即将要学习的机器学习和深度学习的领域中，C++是后期算法工程化的重要一环。\n如果是看完这本书，我觉得三天就够了。如果是精研每个细节就要花个一周了，我决定先快速的get到重点的内容，在接下来写代码的过程中再实践出来。\n本书架构 # 这本书被冠以盛名，源自于其内容的独特性、优质性。 书中不是详细介绍C++的各种特性，而是从大量的工程经验中思考c++编写代码的优秀习惯。\n本书全局来看，由55条准则构成。这55条准则被由浅入深的分成了8个模块，还有一个杂项模块作为第9个模块。 下面我就这些准则和书中的内容做个整理。\n1. 让自己习惯C++ # View C++ as a federation of languages # C++ 今天已经是一个多重范型编程语言，同时支持过程形式、面向对象形式、函数形式、泛型形式、元编程形式的语言。 因此这是一个语言的联邦，几乎各种语言的编程模式都可以在C++中得到体现。 最主要的是，做到这些并且保持着速度。\nPrefer const, enum, inline to #define # 主要就是讲了#define的种种缺点。 从我自身的使用上来说，简短的单文件程序中，使用define还是可以的，但是看别人的代码中就非常的困难了。因此我自己也是不倾向于使用define来定义一些东西。\n常量： 对于常量我们可以使用const来定义，而不是使用define。这样不仅安全，而且编译后的代码更少。 define的一个比较严重的问题就是作用域的问题，其并不重视作用域，在编译的时候，对此后的内容均有效，除非遇到undefine。但是一个常量是可以有作用域的限制的。 除了使用const还可以用enum来定义一个常量，\nclass Game{ private: enum{ NumTurns=5 }; } 这样就定义了一个5的代名词，但是并不会被取到地址，也不会被改变。如果使用者企图调用这个的地址会在编译时就被报错，而不是像const那样在运行时报错出来。\n函数 很多人会define一个小函数，来达到函数的作用又减小了函数调用的开销。但是这样写，一个是不直观，容易错；还有就是括号要很多，也容易出错。用inline是一样的效果。\nUse const whenever possible # 关于const的语法的细节，可以参考之前的相关的内容。 使用const可以避免很多错误，与上面一样，这些错误很可能会发生在运行时。但是如果你适当的用了const，就会在编译的时候被避免。\nCLASS a, b ,c; if( a*b = c) 内置类型会编译报错没有问题，但是对于自定义的类型，就会出现意想不到的错误。\n确保使用的变量都被初始化了 # 这里有一个很有趣的东西，叫做冒号表达式，没错，就是那个冒号表达式。与一般的赋值初始化不同的是，冒号表达式更快速。\nclass A{ Som a, b; A(Som _a, Som _b){ a = _a; b = _b; } A(Som _a, Som _b):a(_a), b(_b){} } 对于第一种写法，需要先调用每个类的默认构造函数，随后进行复值。但是默认构造函数就浪费了。 对于第二种，直接调用其copy构造函数，所以更快。\n然后书中讨论了初始化顺序的问题，在类中的成员是严格按照其定义的顺序进行初始化的，即使你在初始化序列中写的顺序与定义顺序不一致也没有关系。 但是在一些全局的non-local static 变量中，其初始化的顺序是绝对不可预知的，也就是一些你定义在全局，namespace中的静态变量，其初始化的顺序是完全不确定的。 这会引发严重的灾难，会导致你使用到没有初始化的对象。 解决的办法就是不用non-local static变量。将这些变量的定义转移到函数中去，你甚至可以专门写一个函数用来给这个变量初始化，可以保证的是，函数在没有被调用的时候是不会被初始化的，并且在首次调用的时候一定会初始化。这样就可以保证得到的对象是经过初始化的了。 这样做的后果，突出的就是表现为使用函数来访问一个静态变量而原来是直接用变量本身访问。\nConstructs, Destructors, and Assignment Operators # Know what functions C++ silently writes and calls # 编译器会帮你写哪些函数：\nclass Empty{ public : Empty(){} Empty(const Empty\u0026amp; rhs){} ~Empty(){} Empty\u0026amp; operator=(const Empty\u0026amp; rhs){} } 上面这四个函数是默认的，但是如果你写了一个构造函数以后，这个默认的构造函数就不会帮你写了，需要你自己写默认构造。\nExolicitly disallow the use of compiler-generated function you do not want. # 如何避免编译器帮你自动生成一些你不想要的函数，自己声明一个，不要定义，然后private起来。\nDeclare destructors virtual in polymorphic base classes. # 这是因为会产生局部销毁的后果而出现内存泄漏。\n这是因为，在多态继承的类中，我们可以用一个基类的指针来操作一个子类，当我要进行析构的时候，我们会delete pt (pt is a pointer to base class)， 但是如果基类不是个虚函数的析构函数，就会造成局部的析构，产生内存泄漏。\n如果你的类是个多态基类，就要有个virtual的析构函数，否则不要生命析构函数。\nPrevent exception from leaving destructors. # 对于一个C++程序来说，如果有两个异常同时报出来就有可能导致程序发生不明确的行为或是终止，因此，我们一定要捕获这样的异常。 如果在析构函数中产生了一个异常，这非常的尴尬，因为用户无法获知这个问题，从而无法处理，并且导致未明确的行为。 一个比较好的设计就是将可能出现一场的操作放到一个函数中，让用户显示的可以调用并处理异常，同时在析构函数中检验是否已经处理完，如果此时没有处理，只好在析构函数中调用这个函数并吞下这个异常。\nNever call virtual function during construction or destruction # 因为基类的初始化的问题，在初始化的时候，虚函数可能还没有定义，因此是不会被调用到子类的函数中的。\n让赋值操作符返回一个*this 的引用 # 在operator= 中处理自我赋值 # 在赋值的时候很容易会出现赋值给自己的请况，此时请注意在赋值的时候处理好释放空间的时机，以保证不会出现野指针等问题。\nCopy all parts of an object # 在复制一个对象的时候，要保证复制了每一个对像并调用了每个成员的该调用的函数。\nResource Management # 程序使用了一些资源，在不用的时候要及时的还给系统，这些资源包括：内存、文件描述器、互斥锁、图形界面的字形、笔刷、数据库链接、sockets等。\nUse object to manage resources # 这个习惯要求我们把释放资源的任务交给析构函数来做，这样当对象析构的时候自动释放资源。此外，文中提到使用auto_ptr智能指针。 智能指针保证只有一个智能指针指向一个资源，在赋值发生的时候，原指针会被置为空。 使用智能指针是为了防止你多个指针指向一个对象的时候，被其中一个释放，随后其他指针就变成了野指针。\n在资源管理类中小心copy行为 # "},{"id":33,"href":"/posts/self/myheart/","title":"一个决定","section":"Self","content":"终于我还是follow my heart.\n今天下午，我找了我的准未来导师\u0026ndash;刘偲老师，简单的聊了一下。然后，我决定不留在这里\u0026ndash;中国科学院信息工程研究所。\n推免的面试，各个学校基本接近尾声，没有什么机会去别的学校再试试，我选择留在苏州大学NLP组。\n当张民老师问我为什么的时候，让我说出两个不留在研究所的理由。我脑子里只有一个，我不喜欢这里。\n这是一个很重要的决定，对任何人来说。并且对很多人来说，我的这个决定都是脑子进水了。\n计算机是我的爱好 # 上半年选择学校的时候，我就没想去投学校，直接投了研究所。 我希望自己的研究生生活能够花的有意义，去学习更多的更深的东西，虽然我也知道全是靠自己，但是可能研究所的人更靠谱吧。我希望研究所的高要求能让我更有压力不去浪费时间。\n做自己喜欢的事，是人生最幸运的事，我很幸运。 其实无论在哪里，自律都是第一要素，我不该去利用其他人的要求去压制自己的懒惰，我应该从自己的性格中剔除懒惰，才能持续发展。\n我生命中有一个很重要的人，一个让我钦佩的，活生生的人\u0026ndash;张冉，我的初中同学都了解那是怎样的人。平台从来不是限制他的因素，够优秀，并且足够自信自己会优秀。我没有他那么厉害，但我觉得在自己喜欢的事业上，我可以做到。\n我需要一个环境 # 来到研究所两天，我很不适应。环境真的不容乐观，北京又在严打，各类餐馆被关停，吃的很差，住的地方也出了点问题，交通也很不方便，工位的空调也很不好，泰坦显卡的发热量又很大，我几乎隔20分钟就要洗一次脸才能静下来，耳机已经完全不管用了。 很多人会觉得怎么这么矫情，如果在以前，这绝不会让我选择离开。 我很不喜欢这个环境，不适合我静下来做事情。 对于编程和算法这类工作来说，环境是最重要的基础。在理工楼101，我可以从早上11点坐到凌晨3点去写代码。也不会有人来打扰我。（要跟女朋友道歉，来找我还会被我凶）\n在来这里之前，我觉得中科院的环境应该非常好吧，毕竟是国家重点实验室。 但是很不幸，我还是太天真了。学生的生存条件并没有那么得到重视，我以为这里应该以人为本，本来就没有多少人，就更该把环境搞好才行吧。我的师兄们只好每人一个风扇，甚至两个，一个给机器一个给自己。 从他们跟我聊天的语气中，我听到很无奈，习惯就好。我也很佩服他们，环境这么差，还要做很多工作。\n在这样的环境，我很难保证自己的情绪不会影响自己做事情，所以我要慎重的考虑这个因素。\n我很担心未来三年的处境 # 在一开始，导师跟我提出几点要求：\n要花时间。 要服从安排。 在信工所的两天里，我看到的这些人，都很苦恼，一点都不快乐。 选择来这样的地方不该是非常喜欢这份事业的吗？这样的样子很奇怪。 花时间，对我来说，时间除了睡觉，就是在电脑前面了。不成问题。 但是服从安排，我就很没底了。毕竟听到很多人都说自己的导师如何压榨自己。 同时我又从师兄那里听到些不太好的东西。\n对于我来说，我比较耿直，这些事情，对我来说很重要。 如果因为某些事情让我做东西很不开心，我绝对做不好，并且还浪费大量的时间。 听说有一个很厉害的师兄因为跟老师在一些任务上搞的不愉快被外派到其他学校交流去了。\n我想，如果有这样的事情，我应该也会闹的不愉快吧。 我怀着对技术的赤诚，不想成为廉价的劳动力。\n血里有风 # 我要的是自由的精神。\n来过北京几次，我从未喜欢过这里。用今天认识的人的话说，对他来说，这里没有任何生活的气息。 这里是政治中心，在中国，我永远不想沾边的东西。 这里是经济中心，在这里，少有真诚。 \u0026hellip;\n人生很短暂，三年很漫长。 做技术的人，应该都是我这样子。不耻那些偷奸耍滑，不屑那些争名夺利，用自己的能力换取自己应得的那份。 世界虽然很复杂，很坏。 但是我终将面对的，是我自己。并且实时面对的，也都是我自己。 活着，不为谁，为了自己开心。仅此而已。\n在苏大会不甘心吗？ # 并不会。 其实我选择的是张民老师和苏州。\n跟张民老师有很多接触，这个被苏大挖过来的NLP国内前沿学者，带着苏大的NLP排进了前5名。为人非常直接，可能是因为工作太多的缘故，惜时如金，绝不废话。 在我找他的时候，再三跟我说，你要考虑清楚，中科院的研究生跟苏大的研究生含金量不一样的，苏大保一个中科院非常难的，你有这个机会千万别傻。\n刘偲老师也是CV圈比较厉害的，张民老师也是NLP圈很顶尖的。在这一维度，其实并没有什么区别，学校虽然差异很大，但是我毕业以后只能靠自己的能力。\n所以关键是我自己，我愿意用三年的时间，在苏州学习，而不是北京。\n人生是自己的，我应该为自己负责。\n"},{"id":34,"href":"/posts/bash/awk/","title":"awk - Linux文本处理大杀器","section":"Bash","content":"awk 已经不是一种命令了，而是一种语言。用于在linux/unix下对文本和数据进行处理。数据可以来自标准输入(stdin)、一个或多个文件，或其它命令的输出。\n在最开始，我的文本处理方式就是写一个c语言去读文件然后在处理完输出来。刚开始学程序的时候觉得自己很厉害的样子。这样做过几次以后就发现并没有这么好用，因为每次都要写一个很麻烦。\n在后来就是学习用脚本来处理。\n关于Linux命令，推荐一个小站点，写的东西都还非常细致。\n命令形式 # awk [options] \u0026#39;script\u0026#39; var=value file(s) awk [options] -f scriptfile var=value file(s) 命令选项\n-F fs fs指定输入分隔符，fs可以是字符串或正则表达式，如-F: -v var=value 赋值一个用户定义变量，将外部变量传递给awk脚本 -f scripfile 从脚本文件中读取awk命令 脚本模式和操作 # awk的脚本主要由模式和操作组成：\n模式 # /正则表达式/：使用通配符的扩展集。 关系表达式：使用运算符进行操作，可以是字符串或数字的比较测试。 模式匹配表达式：用运算符~（匹配）和~!（不匹配）。 BEGIN语句块、pattern语句块、END语句块 操作 # 操作由一个或多个命令、函数、表达式组成，之间由换行符或分号隔开，并位于大括号内，主要部分是：\n变量或数组赋值 输出命令 内置函数 控制流语句 awk脚本的基本结构 # awk \u0026#39;BEGIN{ print \u0026#34;start\u0026#34; } pattern{ commands } END{ print \u0026#34;end\u0026#34; }\u0026#39; file 一个awk脚本通常由：BEGIN语句块、能够使用模式匹配的通用语句块、END语句块3部分组成，这三个部分是可选的。任意一个部分都可以不出现在脚本中，脚本通常是被单引号或双引号中，例如：\nawk \u0026#39;BEGIN{ i=0 } { i++ } END{ print i }\u0026#39; filename awk \u0026#34;BEGIN{ i=0 } { i++ } END{ print i }\u0026#34; filename 工作原理 # 第一步：执行BEGIN{ commands }语句块中的语句； 第二步：从文件或标准输入(stdin)读取一行，然后执行pattern{ commands }语句块，它逐行扫描文件，从第一行到最后一行重复这个过程，直到文件全部被读取完毕 第三步：当读至输入流末尾时，执行END{ commands }语句块。 BEGIN语句块 在awk开始从输入流中读取行之前被执行，这是一个可选的语句块，比如变量初始化、打印输出表格的表头等语句通常可以写在BEGIN语句块中。 END语句块 在awk从输入流中读取完所有的行之后即被执行，比如打印所有行的分析结果这类信息汇总都是在END语句块中完成，它也是一个可选语句块。 pattern语句块 中的通用命令是最重要的部分，它也是可选的。如果没有提供pattern语句块，则默认执行{ print }，即打印每一个读取到的行，awk读取的每一行都会执行该语句块。\nprint # 当使用不带参数的print时，它就打印当前行，当print的参数是以逗号进行分隔时，打印时则以空格作为定界符。在awk的print语句块中双引号是被当作拼接符使用，例如：\necho | awk \u0026#39;{ var1=\u0026#34;v1\u0026#34;; var2=\u0026#34;v2\u0026#34;; var3=\u0026#34;v3\u0026#34;; print var1,var2,var3; }\u0026#39; # out: v1 v2 v3 双引号：\necho | awk \u0026#39;{ var1=\u0026#34;v1\u0026#34;; var2=\u0026#34;v2\u0026#34;; var3=\u0026#34;v3\u0026#34;; print var1\u0026#34;=\u0026#34;var2\u0026#34;=\u0026#34;var3; }\u0026#39; # out: v1=v2=v3 awk 内置变量 # 说明： [A][N][P][G]表示第一个支持变量的工具，[A]=awk、[N]=nawk、[P]=POSIXawk、[G]=gawk\n$n 当前记录的第n个字段，比如n为1表示第一个字段，n为2表示第二个字段。 $0 这个变量包含执行过程中当前行的文本内容。 [N] ARGC 命令行参数的数目。 [G] ARGIND 命令行中当前文件的位置（从0开始算）。 [N] ARGV 包含命令行参数的数组。 [G] CONVFMT 数字转换格式（默认值为%.6g）。 [P] ENVIRON 环境变量关联数组。 [N] ERRNO 最后一个系统错误的描述。 [G] FIELDWIDTHS 字段宽度列表（用空格键分隔）。 [A] FILENAME 当前输入文件的名。 [P] FNR 同NR，但相对于当前文件。 [A] FS 字段分隔符（默认是任何空格）。 [G] IGNORECASE 如果为真，则进行忽略大小写的匹配。 [A] NF 表示字段数，在执行过程中对应于当前的字段数。 [A] NR 表示记录数，在执行过程中对应于当前的行号。 [A] OFMT 数字的输出格式（默认值是%.6g）。 [A] OFS 输出字段分隔符（默认值是一个空格）。 [A] ORS 输出记录分隔符（默认值是一个换行符）。 [A] RS 记录分隔符（默认是一个换行符）。 [N] RSTART 由match函数所匹配的字符串的第一个位置。 [N] RLENGTH 由match函数所匹配的字符串的长度。 [N] SUBSEP 数组下标分隔符（默认值是34）。 示例\necho -e \u0026#34;line1 f2 f3\\nline2 f4 f5\\nline3 f6 f7\u0026#34; | awk \u0026#39;{print \u0026#34;Line No:\u0026#34;NR\u0026#34;, No of fields:\u0026#34;NF, \u0026#34;$0=\u0026#34;$0, \u0026#34;$1=\u0026#34;$1, \u0026#34;$2=\u0026#34;$2, \u0026#34;$3=\u0026#34;$3}\u0026#39; # out: Line No:1, No of fields:3 $0=line1 f2 f3 $1=line1 $2=f2 $3=f3 Line No:2, No of fields:3 $0=line2 f4 f5 $1=line2 $2=f4 $3=f5 Line No:3, No of fields:3 $0=line3 f6 f7 $1=line3 $2=f6 $3=f7 使用print $NF可以打印出一行中的最后一个字段，使用$(NF-1)则是打印倒数第二个字段，其他以此类推：\n统计文件中的行数：\nawk \u0026#39;END{ print NR }\u0026#39; filename 以上命令只使用了END语句块，在读入每一行的时，awk会将NR更新为对应的行号，当到达最后一行NR的值就是最后一行的行号，所以END语句块中的NR就是文件的行数。\n一个每一行中第一个字段值累加的例子：\nseq 5 | awk \u0026#39;BEGIN{ sum=0; print \u0026#34;总和：\u0026#34; } { print $1\u0026#34;+\u0026#34;; sum+=$1 } END{ print \u0026#34;等于\u0026#34;; print sum }\u0026#39; 将外部变量值传递给awk # 借助-v选项，可以将外部值（并非来自stdin）传递给awk：(在bash脚本中这样写)\nVAR=10000 echo | awk -v VARIABLE=$VAR \u0026#39;{ print VARIABLE }\u0026#39; another\nvar1=\u0026#34;aaa\u0026#34; var2=\u0026#34;bbb\u0026#34; echo | awk \u0026#39;{ print v1,v2 }\u0026#39; v1=$var1 v2=$var2 or\nawk \u0026#39;{ print v1,v2 }\u0026#39; v1=$var1 v2=$var2 filename 以上方法中，变量之间用空格分隔作为awk的命令行参数跟随在BEGIN、{}和END语句块之后。\n运算 # 作为一种程序设计语言所应具有的特点之一，awk支持多种运算，这些运算与C语言提供的基本相同。awk还提供了一系列内置的运算函数（如log、sqr、cos、sin等）和一些用于对字符串进行操作（运算）的函数（如length、substr等等）。这些函数的引用大大的提高了awk的运算功能。作为对条件转移指令的一部分，关系判断是每种程序设计语言都具备的功能，awk也不例外，awk中允许进行多种测试，作为样式匹配，还提供了模式匹配表达式~（匹配）和~!（不匹配）。作为对测试的一种扩充，awk也支持用逻辑运算符。\n``` awk 'BEGIN{a=\u0026quot;b\u0026quot;;print a++,++a;}' 0 2 ``` a+=5; 等价于：a=a+5; 其它同类\nawk 'BEGIN{a=1;b=2;print (a\u0026gt;5 \u0026amp;\u0026amp; b\u0026lt;=2),(a\u0026gt;5 || b\u0026lt;=2);}' 0 1 awk 'BEGIN{a=\u0026quot;100testa\u0026quot;;if(a ~ /^100*/){print \u0026quot;ok\u0026quot;;}}' ok awk 'BEGIN{a=11;if(a \u0026gt;= 9){print \u0026quot;ok\u0026quot;;}}' ok ``` awk \u0026lsquo;BEGIN{a=\u0026ldquo;b\u0026rdquo;;print a==\u0026ldquo;b\u0026rdquo;?\u0026ldquo;ok\u0026rdquo;:\u0026ldquo;err\u0026rdquo;;}\u0026rsquo; ok\nawk \u0026lsquo;BEGIN{a=\u0026ldquo;b\u0026rdquo;;arr[0]=\u0026ldquo;b\u0026rdquo;;arr[1]=\u0026ldquo;c\u0026rdquo;;print (a in arr);}\u0026rsquo; 0\nawk \u0026lsquo;BEGIN{a=\u0026ldquo;b\u0026rdquo;;arr[0]=\u0026ldquo;b\u0026rdquo;;arr[\u0026ldquo;b\u0026rdquo;]=\u0026ldquo;c\u0026rdquo;;print (a in arr);}\u0026rsquo; 1 ``` 高级输入输出 # awk中next语句使用：在循环逐行匹配，如果遇到next，就会跳过当前行，直接忽略下面语句。而进行下一行匹配。net语句一般用于多行合并：\ncat text.txt a b c d e awk \u0026#39;NR%2==1{next}{print NR,$0;}\u0026#39; text.txt 2 b 4 d 分析发现需要将包含有“web”行进行跳过，然后需要将内容与下面行合并为一行：\ncat text.txt web01[192.168.2.100] httpd ok tomcat ok sendmail ok web02[192.168.2.101] httpd ok postfix ok web03[192.168.2.102] mysqld ok httpd ok 0 awk \u0026#39;/^web/{T=$0;next;}{print T\u0026#34;:t\u0026#34;$0;}\u0026#39; test.txt web01[192.168.2.100]: httpd ok web01[192.168.2.100]: tomcat ok web01[192.168.2.100]: sendmail ok web02[192.168.2.101]: httpd ok web02[192.168.2.101]: postfix ok web03[192.168.2.102]: mysqld ok web03[192.168.2.102]: httpd ok getline # 执行linux的date命令，并通过管道输出给getline，然后再把输出赋值给自定义变量out，并打印它：\nawk \u0026#39;BEGIN{ \u0026#34;date\u0026#34; | getline out; print out }\u0026#39; 执行shell的date命令，并通过管道输出给getline，然后getline从管道中读取并将输入赋值给out，split函数把变量out转化成数组mon，然后打印数组mon的第二个元素：\nawk \u0026#39;BEGIN{ \u0026#34;date\u0026#34; | getline out; split(out,mon); print mon[2] }\u0026#39; 命令ls的输出传递给geline作为输入，循环使getline从ls的输出中读取一行，并把它打印到屏幕。\nawk \u0026#39;BEGIN{ while( \u0026#34;ls\u0026#34; | getline) print }\u0026#39; file # 输出到一个文件：\necho | awk \u0026#39;{printf(\u0026#34;hello word!n\u0026#34;) \u0026gt; \u0026#34;datafile\u0026#34;}\u0026#39; 或 echo | awk \u0026#39;{printf(\u0026#34;hello word!n\u0026#34;) \u0026gt;\u0026gt; \u0026#34;datafile\u0026#34;}\u0026#39; 关闭文件：\nclose(\u0026#34;filename\u0026#34;) 设置字段定界符 # 默认的字段定界符是空格，可以使用-F \u0026ldquo;定界符\u0026rdquo; 明确指定一个定界符：\nawk -F: \u0026#39;{ print $NF }\u0026#39; /etc/passwd 或 awk \u0026#39;BEGIN{ FS=\u0026#34;:\u0026#34; } { print $NF }\u0026#39; /etc/passwd 控制语句 # 在linux awk的while、do-while和for语句中允许使用break,continue语句来控制流程走向，也允许使用exit这样的语句来退出。break中断当前正在执行的循环并跳到循环外执行下一条语句。if 是流程选择用法。awk中，流程控制语句，语法结构，与c语言类型。有了这些语句，其实很多shell程序都可以交给awk，而且性能是非常快的。下面是各个语句用法。\n条件判断语句 # awk \u0026#39;BEGIN{ test=100; if(test\u0026gt;90){ print \u0026#34;very good\u0026#34;; } else if(test\u0026gt;60){ print \u0026#34;good\u0026#34;; } else{ print \u0026#34;no pass\u0026#34;; } }\u0026#39; very good for循环 # Type 1.\nawk \u0026#39;BEGIN{ for(k in ENVIRON){ print k\u0026#34;=\u0026#34;ENVIRON[k]; } }\u0026#39; TERM=linux G_BROKEN_FILENAMES=1 SHLVL=1 pwd=/root/text ... logname=root HOME=/root SSH_CLIENT=192.168.1.21 53087 22 Type 2.\nawk \u0026#39;BEGIN{ total=0; for(i=0;i\u0026lt;=100;i++){ total+=i; } print total; }\u0026#39; 5050 While # awk \u0026#39;BEGIN{ test=100; total=0; while(i\u0026lt;=test){ total+=i; i++; } print total; }\u0026#39; 5050 do while # awk \u0026#39;BEGIN{ total=0; i=0; do {total+=i;i++;} while(i\u0026lt;=100) print total; }\u0026#39; 5050 其他 # break 当 break 语句用于 while 或 for 语句时，导致退出程序循环。 continue 当 continue 语句用于 while 或 for 语句时，使程序循环移动到下一个迭代。 next 能能够导致读入下一个输入行，并返回到脚本的顶部。这可以避免对当前输入行执行其他的操作过程。 exit 语句使主输入循环退出并将控制转移到END,如果END存在的话。如果没有定义END规则，或在END中应用exit语句，则终止脚本的执行。 数组 # 数组是awk的灵魂，处理文本中最不能少的就是它的数组处理。因为数组索引（下标）可以是数字和字符串在awk中数组叫做关联数组(associative arrays)。awk 中的数组不必提前声明，也不必声明大小。数组元素用0或空字符串来初始化，这根据上下文而定。\n定义 # 两种方式，数字索引和字符串索引\nArray[1]=\u0026#34;sun\u0026#34; Array[2]=\u0026#34;kai\u0026#34; Array[\u0026#34;first\u0026#34;]=\u0026#34;www\u0026#34; Array[\u0026#34;last\u0026#34;]=\u0026#34;name\u0026#34; Array[\u0026#34;birth\u0026#34;]=\u0026#34;1987\u0026#34; 使用中print Array[1]会打印出sun；使用print Array[2]会打印出kai；使用print[\u0026ldquo;birth\u0026rdquo;]会得到1987。\n遍历数组 # { for(item in array) {print array[item]}; } #输出的顺序是随机的 { for(i=1;i\u0026lt;=len;i++) {print array[i]}; } #Len是数组的长度 相关操作 # length # length返回字符串以及数组长度，split进行分割字符串为数组，也会返回分割得到数组长度。\nawk \u0026#39;BEGIN{info=\u0026#34;it is a test\u0026#34;;lens=split(info,tA,\u0026#34; \u0026#34;);print length(tA),lens;}\u0026#39; 4 4 asort # asort对数组进行排序，返回数组长度。\nawk \u0026#39;BEGIN{info=\u0026#34;it is a test\u0026#34;;split(info,tA,\u0026#34; \u0026#34;);for(k in tA){print k,tA[k];}}\u0026#39; 4 test 1 it 2 is 3 a for…in输出，因为数组是关联数组，默认是无序的。所以通过for…in得到是无序的数组。如果需要得到有序数组，需要通过下标获得。\nawk \u0026#39;BEGIN{info=\u0026#34;it is a test\u0026#34;;tlen=split(info,tA,\u0026#34; \u0026#34;);for(k=1;k\u0026lt;=tlen;k++){print k,tA[k];}}\u0026#39; 1 it 2 is 3 a 4 test 判断键值存在以及删除键值： # awk \u0026#39;BEGIN{tB[\u0026#34;a\u0026#34;]=\u0026#34;a1\u0026#34;;tB[\u0026#34;b\u0026#34;]=\u0026#34;b1\u0026#34;;if( \u0026#34;c\u0026#34; in tB){print \u0026#34;ok\u0026#34;;};for(k in tB){print k,tB[k];}}\u0026#39; a a1 b b1 #删除键值： [chengmo@localhost ~]$ awk \u0026#39;BEGIN{tB[\u0026#34;a\u0026#34;]=\u0026#34;a1\u0026#34;;tB[\u0026#34;b\u0026#34;]=\u0026#34;b1\u0026#34;;delete tB[\u0026#34;a\u0026#34;];for(k in tB){print k,tB[k];}}\u0026#39; b b1 二维、多维数组使用 # awk的多维数组在本质上是一维数组，更确切一点，awk在存储上并不支持多维数组。awk提供了逻辑上模拟二维数组的访问方式。例如，array[2,4]=1这样的访问是允许的。awk使用一个特殊的字符串SUBSEP(34)作为分割字段，在上面的例子中，关联数组array存储的键值实际上是2344。\n类似一维数组的成员测试，多维数组可以使用if ( (i,j) in array)这样的语法，但是下标必须放置在圆括号中。类似一维数组的循环访问，多维数组使用for ( item in array )这样的语法遍历数组。与一维数组不同的是，多维数组必须使用split()函数来访问单独的下标分量。\nawk \u0026#39;BEGIN{ for(i=1;i\u0026lt;=9;i++){ for(j=1;j\u0026lt;=9;j++){ tarr[i,j]=i*j; print i,\u0026#34;*\u0026#34;,j,\u0026#34;=\u0026#34;,tarr[i,j]; } } }\u0026#39; 1 * 1 = 1 1 * 2 = 2 1 * 3 = 3 1 * 4 = 4 1 * 5 = 5 1 * 6 = 6 ... 9 * 6 = 54 9 * 7 = 63 9 * 8 = 72 9 * 9 = 81 Another\nawk \u0026#39;BEGIN{ for(i=1;i\u0026lt;=9;i++){ for(j=1;j\u0026lt;=9;j++){ tarr[i,j]=i*j; } } for(m in tarr){ split(m,tarr2,SUBSEP); print tarr2[1],\u0026#34;*\u0026#34;,tarr2[2],\u0026#34;=\u0026#34;,tarr[m]; } }\u0026#39; 内置函数 # awk内置函数，主要分以下3种类似：算数函数、字符串函数、其它一般函数、时间函数。\nawk \u0026#39;BEGIN{OFMT=\u0026#34;%.3f\u0026#34;;fs=sin(1);fe=exp(10);fl=log(10);fi=int(3.1415);print fs,fe,fl,fi;}\u0026#39; 0.841 22026.466 2.303 3 OFMT 设置输出数据格式是保留3位小数。\nRandom\nawk \u0026#39;BEGIN{srand();fr=int(100*rand());print fr;}\u0026#39; 78 awk \u0026#39;BEGIN{srand();fr=int(100*rand());print fr;}\u0026#39; 31 awk \u0026#39;BEGIN{srand();fr=int(100*rand());print fr;}\u0026#39; 41 gsub,sub使用 # awk \u0026#39;BEGIN{info=\u0026#34;this is a test2010test!\u0026#34;;gsub(/[0-9]+/,\u0026#34;!\u0026#34;,info);print info}\u0026#39; this is a test!test! 在 info中查找满足正则表达式，/[0-9]+/ 用””替换，并且替换后的值，赋值给info 未给info值，默认是$0\n查找字符串（index使用） # awk \u0026#39;BEGIN{info=\u0026#34;this is a test2010test!\u0026#34;;print index(info,\u0026#34;test\u0026#34;)?\u0026#34;ok\u0026#34;:\u0026#34;no found\u0026#34;;}\u0026#39; ok 未找到，返回0\n正则表达式匹配查找(match使用） # awk \u0026#39;BEGIN{info=\u0026#34;this is a test2010test!\u0026#34;;print match(info,/[0-9]+/)?\u0026#34;ok\u0026#34;:\u0026#34;no found\u0026#34;;}\u0026#39; ok 截取字符串(substr使用） # awk \u0026#39;BEGIN{info=\u0026#34;this is a test2010test!\u0026#34;;print substr(info,4,10);}\u0026#39; s is a tes 格式化字符串输出（sprintf使用） # 其中格式化字符串包括两部分内容：一部分是正常字符，这些字符将按原样输出; 另一部分是格式化规定字符，以\u0026quot;%\u0026ldquo;开始，后跟一个或几个规定字符,用来确定输出内容格式。\nawk \u0026#39;BEGIN{n1=124.113;n2=-1.224;n3=1.2345; printf(\u0026#34;%.2f,%.2u,%.2g,%X,%on\u0026#34;,n1,n2,n3,n1,n1);}\u0026#39; 124.11,18446744073709551615,1.2,7C,174 调用外部命令的方式 # awk \u0026#39;BEGIN{b=system(\u0026#34;ls -al\u0026#34;);print b;}\u0026#39; total 42092 drwxr-xr-x 14 chengmo chengmo 4096 09-30 17:47 . drwxr-xr-x 95 root root 4096 10-08 14:01 .. 指定时间(mktime使用） # ``` awk \u0026lsquo;BEGIN{tstamp=mktime(\u0026ldquo;2001 01 01 12 12 12\u0026rdquo;);print strftime(\u0026quot;%c\u0026rdquo;,tstamp);}\u0026rsquo; 2001年01月01日 星期一 12时12分12秒 awk \u0026lsquo;BEGIN{tstamp1=mktime(\u0026ldquo;2001 01 01 12 12 12\u0026rdquo;);tstamp2=mktime(\u0026ldquo;2001 02 01 0 0 0\u0026rdquo;);print tstamp2-tstamp1;}\u0026rsquo; 2634468\nawk \u0026lsquo;BEGIN{tstamp1=mktime(\u0026ldquo;2001 01 01 12 12 12\u0026rdquo;);tstamp2=systime();print tstamp2-tstamp1;}\u0026rsquo; 308201392 ``` "},{"id":35,"href":"/posts/web/node/","title":"node nodejs npm 傻傻分不清楚on Ubuntu","section":"Web","content":"在学习angular的过程中，要安装Node，但是我在ubuntu上用一些方法安装的版本都太低了，而且还有node、nodejs这两个东西交替出现，让我很是怀疑人生。\n决定扒一扒这鬼玩意儿的前世今生。倒要看看你葫芦里装的是什么逼！\nubuntu 下的Node与Nodejs # 首先这两个我认为是一个东西的两个发展阶段，在最开始的时候，名字叫做nodejs，后来升级改版以后就变成了node。\n在某个版本之前，我们安装的都是nodejs。命令行中使用的也都是nodejs。后来可能作者们要开始装逼了，于是决定把丑爆了的js去掉，因为js在一些工程师的眼中很垃圾，所以不能让别人认为node也很垃圾。事实上js确实有很多缺陷，但是并不影响它一统前端，甚至进一步掠夺市场进驻后端，甚至现在在无联网领域成为香饽饽。\njs在进步，同时node也在进步，喜欢用js这样用起来比较便捷的工程师也越来越多，所以，未来的流行语言里，js应该也有重要的一席之地，所以我要学会它。\njs的细节不在这篇文章的讨论范围之内，我还是比较关心这个node到底是个什么神通广大的东西，让这么多程序员都不淡定了。\nNode是个啥 # 官方解释：nodejs是一个平台, 它构建在chrome的v8引擎之上,能简易的构建快速,可扩展的网络应用程序\u0026hellip;\n害怕，口气还真是很大。关键是人家说的是网络应用程序哎！不是前端，也不是server，而是网络应用程序。 其本质就是一个网络应用程序喽，所以必然有两个的东西非常重要，一个是网络，一个是应用程序。\n下面分几个小点\nV8引擎，名字很帅哈。这个引擎其实就是javascript的解释器，将代码解释成本机可以运行的机器代码。\nopenssl是个开源的，安全套接层协议。其将数据加密和通信加密算法直接实现在协议中，使得数据离开你的机器时就是加密的，直到目的地才进行解密。是安全通信领域应用最广的一个开源项目。这部分详细的内容会在接下来的文章中详述。Node本身是集成了这个openssl项目的。\n事件驱动的非阻塞io模型。 这个是其作为应用程序的一个特征。所谓事件驱动，就是一个异步的处理机制。整个程序通过订阅相应的时间消息，来出发相应的动作。 实现这个功能的主要技术就是libuv， 其前身是linux中的libev。Node重写了这个库并在windows上做了相应的实现，所以node是个可跨平台的运行的程序。\n以上就是Node的几个重要的特点，了解了这些特征就能进一步了解其原理。下面在选择一些东西来记录一下。\nlibuv # nodejs 其实就是 libuv 的一个应用而已。\n你自己写程序也可以集成libuv进来, 这样你的c++程序就有了消息循环了. 不再是简单main函数了. 你可以订阅系统的事件, 然后当事件发生时, 系统会调用你的回调函数, 就跟windows上的button click事件一样方便. 而且是跨平台的哦. 是不是很酷. 你几乎可以订阅所有的系统事件, 比如socket事件, 文件读写事件等等.\nnodejs简单的说只是把javascript解释成c++的回调, 并挂在libuv消息循环上, 等待处理. 这样就实现了非阻塞的异步处理机制(non-blocking I/O model).\n那么为什么是javascript而不是其他的语言. 很简单, 因为javascript的闭包. 这非常适合做回调函数. 因为我们一般都希望当回调发生时, 它能记住它原来所在的上下文. 这就是闭包最好的应用场景.\n小结 # Node其实就是一个平台，在这个平台上运行的是javascript语言。你可以使用它来实现很多东西，不仅仅是server端的服务程序，也可以写一个窗口的软件程序等等。 Node与python、JVM其实都是一类东西。\nubuntu 安装最新的Node和npm # npm是Node的包管理器。就像是我们的apt对于debian的概念一样。\nubuntu维护的源大多是LTS版本的，但是node的发展速度很快有很多新特性在新的版本中。所以很多时候稳定版本并不能满足我们的需求。下面就介绍一下最新版本的怎么安装。\n安装npm # 先用ubuntu库中的资源安装一个低版本\nsudo apt install npm 此时我们npm -v发现版本是3.5.2。 升级到新版本：\nsudo npm install npm@latest -g 升级后的版本是：5.3.0。版本差距还是非常大的，所以升级十分必要。\n安装一个第三方的模块n # 项目在Github上，不复杂，主要就是一个脚本。\nsudo npm install -g n 然后用这个第三方模块来选择安装的node版本。\n//安装官方最新版本 sudo n latest //安装官方稳定版本 sudo n stable //安装官方最新LTS版本 sudo n lts 我一般会选择安装lts版本。\n至此node安装完毕可以开始搞angular了。\n"},{"id":36,"href":"/posts/web/cors/","title":"CORS Cross-Origin Resource Sharing","section":"Web","content":"有一种痛，叫做就是想让你多学习一点东西。\n这个知识点，来源于一口还没找到源头的大黑锅。而我不能背这个锅，并且要找到一个人来背锅。\nIntroduction # 在之前的sso文章中，有提到过一个问题，就是cookie的不能跨域的问题。 出于安全考虑，浏览器会限制从脚本内发起的跨域HTTP请求。例如，XMLHttpRequest 和 Fetch 遵循同源策略。因此，使用 XMLHttpRequest或 Fetch 的Web应用程序只能将HTTP请求发送到其自己的域。为了改进Web应用程序，开发人员要求浏览器厂商允许跨域请求。\n针对跨域的解决方案有很多，比如：flush、JSONP、ifame、xhr2等，但是都有很多弊端，我觉得CORS比较有前途。\n这个解决方案已经被几乎所有的主流的浏览器支持了。浏览器内置了这种解决方案，所以对于前端的工程师来说就是透明的，当前端使用ajax发起一个跨域请求的时候，浏览器自动使用这个方案来处理。但是这个方案需要浏览器和服务器共同支持才可以。\n今天主要的使用是依靠XMLHttpRequest来实现。这是一个js的对象，负责与服务端进行动态数据交互。\n发起一个XMLHttpRequest请求 # 原生的请求形式。\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; //XmlHttpRequest对象 function createXmlHttpRequest(){ if(window.ActiveXObject){ //如果是IE浏览器 return new ActiveXObject(\u0026#34;Microsoft.XMLHTTP\u0026#34;); }else if(window.XMLHttpRequest){ //非IE浏览器 return new XMLHttpRequest(); } } // 调用getFile方法 function getFile() { var img_Container = document.getElementById(\u0026#34;img_Div\u0026#34;); var xhr = createXmlHttpRequest(); xhr.open(\u0026#39;GET\u0026#39;, \u0026#39;http://oss.youkouyang.com/1.jpg\u0026#39;, true); xhr.setRequestHeader(\u0026#39;Content-Type\u0026#39;, \u0026#39;image/jpeg\u0026#39;); xhr.responseType = \u0026#34;blob\u0026#34;; xhr.onload = function() { if (this.status == 200) { var blob = this.response; var img = document.createElement(\u0026#34;img\u0026#34;); img.onload = function(e) { window.URL.revokeObjectURL(img.src); }; img.src = window.URL.createObjectURL(blob); img_Container.appendChild(img); } } xhr.send(null); } \u0026lt;/script\u0026gt; 请求过程 # 请求分成两种，一种是简单请求，还有一种是非简单请求。\n同时符合下面两种情况的是简单请求：\n属于下列method之一的 GET POST HEAD HTTP的头信息不超出以下几种字段： Accept Accept-Language Content-Language Last-Event-ID Content-Type：只限于三个值application/x-www-form-urlencoded、multipart/form-data、text/plain 除此以外是非简单请求。\n简单请求 # 对于简单请求，浏览器会自动加上一个header字段Origin，然后发起访问：\nGET /cors HTTP/1.1 Origin: http://api.bob.com Host: api.alice.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... 表示这个访问来自于什么源。\n服务端收到这个请求以后查看这个源是否是合法的，如果是合法的就继续。如果是不合法的就返回。 但是请求都是成功的，区别就是在返回的header中。\n如果是不合法的，返回的header中不会有这个字段：Access-Control-Allow-Origin 如果是合法的，就会多出下面的几个字段： Access-Control-Allow-Origin: http://api.bob.com Access-Control-Allow-Credentials: true Access-Control-Expose-Headers: FooBar Content-Type: text/html; charset=utf-8\nAccess-Control-Allow-Origin 该字段是必须的。它的值要么是请求时Origin字段的值，要么是一个*，表示接受任意域名的请求。 Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie。默认情况下，Cookie不包括在CORS请求之中。设为true，即表示服务器明确许可，Cookie可以包含在请求中，一起发给服务器。这个值也只能设为true，如果服务器不要浏览器发送Cookie，删除该字段即可。 Access-Control-Expose-Headers 该字段可选。CORS请求时，XMLHttpRequest对象的getResponseHeader()方法只能拿到6个基本字段：Cache-Control、Content-Language、Content-Type、Expires、Last-Modified、Pragma。如果想拿到其他字段，就必须在Access-Control-Expose-Headers里面指定。上面的例子指定，getResponseHeader(\u0026lsquo;FooBar\u0026rsquo;)可以返回FooBar字段的值。 非简单请求 # 非简单请求的CORS请求，会在正式通信之前，增加一次HTTP查询请求，称为\u0026quot;预检\u0026quot;请求（preflight）。 浏览器先询问服务器，当前网页所在的域名是否在服务器的许可名单之中，以及可以使用哪些HTTP动词和头信息字段。只有得到肯定答复，浏览器才会发出正式的XMLHttpRequest请求，否则就报错。\n带Cookie # 一般跨域请求是不带cookie的，需要打开相应的选项才会发送cookie，服务器请求写cookie的时候才会被浏览器接受。\n服务器端需要指定Access-Control-Allow-Credentials字段。 Access-Control-Allow-Credentials: true 另一方面，开发者必须在AJAX请求中打开withCredentials属性。 var xhr = new XMLHttpRequest(); xhr.withCredentials = true;\n需要注意的是，如果要发送Cookie，Access-Control-Allow-Origin就不能设为星号，必须指定明确的、与请求网页一致的域名。同时，Cookie依然遵循同源政策，只有用服务器域名设置的Cookie才会上传，其他域名的Cookie并不会上传，且（跨源）原网页代码中的document.cookie也无法读取服务器域名下的Cookie。\nJava tomcat实现 # 上面说的再多，你也很困惑，怎么实现，难道要我自己写吗？\n在Java web中我们会使用过滤器来实现这个操作。暂时介绍使用第三方包：cors-filter-1.7.jar，Java-property-utils-1.9.jar\n在web.xml中配置下面的东西就可以实现过滤了。\n\u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;CORS\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;com.thetransactioncompany.cors.CORSFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;cors.allowOrigin\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;*\u0026lt;/param-value\u0026gt; \u0026lt;!-- // 允许访问的网站，多个时用逗号分开；*代表允许所有 \u0026lt;param-value\u0026gt;http://www.baidu.con, http://www.jd.com\u0026lt;/param-value\u0026gt; --\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;cors.supportedMethods\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;GET, POST, HEAD, PUT, DELETE\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;cors.supportedHeaders\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;Accept, Origin, X-Requested-With, Content-Type, Last-Modified\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;cors.exposedHeaders\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;Set-Cookie\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;cors.supportsCredentials\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;CORS\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 安全 # 以上这些只能保证可以用，但是并不能保证安全，还是要有其他的方式进行安全验证才好。\n"},{"id":37,"href":"/posts/others/curator/","title":"apache curator","section":"Others","content":"\u0026ldquo;Guava is to java what Curator is to Zookeeper\u0026rdquo;.\nStart # Curator之前介绍过一些，是一个使用流式API方式实现的Zookeeper的Java客户端。\nGet a connection # connection的实例(CuratorFramework)是用工厂模式分配的(CuratorFrameworkFactory)，对于一个zk集群，你只需要一个连接的实例。 同时你可能会用到的是RetryPolicy 去设置失败重试的参数，一般你会这样使用：\nRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3) CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperConnectionString, retryPolicy); client.start(); 客户端需要显式的start并且在不用的时候显式的close.\n在链接成功以后就可以直接操作对应的集群。并且，如果在执行操作的过程中出现了连接错误，curator的manage会自动重新尝试操作。\n分布式锁 # 不可以对某个路径下的节点进行上锁：\nInterProcessMutex lock = new InterProcessMutex(client, lockPath); if ( lock.acquire(maxWait, waitUnit) ) { try { // do some work inside of the critical section here } finally { lock.release(); } } "},{"id":38,"href":"/posts/others/synchronized/","title":"synchronized 同步锁","section":"Others","content":" synchronized # 修饰一个代码块，被修饰的代码块称为同步语句块，其作用的范围是大括号{}括起来的代码，作用的对象是调用这个代码块的对象； 修饰一个方法，被修饰的方法称为同步方法，其作用的范围是整个方法，作用的对象是调用这个方法的对象； 修饰一个静态的方法，其作用的范围是整个静态方法，作用的对象是这个类的所有对象； 修饰一个类，其作用的范围是synchronized后面括号括起来的部分，作用的对象是这个类的所有对象。 代码块加锁 # 一个线程访问一个对象中的synchronized(this)同步代码块时，其他试图访问该对象的线程将被阻塞。我们看下面一个例子：\n/** * 同步线程 */ class SyncThread implements Runnable { private static int count; public SyncThread() { count = 0; } public void run() { synchronized(this) { for (int i = 0; i \u0026lt; 5; i++) { try { System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + (count++)); Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } } } public int getCount() { return count; } } 调用的方式如下：\nSyncThread syncThread = new SyncThread(); Thread thread1 = new Thread(syncThread, \u0026#34;SyncThread1\u0026#34;); Thread thread2 = new Thread(syncThread, \u0026#34;SyncThread2\u0026#34;); thread1.start(); thread2.start(); 这里只有一个对象，创建了两个线程。两个县城先后启动。其结果就是先后的，因为有同步锁的存在。\nSyncThread1:0 SyncThread1:1 SyncThread1:2 SyncThread1:3 SyncThread1:4 SyncThread2:5 SyncThread2:6 SyncThread2:7 SyncThread2:8 SyncThread2:9 但是对于没有同步锁的代码块就没有这个限制：\nclass Counter implements Runnable{ private int count; public Counter() { count = 0; } public void countAdd() { synchronized(this) { for (int i = 0; i \u0026lt; 5; i ++) { try { System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + (count++)); Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } } } //非synchronized代码块，未对count进行读写操作，所以可以不用synchronized public void printCount() { for (int i = 0; i \u0026lt; 5; i ++) { try { System.out.println(Thread.currentThread().getName() + \u0026#34; count:\u0026#34; + count); Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } } public void run() { String threadName = Thread.currentThread().getName(); if (threadName.equals(\u0026#34;A\u0026#34;)) { countAdd(); } else if (threadName.equals(\u0026#34;B\u0026#34;)) { printCount(); } } } 调用方式：\nCounter counter = new Counter(); Thread thread1 = new Thread(counter, \u0026#34;A\u0026#34;); Thread thread2 = new Thread(counter, \u0026#34;B\u0026#34;); thread1.start(); thread2.start(); 结果如下：\nA:0 B count:1 A:1 B count:2 A:2 B count:3 A:3 B count:4 A:4 B count:5 对象加锁 # /** * 银行账户类 */ class Account { String name; float amount; public Account(String name, float amount) { this.name = name; this.amount = amount; } //存钱 public void deposit(float amt) { amount += amt; try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } //取钱 public void withdraw(float amt) { amount -= amt; try { Thread.sleep(100); } catch (InterruptedException e) { e.printStackTrace(); } } public float getBalance() { return amount; } } /** * 账户操作类 */ class AccountOperator implements Runnable{ private Account account; public AccountOperator(Account account) { this.account = account; } public void run() { synchronized (account) { account.deposit(500); account.withdraw(500); System.out.println(Thread.currentThread().getName() + \u0026#34;:\u0026#34; + account.getBalance()); } } } 主要是账户操作类中的操作，调用方式：\nAccount account = new Account(\u0026#34;zhang san\u0026#34;, 10000.0f); AccountOperator accountOperator = new AccountOperator(account); final int THREAD_NUM = 5; Thread threads[] = new Thread[THREAD_NUM]; for (int i = 0; i \u0026lt; THREAD_NUM; i ++) { threads[i] = new Thread(accountOperator, \u0026#34;Thread\u0026#34; + i); threads[i].start(); } /* 结果如下： Thread3:10000.0 Thread2:10000.0 Thread1:10000.0 Thread4:10000.0 Thread0:10000.0 */ 获得锁的顺序会乱，但是没有两个线程同时修改一个count对象。\n利用这种方式你可以让任何一段代码变成同步且有同步锁的，只要建立一个对象，对这个对象加锁就可以了，最快的就是开个长度为空的数组：\nclass Test implements Runnable { private byte[] lock = new byte[0]; // 特殊的instance变量 public void method() { synchronized(lock) { // todo 同步代码块 } } public void run() { } } 生成零长度的byte[]对象只需3条操作码，而Object lock = new Object()则需要7行操作码。\n注意事项 - synchronized关键字不能继承 # 这个其实也不算是注意事项，但是有的人对继承的中的函数覆盖和重写如果理解不够深刻就可能会出问题， 主要表现在子类中重写父类同步方法的时候如果没有加同步关键字是默认不同步的。\n但是你调用父类的同步方法还是没有问题的。\n修饰静态方法 # 其实修饰静态方法就相当与锁定了所有对象的某个方法，因为静态的就是所有的嘛。\n修饰类 # 这个类的所有的对象共用一把锁。\n"},{"id":39,"href":"/posts/java/javawait/","title":"java wait一种线程通信方式","section":"Java","content":"在一个异步改同步的工程中，有两种方式，一个是轮询，一个是中断。这里介绍一下中断的操作。\n在看这一部分之前你可能先要看下一篇文章，关于synchronized同步锁的问题。下面会用到。\n如果你的Java程序中有两个线程——即生产者和消费者，那么生产者可以通知消费者，让消费者开始消耗数据，因为队列缓冲区中有内容待消费（不为空）。相应的，消费者可以通知生产者可以开始生成更多的数据，因为当它消耗掉某些数据后缓冲区不再为满。\nwait # Object类中相关的方法有两个notify方法和三个wait方法： 因为wait和notify方法定义在Object类中，因此会被所有的类所继承。 这些方法都是final的，即它们都是不能被重写的，不能通过子类覆写去改变它们的行为。\nwait()方法使得当前线程必须要等待，等到另外一个线程调用notify()或者notifyAll()方法。 线程调用wait()方法，释放它对锁的拥有权，然后等待另外的线程来通知它（通知的方式是notify()或者notifyAll()方法），这样它才能重新获得锁的拥有权和恢复执行。\n要确保调用wait()方法的时候拥有锁，即，wait()方法的调用必须放在synchronized方法或synchronized块中。\n与sleep不同的是sleep不会释放锁。\nnotify # notify()方法会唤醒一个等待当前对象的锁的线程。如果多个线程在等待，它们中的一个将会选择被唤醒。这种选择是随意的，和具体实现有关。(线程等待一个对象的锁是由于调用了wait方法中的一个)。\n被唤醒的县城也并不是直接就能执行，而是要进入到正常的线程竞争过程中。\n同样的你notify方法也要放在synchronized方法或者synchronized块中执行。\n正确的使用 # 除了要在同步的基础上使用以外，在书《Java并发实践》中，作者提出一定要在循环中使用wait。正确的代码应该是下面的样子：\n// The standard idiom for calling the wait method in Java synchronized (sharedObject) { while (condition) { sharedObject.wait(); // (Releases lock, and reacquires on wakeup) } // do action based upon condition e.g. take or put into queue } 在while循环里使用wait的目的，是在线程被唤醒的前后都持续检查条件是否被满足。如果条件并未改变，wait被调用之前notify的唤醒通知就来了，那么这个线程并不能保证被唤醒，有可能会导致死锁问题。\n这两个函数都是对于某个对象来说的，这个对象一定是一个多线程共享的对象。是同步，是利用锁的机制进行同步的。\n在生产者消费者的概念中，就是对产品的队列进行共享，所以wait()和notify()都是queue的动作，同时锁也是对于queue来说的。\n"},{"id":40,"href":"/posts/c++/funcp/","title":"C 函数指针","section":"C","content":"C语言有了函数指针以后，就算是完整了，构建了这个世界。\n先来看三个例子：\nA) char * (*fun1)(char * p1,char * p2); B) char * *fun2(char * p1,char * p2); C) char * fun3(char * p1,char * p2); 最后一个很好理解，fun3是函数名，函数返回一个char*。 中间个是返回一个二级指针，本质与最后一个没有什么区别。\n在第一个中，其实就是函数指针了，fun1是个函数指针，这个函数返回一个char*。\n函数指针其归根结底是一个指针，所以他是可以赋值的。如下的一个函数指针：\nint (*p)(int a, int b) = NULL;//初始化为 NULL 如果我们要给 p 赋值的话，我们就应该定义一个返回值类型为 int ，两个参数为 int 的函数：\nint add(int a, int b) { return a + b; } p = add;//给函数指针赋值 经过上面的赋值，我们就可以使用 p 来代表函数：\np(5, 6);//等价于 add(5, 6); printf(\u0026#34;%d\\n\u0026#34;, p(5, b)); 当然这并不是主要的用法，最主要的用法是用作回调函数。\n函数回调 # 函数回调的本质就是让函数指针作为函数参数，函数调用时传入函数地址，也就是函数名即可。 所谓回调函数就是在做完某些事情以后做的一件事情，函数回调一般使用在需要等待或者耗时操作，或者得在一定时间或者事件触发后回调执行的情况下。\n想比较其他的方式，回调函数更加灵活。回调函数是由你来实现，交给对方来执行。你传递给对方你一个函数指针。\nexample # //定义回调函数 void PrintfText() { printf(\u0026#34;Hello World!\\n\u0026#34;); } //定义实现回调函数的\u0026#34;调用函数\u0026#34; void CallPrintfText(void (*callfuct)()) { callfuct(); } //实现函数回调 int main(int argc,char* argv[]) { CallPrintfText(PrintfText); return 0; } 函数名本身就是一个函数指针，所以直接传函数名就可以实现。在函数声明的地方要使用函数指针的方式去声明参数。\n"},{"id":41,"href":"/posts/c++/cpp-1/","title":"cpp lamda \u0026 for_each","section":"C","content":"既然学习了java的lamda表达式，当然要来顺便学习一下C++的实现。\nlamda # C++11 有了对lamda表达式的支持。基本的形式有下面几种：\n|\u0026mdash;\u0026ndash;| | [capture] ( params ) mutable exception attribute -\u0026gt; ret { body } | | [capture] ( params ) -\u0026gt; ret { body }\t| | [capture] ( params ) { body }\t| | [capture] { body }\t|\n[capture]: 需要用到的外部变量 [a,\u0026amp;b] a变量以值的方式呗捕获，b以引用的方式被捕获。 [this] 以值的方式捕获 this 指针。 [\u0026amp;] 以引用的方式捕获所有的外部自动变量。 [=] 以值的方式捕获所有的外部自动变量。 [] 不捕获外部的任何变量。 [\u0026amp;, x] x显式地按值捕获. 其它变量按引用捕获 [=, \u0026amp;z] z按引用捕获. 其它变量按值捕获 (params): 函数的参数, 无参数括号可以省略。 mutable: 修饰符说明 lambda 表达式体内的代码可以修改被捕获的变量，并且可以访问被捕获对象的 non-const 方法。 exception: 说明 lambda 表达式是否抛出异常(noexcept)，以及抛出何种异常，类似于void f() throw(X, Y) attribute: 用来声明属性 几个例子：\n[](int x, int y) { return x + y; } // 隐式返回类型 [](int\u0026amp; x) { ++x; } // 没有return语句 -\u0026gt; lambda 函数的返回类型是\u0026#39;void\u0026#39; [a](int\u0026amp; x) { x+=a; } // 没有return语句 -\u0026gt; lambda 函数的返回类型是\u0026#39;void\u0026#39;;注意，此处a是从lambda函数体外部传入其中的变量 []() { ++global_x; } // 没有参数,仅访问某个全局变量 []{ ++global_x; } // 与上一个相同,省略了() // 可以像下面这样显示指定返回类型: [](int x, int y) -\u0026gt; int { int z = x + y; return z; } // 在这个例子中创建了一个临时变量z来存储中间值. 和普通函数一样,这个中间值不会保存到下次调用. 什么也不返回的Lambda函数可以省略返回类型, 而不需要使用 -\u0026gt; void 形式. 下面举两个例子：\nstd::vector\u0026lt;int\u0026gt; some_list; int total = 0; for (int i=0;i\u0026lt;5;++i) some_list.push_back(i); std::for_each(begin(some_list), end(some_list), [\u0026amp;total](int x) { total += x; }); 在其中用到了for_each的语法，直接介绍一下最后一个参数，是一个方法，同样也可以是一个lamda表达式。 for_each需要algorithm头文件。\n比较好奇的就是怎么传的参数。。\n以前用过一个函数sort，直接传一个函数的名就可以自定义比较函数了，但是一直没有去思考如何做到的。 看到有一种实现方式是函数指针，感觉这个东西在C语言中也有很大的意义，所以打算另起一篇来记录。\n在使用lamda的时候参数是包含的函数本身确定的，例如for_each就会传入一个元素。\n"},{"id":42,"href":"/posts/java/lamda/","title":"Java lamda 表达式","section":"Java","content":"本文大部分来自该博客，有些是自己的写代码的经验，觉得作者写的很清晰，非常棒。\n1. 什么是λ表达式 # λ表达式本质上是一个匿名方法。让我们来看下面这个例子：\npublic int add(int x, int y) { return x + y; } 转成λ表达式后是这个样子：\n(int x, int y) -\u0026gt; x + y; 参数类型也可以省略，Java编译器会根据上下文推断出来：\n(x, y) -\u0026gt; x + y; //返回两数之和 或者\n(x, y) -\u0026gt; { return x + y; } //显式指明返回值 可见λ表达式有三部分组成：参数列表，箭头（-\u0026gt;），以及一个表达式或语句块。\n下面这个例子里的λ表达式没有参数，也没有返回值（相当于一个方法接受0个参数，返回void，其实就是Runnable里run方法的一个实现）：\n() -\u0026gt; { System.out.println(\u0026#34;Hello Lambda!\u0026#34;); } 如果只有一个参数且可以被Java推断出类型，那么参数列表的括号也可以省略：\nc -\u0026gt; { return c.size(); } 函数接口 # lamda表达式是什么？它不是一个object，而是一个函数接口。 在java8中引入的新特性，函数接口。定义如下：一个接口，如果只有一个显式声明的抽象方法，那么它就是一个函数接口。\n也就是你生命一个接口，这个接口只有一个显示的抽象函数，那么这个函数其实就是lamda表达式本身。你可以写个类来实现它，然后在传入lamda表达式的位置传入这个类的实例，效果与lamda表达式是一样的。 这个接口可以使用一个注解来注解出来:@FunctionalInterface。\n你可以用lamda表达式为一个函数接口赋值：\nRunnable r1 = () -\u0026gt; {System.out.println(\u0026#34;Hello Lambda!\u0026#34;);}; 然后再赋值给一个Object：\nObject obj = r1; 但是不能直接赋值给object。\n需要注意的是，一个lamda表达式必须能够对应至少一个函数接口，也就说，当你要在一个函数中传入一个人lamda表达式的时候要看一下人家的参数是不是一个函数接口，如果是就可以用lamda来写。\n作用 # λ表达式主要用于替换以前广泛使用的内部匿名类，各种回调，比如事件响应器、传入Thread类的Runnable等。看下面的例子：\nThread oldSchool = new Thread( new Runnable () { @Override public void run() { System.out.println(\u0026#34;This is from an anonymous class.\u0026#34;); } } ); // lamda 表达式版本(高端大气上档次) Thread gaoDuanDaQiShangDangCi = new Thread( () -\u0026gt; { System.out.println(\u0026#34;This is from an anonymous method (lambda exp).\u0026#34;); } ); lamda 的目的主要有两个方面 这部分就不是我的功力能够写出来的了。直接贴别人的文字啦。\n块操作 # 集合类的批处理操作API的目的是实现集合类的“内部迭代”，并期望充分利用现代多核CPU进行并行计算。 Java8之前集合类的迭代（Iteration）都是外部的，即客户代码。而内部迭代意味着改由Java类库来进行迭代，而不是客户代码。例如：\nfor(Object o: list) { // 外部迭代 System.out.println(o); } 可以写成：\nlist.forEach(o -\u0026gt; {System.out.println(o);}); //forEach函数实现内部迭代 集合类（包括List）现在都有一个forEach方法，对元素进行迭代（遍历），所以我们不需要再写for循环了。forEach方法接受一个函数接口Consumer做参数，所以可以使用λ表达式。\n这种内部迭代方法广泛存在于各种语言，如C++的STL算法库、python、ruby、scala等。\nJava8为集合类引入了另一个重要概念：流（stream）。一个流通常以一个集合类实例为其数据源，然后在其上定义各种操作。流的API设计使用了管道（pipelines）模式。对流的一次操作会返回另一个流。如同IO的API或者StringBuffer的append方法那样，从而多个不同的操作可以在一个语句里串起来。看下面的例子：\nList\u0026lt;Shape\u0026gt; shapes = ... shapes.stream() .filter(s -\u0026gt; s.getColor() == BLUE) .forEach(s -\u0026gt; s.setColor(RED)); 首先调用stream方法，以集合类对象shapes里面的元素为数据源，生成一个流。然后在这个流上调用filter方法，挑出蓝色的，返回另一个流。最后调用forEach方法将这些蓝色的物体喷成红色。（forEach方法不再返回流，而是一个终端方法，类似于StringBuffer在调用若干append之后的那个toString） (这部分是不是与上一篇中的流式接口非常的像)\nfilter方法的参数是Predicate类型，forEach方法的参数是Consumer类型，它们都是函数接口，所以可以使用λ表达式。\n还有一个方法叫parallelStream()，顾名思义它和stream()一样，只不过指明要并行处理，以期充分利用现代CPU的多核特性。\nshapes.parallelStream(); // 或shapes.stream().parallel() 来看更多的例子。下面是典型的大数据处理方法，Filter-Map-Reduce：\n//给出一个String类型的数组，找出其中所有不重复的素数 public void distinctPrimary(String... numbers) { List\u0026lt;String\u0026gt; l = Arrays.asList(numbers); List\u0026lt;Integer\u0026gt; r = l.stream() .map(e -\u0026gt; new Integer(e)) .filter(e -\u0026gt; Primes.isPrime(e)) .distinct() .collect(Collectors.toList()); System.out.println(\u0026#34;distinctPrimary result is: \u0026#34; + r); } 第一步：传入一系列String（假设都是合法的数字），转成一个List，然后调用stream()方法生成流。\n第二步：调用流的map方法把每个元素由String转成Integer，得到一个新的流。map方法接受一个Function类型的参数，上面介绍了，Function是个函数接口，所以这里用λ表达式。\n第三步：调用流的filter方法，过滤那些不是素数的数字，并得到一个新流。filter方法接受一个Predicate类型的参数，上面介绍了，Predicate是个函数接口，所以这里用λ表达式。\n第四步：调用流的distinct方法，去掉重复，并得到一个新流。这本质上是另一个filter操作。\n第五步：用collect方法将最终结果收集到一个List里面去。collect方法接受一个Collector类型的参数，这个参数指明如何收集最终结果。在这个例子中，结果简单地收集到一个List中。我们也可以用Collectors.toMap(e-\u0026gt;e, e-\u0026gt;e)把结果收集到一个Map中，它的意思是：把结果收到一个Map，用这些素数自身既作为键又作为值。toMap方法接受两个Function类型的参数，分别用以生成键和值，Function是个函数接口，所以这里都用λ表达式。\n你可能会觉得在这个例子里，List l被迭代了好多次，map，filter，distinct都分别是一次循环，效率会不好。实际并非如此。这些返回另一个Stream的方法都是“懒（lazy）”的，而最后返回最终结果的collect方法则是“急（eager）”的。在遇到eager方法之前，lazy的方法不会执行。\n当遇到eager方法时，前面的lazy方法才会被依次执行。而且是管道贯通式执行。这意味着每一个元素依次通过这些管道。例如有个元素“3”，首先它被map成整数型3；然后通过filter，发现是素数，被保留下来；又通过distinct，如果已经有一个3了，那么就直接丢弃，如果还没有则保留。这样，3个操作其实只经过了一次循环。\n除collect外其它的eager操作还有forEach，toArray，reduce等。\n下面来看一下也许是最常用的收集器方法，groupingBy：\n//给出一个String类型的数组，找出其中所有不重复的素数，并统计其出现次数 public void primaryOccurrence(String... numbers) { List\u0026lt;String\u0026gt; l = Arrays.asList(numbers); Map\u0026lt;Integer, Integer\u0026gt; r = l.stream() .map(e -\u0026gt; new Integer(e)) .filter(e -\u0026gt; Primes.isPrime(e)) .collect( Collectors.groupingBy(p-\u0026gt;p, Collectors.summingInt(p-\u0026gt;1)) ); System.out.println(\u0026#34;primaryOccurrence result is: \u0026#34; + r); } 注意这一行：\nCollectors.groupingBy(p-\u0026gt;p, Collectors.summingInt(p-\u0026gt;1)) // 它的意思是：把结果收集到一个Map中，用统计到的各个素数自身作为键，其出现次数作为值。 下面是一个reduce的例子：\n//给出一个String类型的数组，求其中所有不重复素数的和 public void distinctPrimarySum(String... numbers) { List\u0026lt;String\u0026gt; l = Arrays.asList(numbers); int sum = l.stream() .map(e -\u0026gt; new Integer(e)) .filter(e -\u0026gt; Primes.isPrime(e)) .distinct() .reduce(0, (x,y) -\u0026gt; x+y); // equivalent to .sum() System.out.println(\u0026#34;distinctPrimarySum result is: \u0026#34; + sum); } reduce方法用来产生单一的一个最终结果。 流有很多预定义的reduce操作，如sum()，max()，min()等。\n再举个现实世界里的栗子比如：\n// 统计年龄在25-35岁的男女人数、比例 public void boysAndGirls(List\u0026lt;Person\u0026gt; persons) { Map\u0026lt;Integer, Integer\u0026gt; result = persons.parallelStream().filter(p -\u0026gt; p.getAge()\u0026gt;=25 \u0026amp;\u0026amp; p.getAge()\u0026lt;=35). collect( Collectors.groupingBy(p-\u0026gt;p.getSex(), Collectors.summingInt(p-\u0026gt;1)) ); System.out.print(\u0026#34;boysAndGirls result is \u0026#34; + result); System.out.println(\u0026#34;, ratio (male : female) is \u0026#34; + (float)result.get(Person.MALE)/result.get(Person.FEMALE)); } 更多的用法 # // 嵌套的λ表达式 Callable\u0026lt;Runnable\u0026gt; c1 = () -\u0026gt; () -\u0026gt; { System.out.println(\u0026#34;Nested lambda\u0026#34;); }; c1.call().run(); // 用在条件表达式中 Callable\u0026lt;Integer\u0026gt; c2 = true ? (() -\u0026gt; 42) : (() -\u0026gt; 24); System.out.println(c2.call()); // 定义一个递归函数 private UnaryOperator\u0026lt;Integer\u0026gt; factorial = i -\u0026gt; { return i == 0 ? 1 : i * factorial.apply( i - 1 ); }; ... System.out.println(factorial.apply(3)); 在Java中，随声明随调用的方式是不行的，比如下面这样，声明了一个λ表达式(x, y) -\u0026gt; x + y，同时企图通过传入实参(2, 3)来调用它：\nint five = ( (x, y) -\u0026gt; x + y ) (2, 3); // ERROR! try to call a lambda in-place 这在C++中是可以的，但Java中不行。Java的λ表达式只能用作赋值、传参、返回值等。\n其他相关概念 # 捕获 # 捕获的概念在于解决在λ表达式中我们可以使用哪些外部变量（即除了它自己的参数和内部定义的本地变量）的问题。\n答案是：与内部类非常相似，但有不同点。不同点在于内部类总是持有一个其外部类对象的引用。而λ表达式呢，除非在它内部用到了其外部类（包围类）对象的方法或者成员，否则它就不持有这个对象的引用。\n在Java8以前，如果要在内部类访问外部对象的一个本地变量，那么这个变量必须声明为final才行。在Java8中，这种限制被去掉了，代之以一个新的概念，“effectively final”。它的意思是你可以声明为final，也可以不声明final但是按照final来用，也就是一次赋值永不改变。换句话说，保证它加上final前缀后不会出编译错误。\n在Java8中，内部类和λ表达式都可以访问effectively final的本地变量。λ表达式的例子如下：\nint tmp1 = 1; //包围类的成员变量 static int tmp2 = 2; //包围类的静态成员变量 public void testCapture() { int tmp3 = 3; //没有声明为final，但是effectively final的本地变量 final int tmp4 = 4; //声明为final的本地变量 int tmp5 = 5; //普通本地变量 Function\u0026lt;Integer, Integer\u0026gt; f1 = i -\u0026gt; i + tmp1; Function\u0026lt;Integer, Integer\u0026gt; f2 = i -\u0026gt; i + tmp2; Function\u0026lt;Integer, Integer\u0026gt; f3 = i -\u0026gt; i + tmp3; Function\u0026lt;Integer, Integer\u0026gt; f4 = i -\u0026gt; i + tmp4; Function\u0026lt;Integer, Integer\u0026gt; f5 = i -\u0026gt; { tmp5 += i; // 编译错！对tmp5赋值导致它不是effectively final的 return tmp5; }; ... tmp5 = 9; // 编译错！对tmp5赋值导致它不是effectively final的 } Java要求本地变量final或者effectively final的原因是多线程并发问题。内部类、λ表达式都有可能在不同的线程中执行，允许多个线程同时修改一个本地变量不符合Java的设计理念。\n方法引用（Method reference） # 这部分我并没有抓住其本质，表示没有很透彻的理解意思。\n任何一个λ表达式都可以代表某个函数接口的唯一方法的匿名描述符。我们也可以使用某个类的某个具体方法来代表这个描述符，叫做方法引用。例如：\nInteger::parseInt //静态方法引用 System.out::print //实例方法引用 Person::new //构造器引用 下面是一组例子，教你使用方法引用代替λ表达式：\n//c1 与 c2 是一样的（静态方法引用） Comparator\u0026lt;Integer\u0026gt; c2 = (x, y) -\u0026gt; Integer.compare(x, y); Comparator\u0026lt;Integer\u0026gt; c1 = Integer::compare; //下面两句是一样的（实例方法引用1） persons.forEach(e -\u0026gt; System.out.println(e)); persons.forEach(System.out::println); //下面两句是一样的（实例方法引用2） persons.forEach(person -\u0026gt; person.eat()); persons.forEach(Person::eat); //下面两句是一样的（构造器引用） strList.stream().map(s -\u0026gt; new Integer(s)); strList.stream().map(Integer::new); 使用方法引用，你的程序会变得更短些。现在distinctPrimarySum方法可以改写如下： public void distinctPrimarySum(String... numbers) { List\u0026lt;String\u0026gt; l = Arrays.asList(numbers); int sum = l.stream().map(Integer::new).filter(Primes::isPrime).distinct().sum(); System.out.println(\u0026#34;distinctPrimarySum result is: \u0026#34; + sum); } 还有一些其它的方法引用:\nsuper::methName //引用某个对象的父类方法 TypeName[]::new //引用一个数组的构造器 默认方法（Default method） # Java8中，接口声明里可以有方法实现了，叫做默认方法。在此之前，接口里的方法全部是抽象方法。\npublic interface MyInterf { String m1(); default String m2() { return \u0026#34;Hello default method!\u0026#34;; } } 这实际上有点混淆接口和抽象类，但一个类仍然可以实现多个接口，而只能继承一个抽象类。\n这么做的原因是：由于Collection库需要为批处理操作添加新的方法，如forEach()，stream()等，但是不能修改现有的Collection接口——如果那样做的话所有的实现类都要进行修改，包括很多客户自制的实现类。\n那么，我们就面临一种类似多继承的问题。如果类Sub继承了两个接口，Base1和Base2，而这两个接口恰好具有完全相同的两个默认方法，那么就会产生冲突。这时Sub类就必须通过重载来显式指明自己要使用哪一个接口的实现（或者提供自己的实现）:\npublic class Sub implements Base1, Base2 { public void hello() { Base1.super.hello(); //使用Base1的实现 } } 除了默认方法，Java8的接口也可以有静态方法的实现：\npublic interface MyInterf { String m1(); default String m2() { return \u0026#34;Hello default method!\u0026#34;; } static String m3() { return \u0026#34;Hello static method in Interface!\u0026#34;; } } 生成器函数（Generator function） # 有时候一个流的数据源不一定是一个已存在的集合对象，也可能是个“生成器函数”。一个生成器函数会产生一系列元素，供给一个流。Stream.generate(Supplier\u0026lt;T\u0026gt; s)就是一个生成器函数。其中参数Supplier是一个函数接口，里面有唯一的抽象方法 \u0026lt;T\u0026gt; get()。\n下面这个例子生成并打印5个随机数：\nStream.generate(Math::random).limit(5).forEach(System.out::println); 注意这个limit(5)，如果没有这个调用，那么这条语句会永远地执行下去。也就是说这个生成器是无穷的。这种调用叫做终结操作，或者短路（short-circuiting）操作。\n作者列出的参考资料是jdk的说明文档。\n"},{"id":43,"href":"/posts/others/zookeeper/","title":"ZooKeeper","section":"Others","content":"暂且将恼人的Tomcat放在一边，来解决新的问题，并学习新的玩意儿。\nZookeeper 是啥 # 动物园管理员，分布式服务就像是一个动物园。\nZookeeper是一个开源的分布式应用程序协调程序，为分布式应用程序提供一致性服务。 在分布式计算的应用中，最令人头疼的就是分布式锁的问题。同时各种同步问题也很让人崩溃，Zookeeper就是封装可一些算法，保证了其分布式服务的一致性，作为很多分布式服务的基础服务程序。\nZooKeeper 的设计原理 # 官方称之为鸟瞰：\n第一段在百度百科上。 在特性上面，zookeeper有这样几个特点。\n使用文件系统的结构来存储数据。 数据在用户的角度来看，是以类似与unix文件系统的方式来组织的，所以其定位方式是使用路径来定位数据。但是与文件系统不同的是，每个结点都可以存储数据，没有文件夹和文件的区别概念。\n高并发低延迟。 存储的数据在每一个zookeeper服务节点上都是一样的，所以读数据只要连接一个服务器直接读取就可以。数据的大小被限制在1M以内。\n高可用，自动故障转移。 这个是其设计的精髓之一，下面重点会讲。\n下面概要的讲一下运行的逻辑。\n选举 第一个，非常重要的步骤就是选举，在集群上部署完zookeeper以后，他们便开始执行选举流程，使用选举算法Fast Paxos作为基础。选举会产生一个leader。\n客户端与server 当有客户端与一个服务器建立连接的之后，他们之间会维持一个tcp连接，客户端会给服务器发送心跳请求，告诉服务器自己还在线。如果一个server监测到一个客户端断线了，就会在本地清除相关的数据。而客户端会重新去找一个server建立连接。\n写请求 在客户端读取数据的时候只要在其对应的服务器上读取就可以了。当其要写数据的时候，server会将这个写请求转发给leader服务器，leader将这个写请求统一发给每一个server进行写数据操作，当确认有严格的大于一半的server都写入成功以后，就算是写请求成功，再返回给原server，由原server返回成功给客户端。\n重新选举 leader会给server之间保持通信，通常就是所说的心跳。leader通过心跳来确认server是否存活，同时，server也可以确认leader是否存活，如果leader挂了，servers就会重新进行选举，然后再提供服务。\n通知 watcher是zk比较特殊的设计，允许一个或多个客户端绑定多个节点数据。当zk上的数据发生变化的时候能够通知到相应的客户端。这个设计就可以用来做很多的应用啦。redis数据库同样也有提供这样的消息发布与订阅的功能，不过那个是特意实现的一个功能给应用使用的。\n实现上的诸多细节 # 在听之前的老司机分享的时候，他们探讨了很多实现细节上的问题，感觉实现这样的一个分布式系统还是非常有挑战的。\n比如，如果写请求进行中leader挂掉了怎么办，数据tcp丢包了怎么办。如何同步数据等等。有空很想看看其实现方式。\n使用 # (这里补充一下服务器版的安装。与使用)\n最主要的使用途径还是通过客户端程序来访问zk。客户端有Java、python、lua、Go等。 我用java，所以。。\nmaven # \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.zookeeper\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;zookeeper\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 不过，这个有一点低端，所以我使用另外一个客户端的实现：curator。也是一个开源的zk客户端的实现，封装层次更高，所以操作更简便。\nCurator框架提供了一套高级的API， 简化了ZooKeeper的操作。 它增加了很多使用ZooKeeper开发的特性，可以处理ZooKeeper集群复杂的连接管理和重试机制。 这些特性包括：\n自动化的连接管理: 重新建立到ZooKeeper的连接和重试机制存在一些潜在的错误case。 Curator帮助你处理这些事情，对你来说是透明的。 清理API: 简化了原生的ZooKeeper的方法，事件等 提供了一个现代的流式接口 (提供了Recipes实现： 如前面的文章介绍的那样，基于这些Recipes可以创建很多复杂的分布式应用.这部分不明白，待补充)。\nCurator框架通过CuratorFrameworkFactory以工厂模式和builder模式创建CuratorFramework实 例。 CuratorFramework实例都是线程安全的，你应该在你的应用中共享同一个CuratorFramework实例.\n工厂方法newClient()提供了一个简单方式创建实例。 而Builder提供了更多的参数控制。一旦你创建了一个CuratorFramework实例，你必须调用它的start()启动，在应用退出时调用close()方法关闭.\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.curator\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;curator-recipes\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 这个版本的API 是流式的API，也就是。。用的时候一句话里有一串的调用，不断的点操作符。 for 一个zample: client.create().creatingParentContainersIfNeeded().forPath(node.getPath(), node.data()); 这并不是最长的。\n基本方式 # 声明两个变量，存zk信息。 /** Zookeeper info */ private static final String ZK_ADDRESS = \u0026#34;192.168.1.100:2181\u0026#34;; private static final String ZK_PATH = \u0026#34;/zktest\u0026#34;; 实例化客户端 // 1.Connect to zk CuratorFramework client = CuratorFrameworkFactory.newClient( ZK_ADDRESS, new RetryNTimes(10, 5000) ); client.start(); 目前zk还是空的，因为我们没有写数据。 先create一个ZNode，参数是路径和数据 client.create(). creatingParentsIfNeeded(). forPath(ZK_PATH, data1.getBytes()); 取数据 client.getData().forPath(ZK_PATH) 更多操作 // 获取节点的子节点 client.getChildren().forPath(\u0026#34;/\u0026#34;) // 修改数据 client.setData().forPath(ZK_PATH, data2.getBytes()); // 删除结点 client.delete().forPath(ZK_PATH); 监视器的使用 # 在curator中提供了三种监视器：\nPathCache： 监视一个路径下孩子结点的创建、删除，以及结点数据的更新。产生的事件会传递给注册的PathChildrenCacheListener。\nNodeCache： 监视一个结点的创建、更新、删除，并将结点的数据缓存在本地。\nTreeCache： Path Cache和Node Cache的“合体”，监视路径下的创建、更新、删除事件，并缓存路径下所有孩子结点的数据。\n监视器在client启动之后进行注册。\n// Register watcher PathChildrenCache watcher = new PathChildrenCache( client, ZK_PATH, true // if cache data ); 添加Listener watcher.getListenable().addListener((client1, event) -\u0026gt; { ChildData data = event.getData(); if (data == null) { System.out.println(\u0026#34;No data in event[\u0026#34; + event + \u0026#34;]\u0026#34;); } else { System.out.println(\u0026#34;Receive event: \u0026#34; + \u0026#34;type=[\u0026#34; + event.getType() + \u0026#34;]\u0026#34; + \u0026#34;, path=[\u0026#34; + data.getPath() + \u0026#34;]\u0026#34; + \u0026#34;, data=[\u0026#34; + new String(data.getData()) + \u0026#34;]\u0026#34; + \u0026#34;, stat=[\u0026#34; + data.getStat() + \u0026#34;]\u0026#34;); } }); 这一部分涉及到了lamda表达式的东西，决定下一篇就来学习一下lamda表达式和泛型编程这两个特性。\naddListener 方法的参数可以是一个匿名的函数，在监听到对应的消息的时候执行。也可以是一个接口，实现一个函数，函数包含两个参数(client, event)就可以被执行。\n这一点看了一个小时才理解出来，基础的Java特性不了解就是不行啊。\n关于zk的东西就先介绍到这里。基本上够我继续往下用的。\n同样都是写代码，不同的功力的人写出来的东西就是不一样啊。整个代码的大逻辑架构很清晰，但是写起来非常复杂。线程开的满天飞，监听器，触发器，写起来就像是组装一个巨大的流水线系统。非常的优美，没有暴力计算的感觉。\n下面的文章中有关于curator更深入的使用方式。\n"},{"id":44,"href":"/posts/web/tomcatserver/","title":"tomcat Server.xml及其启动顺序","section":"Web","content":"欲仙又欲死。阿里巴巴真是一朵大奇葩。 一个写死的回调地址就能浪费我两天的时间去搞，还没有搞定。此坑绵绵无绝期。 一个sso的回调地址，写死的，要强行将应用部署到ROOT里中去。\n在tomcat中有一个配置文件经常被用到，conf/server.xml。这个配置文件描述了如何启动tomcat server。 tomcat是servlet的容器，也就是能够运行servlet的一个程序。作为一个http服务的程序，可以监听端口，处理请求等。\n配置文件结构 # \u0026lt;Server\u0026gt; \u0026lt;Listener /\u0026gt; \u0026lt;GlobaNamingResources\u0026gt; \u0026lt;/GlobaNamingResources \u0026lt;Service\u0026gt; \u0026lt;Connector /\u0026gt; \u0026lt;Engine\u0026gt; \u0026lt;Logger /\u0026gt; \u0026lt;Realm /\u0026gt; \u0026lt;host\u0026gt; \u0026lt;Logger /\u0026gt; \u0026lt;Context /\u0026gt; \u0026lt;/host\u0026gt; \u0026lt;/Engine\u0026gt; \u0026lt;/Service\u0026gt; \u0026lt;/Server\u0026gt; 对我们来说，内层的Service才是有操作意义的部分。主要的部分简介如下：\n元素 说明 service 提供服务的主体，默认的名字是Catalina Connector 客户端与服务端之间的连接，包括端口，协议版本，超时时间，等。 Engine 请求的处理机，接收和处理Connector的请求， 与host的联系比较大 Context 表示一个应用 host 表示一个虚拟主机 Tomcat Server处理一个http请求的过程 # 假设来自客户的请求为：http://localhost:8080/wsota/wsota_index.jsp\n在这里有一幅图我觉得非常清晰的说明了这个过程，但是其本身跟这个毫无关系。\n请求被发送到本机端口8080，被在那里侦听的Coyote HTTP/1.1 Connector获得 Connector把该请求交给它所在的Service的Engine来处理，并等待来自Engine的回应 Engine获得请求localhost/wsota/wsota_index.jsp，匹配它所拥有的所有虚拟主机Host Engine匹配到名为localhost的Host（即使匹配不到也把请求交给该Host处理，因为该Host被定义为该Engine的默认主机） localhost Host获得请求/wsota/wsota_index.jsp，匹配它所拥有的所有Context Host匹配到路径为/wsota的Context（如果匹配不到就把该请求交给路径名为\u0026quot;\u0026ldquo;的Context去处理） path=\u0026quot;/wsota\u0026quot;的Context获得请求/wsota_index.jsp，在它的mapping table中寻找对应的servlet Context匹配到URL PATTERN为.jsp的servlet，对应于JspServlet类 构造HttpServletRequest对象和HttpServletResponse对象，作为参数调用JspServlet的doGet或doPost方法 Context把执行完了之后的HttpServletResponse对象返回给Host Host把HttpServletResponse对象返回给Engine Engine把HttpServletResponse对象返回给Connector Connector把HttpServletResponse对象返回给客户browser Context # 来看最重要的Context， 一般我们为每个应用做的定制化的东西都是依靠这个来做的，就比如我们要把war包部署成一个默认的应用。\n安装完以后tomcat的默认的主目录是webapps/ROOT，我们直接localhost就是去访问这个路径下的应用。如果我们要更改默认路径，改成我们的某个应用可以定制一个context，如下:\n\u0026lt;Context path=\u0026#34;/\u0026#34; docBase=\u0026#34;E:\\tomcatApp\\JeasyCMS\u0026#34; debug=\u0026#34;0\u0026#34; reloadable=\u0026#34;true\u0026#34; crossContext=\u0026#34;true\u0026#34;/\u0026gt; 参数说明 # path 是URL的路径。 docBase 是应用的文件路径，如果是开放的目录结构，直接写到目录的根目录中，如果是war包，需要将war包解包，然后写解包后的文件夹名。在此我要喷死网上的那些博主，写的什么JB玩意儿，我写war包的路径找了一天的原因，哼。垃圾。 reloadable 就是是否检测路径下的文件变化，即热部署的必要条件。\n在一个项目中我碰到了一个问题，就是一个项目提供的API是带项目名称来访问的，但是这个项目本身有一个组件，这个组件自己重定向到自己的项目的时候用的是不带项目名称来访问的，而且是写死的，很难改。\n也就是索，对于同一个项目有两种访问方式，我心一凉。这会肯定要被其他工程师骂是傻逼了，但是这也不是我写的呀，这个锅我不能背。\n于是奇迹就出现了。\nwar包部署在webapps下是会被自动解包发布的，如果我将根路径也定向到这个解出来的包不就好了。于是加了一个Context就解决了这个口大黑锅。\nappBase \u0026amp; docBase # 在host节点的配置中有一个appBase，这个路径是指，放在该路径下的web包或目录都会被自动发布，使用默认的方式发布。\n每个host都对应了一个域名，有的时候我们会把多个域名绑定到一个机器上，这时候我们可以通过配置不同的host来定向不同的请求。\n每个host下面，配置的是Context，每个context对应的是一个应用。所以可以配置应用的访问路径，并且配置其与实际路径之间的映射。\n"},{"id":45,"href":"/posts/java/javajsonandobject/","title":"Java Json And Object","section":"Java","content":"在写RESTFul风格的接口的时候最经常使用的就是Json和对象的互换。 今天记录一下阿里巴巴开源的FastJson的使用方式。\nFastJson号称最快的Json解析工具包。有幸听了作者的分享会，并且在前几天的转正答辩的时候，他作为我的面试官之一。花名很奇特，叫高铁，可能这就是FastJson为什么这么快的原因吧。\n在听分享会的时候，惊叹于其将一个小小的工具包中运用了如此多的优化方式。他曾是阿里安全团队的一元，对于Java底层非常了解，并且一些算法能力也很强，更是运用了产生式编程的神奇方式编写了这个工具包的某些部分。\npackage # 这是开源的工具，听闻，据说是阿里对Java社区做的最大贡献了。\nimport com.alibaba.fastjson.*;\nmaven: # \u0026lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.36\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; Example # 其对于json的操作都是在几个静态类中进行的。 举几个常用的例子来说名用法：\n将Json文本数据信息转换为JsonObject对象，通过键值对获取值 # private static void json2JsonObject() { //一个JsonObject文本数据 String s = \u0026#34;{\\\u0026#34;name\\\u0026#34;:\\\u0026#34;xxx\\\u0026#34;}\u0026#34;; //将JsonObject数据转换为Json JSONObject object = JSON.parseObject(s); //利用键值对的方式获取到值 System.out.println(object.get(\u0026#34;name\u0026#34;)); } 将Json文本数据转换为JavaBean # 需要注意的是，Json文本信息中的键的名称必须和JavaBean中的字段名称一致。\nprivate static void json2BeanM2() { String s = \u0026#34;{\\\u0026#34;id\\\u0026#34;:\\\u0026#34;xx\\\u0026#34;,\\\u0026#34;city\\\u0026#34;:\\\u0026#34;xxx\\\u0026#34;}\u0026#34;; //一个简单方便 的方法将Json文本信息转换为JsonObject对象的同时转换为JavaBean对象！ Weibo weibo = JSON.parseObject(s, Weibo.class);//Weibo类在下边定义 System.out.println(weibo.getId()); System.out.println(weibo.getCity()); } Map类型的数据转换为JsonString # Map\u0026lt;Integer, Object\u0026gt; map = new HashMap\u0026lt;Integer,Object\u0026gt;(); map.put(1, \u0026#34;No.1\u0026#34;); map.put(2, \u0026#34;No.2\u0026#34;); map.put(3, group.getList()); String jsonString = JSON.toJSONString(map); System.out.println(jsonString); // Map 套List的结构也可以。 有了上面几个例子就可以很明白了，在使用的时候还是用补全来看就可以了。\n一般的思路就是先吧Json转成JSONObject，然后进行操作。 如果是直接操作Json，就是用静态类JSON来做，JSONObject就是用JSONObject来做。\n在将Json转为对象的时候，要注意，对象的成员名一定要和Json中的键一致，都则就是null了。\n"},{"id":46,"href":"/posts/java/javahttp/","title":"Java HttpClient","section":"Java","content":"来记录一下Java 发起Http请求的方法。\n这里使用的是org.apache.http包中的一些封装工具。\n首先实例化一个client： CloseableHttpClient httpclient = HttpClients.createDefault(); 然后来实例化一个URIBuild： URIBuilder builder = new URIBuilder(url); 如果Http请求带有参数，就设置在uri中： builder.setParameter(key, value); 实例化一个Httpget/Httppost: HttpGet httpget = new HttpGet(builder.build()); HttpPost httppost = new HttpPost(builder.build()); 你可以设置请求的Header： httpget.setHeader(\u0026#34;Accept\u0026#34;, \u0026#34;application/json\u0026#34;); // 接收json数据格式 发送请求： CloseableHttpResponse response = httpclient.execute(httpget); 查看请求结果： if (response.getStatusLine().getStatusCode() == 200) { String content = EntityUtils.toString(response.getEntity(), \u0026#34;utf-8\u0026#34;); } 更多设置可以直接补全出来看。\n"},{"id":47,"href":"/posts/web/cookie/","title":"Cookie","section":"Web","content":"由于Http协议本身是没有状态的，每个请求都要建立新的连接。Cookie就是为了弥补这方面的不足而设计的，主要用来跟踪会话。\n会话 # 跟同一个机器中的同一个应用在一段时间内的通信交互，我们可以认为是一个会话(Session)。 会话与会话之间需要被隔离开。\n形象的理解 # Cookie就像是你的一张证明，并且，你跟不同的对方打交道用的是不同的证明。你会把这个证明带在身上，你可以在证明上写东西，对方也可以在上面写东西。在有需要的时候，双方都可以打开这个证明来看看里面的内容。 其本质其实就是一个键值对形式的文本信息。\n在控制台中，输入命令：alert(document.cookie) 就可以看到你与当前页面应用之间保存的cookie内容。 手机上的浏览器一般不支持cookie。\n跨域 # cookie是以域名作为单位的，同一个域名共享一个cookie。不同域名之间不能操作对方的cookie。 这里就是sso主要要解决的难点。\n跨域设置Cookie有几种实现的方式，其中最方便的就是使用jsonp的方式来实现。\njsonp 跨域 # 在JQuery中使用ajax可以处理同一域名下的重定向请求。但是其处理不了跨域名的重定向。\n也就是在同一个域名下进行重定向，ajax使得重定向对用户来说是透明的。但如果是跨域的，ajax就会报错。\n"},{"id":48,"href":"/posts/web/sso/","title":"sso 单点登录","section":"Web","content":"每天要接N多个需求，我也是很怀疑人生。本是在集群运维组干着运维系统开发，却被隔壁存储数据库组拉着每天做些数据结构思考题，虽然到现在我已经积攒了很多个思考题没来的及思考了。今天又来了个自己组的一个月前的bug要搞定。\n多应用服务下，实现单点登录，多点信任的方案。\nSSO的基本概念 # 在wiki上的解释非常清晰，比其本身的名字(Single Sign-On)更清晰：在一个多应用但彼此独立的系统上，只要进行一次登录就可以在不同的应用中获得信任。就是你在淘宝登录一下，然后你在咸鱼、tmall、阿里云等等网站上都不用登录了，就可以直接被识别出来，不过是在一定时间长度内。\n基本问题 # 实现这个系统有两个问题：\n用户数据统一 系统内信息统一 首先就是你的一个用户名和密码在每个应用上都能登录。其次就是在你登录以后其他的应用都能获取到这个登录信息。\n解决这个问题的主要思路就是建立一个公共的缓存，所有的应用都去这里提取用户的信任信息。有了公共缓存以后，问题的核心又转移到了客户端。因为客户端（这里就是指浏览器）在访问每个应用的时候所带有的信息是不一样的，所以你去缓存中也提取不到这个信息了。主要解决的就是如何让客户端在访问同一个系统中的不同应用的时候带有一个相同的ID信息。\nCookie # 这一部分的具体细节可以看下一篇博客。\nSSO的基本流程 # 在网上看到了很多实现方式的分析，还有人要步步深入，循序渐进。我觉得这个模型还是比较简单的，所以就直接来聊聊这个模型就可以了。\n我们模型要解决的问题是：跨域名的单点登录。 问题主要使用的技术就是Cookie。\n主要流程 # 本机客户端也就是浏览器，发起一个请求到目标应用的服务器。 服务器判断你没有登录，因为你没有携带任何的凭证信息在你的Cookie中。 于是给你返回一个302，302就是一个重定向的返回代码，并且与之匹配的还有一个参数也会被返回过来，就是重定向的目标地址。同时还携带了这个服务器自己的URL地址，也就是你最终要访问的那个。 浏览器接收到302和参数以后，自行发起一个到重定向地址的请求。请求中有一个参数，就是原目标地址。 链接上这个地址，并且这个页面一般就是个登录页面。登录完成以后，这个第三方的服务器会在你的Cookie里写一个TokenId，并且也返回给你一个302。这次重定向的目的地是你真正要访问的地址。 你的浏览器接受到这个参数就再一次发起请求，并且在Cookie中带有了一个TokenID。 目的服务器验证成功，登录成功。 对于上面的过程中有几个东西要解释一下。\n302 # 这是HTTP的一个状态码，表示暂时性的重定向到另外一个地址上去访问。在浏览器收到这个状态码的时候就去请求新的URL。\n在php代码中，我们写\u0026lt;?php header(\u0026quot;Location:http://ip/path/\u0026quot;); ?\u0026gt;就是返回一个重定向302的状态。基础知识很重要。\n在下一篇Cookie中，也有这方面的内容。\n如何认证 # 我自己用php写了一个简单的模型。还是比较简单的。 下面就按步骤介绍一下：\n修改本地hosts # hosts作为你的联通网络的第一个路由表，你可以做一些修改，比如给自己的电脑绑定n个不同的域名。 当然这个域名只在你的路由表中，所以只在你的电脑上管用。不过没关系，我们用这种方法模拟出了一个跨域名的环境。\nubuntu下hosts文件：/etc/hosts\n在其中添加：\n127.0.0.1 baiyan.a 127.0.0.1 paladnix.b 然后我们编写下面的几个php文件来模拟整个过程，文件位置在/var/www/html/sso/下。\n过程 # 首先我们去访问：http://baiyan.a/sso/hello.php\n\u0026lt;?php if( ($_GET[\u0026#39;uuid\u0026#39;]== \u0026#39;\u0026#39; || $_GET[\u0026#39;uuid\u0026#39;]!=553) \u0026amp;\u0026amp; ($_COOKIE[\u0026#39;uuid\u0026#39;]==\u0026#39;\u0026#39; || $_COOKIE[\u0026#39;uuid\u0026#39;]!=553 )){ header(\u0026#34;Location:http://paladnix.b/sso/log.php?call_back=http://baiyan.a/sso/hello.php\u0026#34;); } else{ setcookie(\u0026#39;uuid\u0026#39;, $_GET[\u0026#39;uuid\u0026#39;], time()+3600); echo \u0026#34;Hello \u0026#34;.$_GET[\u0026#39;uuid\u0026#39;].\u0026#34; \u0026#34;.$_COOKIE[\u0026#39;uuid\u0026#39;]; } 根据你的参数和cookie来确定是否要定向到登录站点。并将自己的uri作为参数附在后面。\n跳转到验证点\n\u0026lt;?php $call_back = $_GET[\u0026#39;call_back\u0026#39;]; if( $_COOKIE[\u0026#39;uuid\u0026#39;] == \u0026#39;\u0026#39; ){ header(\u0026#34;Location:http://paladnix.b/sso/loginh.php?call_back=$call_back\u0026#34;); }else{ $uuid = 553; setcookie(\u0026#39;uuid\u0026#39;, $uuid); //echo $_COOKIE[\u0026#39;uuid\u0026#39;]; header(\u0026#34;Location:$call_back?uuid=$uuid\u0026#34;); } 在这里判断一下对方最近是否有登录，也是通过cookie来判断，注意这里已经是另外一个域名了，所以cookie已经不一样了。没有登录定向到登录页面。\n\u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Login\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;login.php\u0026#34;\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;name\u0026#34; value=\u0026#34;\u0026#34; /\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;pw\u0026#34; value=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;hidden\u0026#34; name=\u0026#34;call_back\u0026#34; value=\u0026#34;\u0026lt;?php echo $_GET[\u0026#39;call_back\u0026#39;] ?\u0026gt;\u0026#34; /\u0026gt; \u0026lt;button type=\u0026#34;submit\u0026#34;\u0026gt;submit\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 在表单中添加了一个隐藏字段，call_back。填写信息并去验证。\n\u0026lt;?php $name = $_POST[\u0026#39;name\u0026#39;]; $pw = $_POST[\u0026#39;pw\u0026#39;]; $call_back = $_POST[\u0026#39;call_back\u0026#39;]; if($name == \u0026#39;baiyan\u0026#39;){ $uuid = 553; setcookie(\u0026#39;uuid\u0026#39;,$uuid, time()+1800); header(\u0026#34;Location:$call_back?uuid=$uuid\u0026#34;); } else { header(\u0026#34;Location:http://paladnix.b/sso/loginh.php?call_back=$call_back\u0026#34;); } 验证并且写个cookie，并设置半小时后过期。 然后就会跳转回去显示hello了。\n加密 # 上面的方式都是明文的非藏不安全，一般的做法，我们可以给cookie的内容加密。\n在验证方式上，现在是没有再验证uuid的正确性。有些做法会拿到uuid以后再发送给登录服务器去校验真伪。我觉得这个完全可以避免，可以设计一个算法，在本地验证uuid的正确性比较优。\n所以在编码uuid的时候我们可以将其有效时间也编在内，校验准确性的同时也也可以校验是否过期。我们可以再增加一个字段，使得uuid是由这个字段通过不可逆计算得到的hash值，然后到本地以后，重复这个算法，比对结果hash是否一致。\n逐步完善吧。暂时还没有时间。\n"},{"id":49,"href":"/posts/java/spring-2/","title":"每天读点Spring(2)--Start","section":"Java","content":"在本章中，作者开篇就讲到，学习一个新的开发工具最难的就是不知道从哪里入手，尤其是Spring这样有很多选择的框架。但是幸好在这本书中是简单的，下面介绍一些必要的基本知识。\n这就是很人性的化的写技术书籍的方式，透露出考虑之周到。 我觉得很多时候，国内的教育体制总是要用比人家多的时间去学会一个东西。很多人看到老外中学成绩都很差，到了大学才开始学习。但是仔细想一下就会发现不太对劲，为什么人家学习的深度比我们还深呢？明明没有我们的基础好，也没有我们花费的时间多啊。\n我觉得很大一部分原因是国内的教材有问题。很多教材都是非常的笼统的介绍一个东西是什么，然后就搬上一大堆理论出来证明。但是让人看了很费劲，因为我不一定就具备了看懂这个知识的基础能力，可能我要先去了解一下什么东西再来看这个会效果更好。在我看的很多国外工程师写的文档或者是书中，都有这样的设定，要么会给出在你继续往下看之前你需要去了解的知识清单，要么就直接把需要的知识写在正式内容之前。这是一个非常负责的行为，在人家眼里是很正常的事情，在我们这里可能就是不在我的工作范围中。就像初中上高中的时候，初中老师说这个你们在以后上高中就知道了，高中老师说，你们应该在初中就学过了。有些老师会讲，这些老师的学生就会很轻松的就掌握这部分东西。\n不要觉得什么都要别人告诉你很low，学习就是一个这样的过程，你需要别人不断的告诉你一些东西，那些已经被解决的问题不是你主要要解决的问题，而是你要快速掌握的理论。你在学车的时候如果碰到一个什么都不教，直接让你把车开起来上路的师傅，你就会说：“如果我什么都知道还要来学嘛？”，就是这个道理。\n国内很多作者纯粹就是急于求成，这些看似不是自己的责任的事情就不做，默认你会。然后把那些确实是核心的问题官方的表述一下，就算是写完了一本技术著作。很不厚道，我作为学生非常鄙视这样的人。\n需要具备的知识 # 也不能算是知识，是关于Spring的一些更细节的信息，和设计。\n理解Spring的包 # 这部分介绍了Spring是由哪些模块构成，你可以按照自己的需求选择使用那些模块，并介绍了每个模块的基本功能。\n在Spring4.0.2发行版中一共有20个包。每个模块的包名格式如下，以aop为例：spring-aop-4.0.2.RELEASE.jar\nJar File Description aop 如果你要用到AOP功能，或是你用到的Spring的其他模块用到了这个功能，你就需要把这个包添加进你的项目中 aspects 如果你用到了AspectJ AOP的功能就要包含这个包（Aspectj是Eclipse出的一个AOP的编程框架，Spring 兼容了它） bean 包含了所有用来实现Spring控制bean的类，其中很多类也都支持Spring的bean工程模式，例如解析xml和注解的类 context 这个包给Spring core提供了很多扩展能力，Spring的很多功能都依赖于此，并且实现交互的脚本语言也是集成在其中的 context-support 这个包有扩展了context的功能，例如邮件支持、模板引擎例如Velocity、FreeMaker，此外还有很多作业的执行和调度，例如CommonJ(计时器)和Quartz(作业调度)都打包在这里。 core 这是你必须包含的包，其中的类被用在很多其他的包中，并且有一些全局工具你也可以用在自己的代码中 expression 这个包是支持Spring Expression Language的，是一种强大而简洁的装配Bean的方式 instrument 这个模块包括Java虚拟机的引导(翻译有待确认)？当你在使用AspectJ时需要使用这个包 instrument-tomcat JVM Bootstrapping in the tomcat-server jdbc 数据库链接操作相关 messaging 是基于消息的应用相关的，以及支持STOMP消息文本协议 orm 扩展了JDBC，支持ORM框架，诸如Hibernate、JDO、JPA oxm 支持Object/XML Mapping (OXM) test 提供了强大的单元测试的功能，紧密集成了JUnit tx 支持分布式事物操作 web web功能的核心，支持了文件上传，参数解析等 web-mvc 支持MVC模式的web web-portlet 门户网站服务器部署支持（Not know） websocket 支持Java API for WebSocket（Not know） 随后讲了你可以用maven获取这些，就像你不知道maven一样\nExample # 下面作者将一个Hello World的程序通过演进，利用Spring来实现。\n首先在简单的Hello World就不写了。作者对于这个HelloWorld提出了两个要求，就是要能够动态的输出东西，并且能够支持输出到不同的目标上，并将这个项目改写成了下面的样子。\n增加了两个接口，一个是MessageProvider还有一个是MessageRender。\nMessageProvider:\npackage com.paladnix; /** * MessageProvider Interface * */ public interface MessageProvider { String getMessage(); } MessageRender:\npackage com.paladnix; /** * MessageRender Interface * */ public interface MessageRender{ void render(); void setMessageProvider(MessageProvider provider); MessageProvider getMessageProvider(); } 这两个都是符合JavaBean风格的接口。所谓JavaBean风格就是get和set一堆的那种。\n然后来实现两个实现其功能的类： HelloMessageProvider:\npackage com.paladnix; public class HelloMessageProvider implements MessageProvider{ @Override public String getMessage(){ return \u0026#34;Hello World\u0026#34;; } } StdOutMessageRender:\npackage com.paladnix; public class StdOutMessageRender implements MessageRender{ private MessageProvider messageProvider; @Override public void render(){ if( messageProvider == null ){ throw new RuntimeException(\u0026#34;You must set the property messageProvider of class:\u0026#34; + StdOutMessageRender.class.getName()); } System.out.println(messageProvider.getMessage()); } @Override public void setMessageProvider(MessageProvider provider){ this.messageProvider = provider; } @Override public MessageProvider getMessageProvider(){ return this.messageProvider; } } main:\npackage com.paladnix; /** * Hello world! * */ public class Hello { public static void main( String[] args ){ MessageRender mr = new StdOutMessageRender(); MessageProvider mp = new HelloMessageProvider(); mr.setMessageProvider(mp); mr.render(); } } 这样的代码就比原来的要高端很多了吧。但是依然是灵活性很差。然后作者引入了工厂模式，工厂模式可以看之前关于Spring的想关文章。这里就不介绍了，其本质就是反射。\nFactory # 下面来看工厂模式的实现方式。\nFactory\npackage com.paladnix; import java.io.FileInputStream; import java.util.Properties; public class MessageSupportFactory { private static MessageSupportFactory instance; private Properties props; private MessageRender renderer; private MessageProvider provider; private MessageSupportFactory(){ props = new Properties(); try { props.load(new FileInputStream(\u0026#34;msf.properties\u0026#34;)); String renderClass = props.getProperty(\u0026#34;render.class\u0026#34;); String providerClass = props.getProperty(\u0026#34;provider.class\u0026#34;); renderer = (MessageRender)Class.forName(renderClass).newInstance(); provider = (MessageProvider)Class.forName(providerClass).newInstance(); } catch (Exception e){ e.printStackTrace(); } } static { instance = new MessageSupportFactory(); } public static MessageSupportFactory getInstance(){ return instance; } public MessageRender getMessageRender(){ return renderer; } public MessageProvider getMessageProvider(){ return provider; } } HelloWorldWithFactory:\npackage com.paladnix; public class HelloWorldWithFactory { public static void main(String[] args){ MessageRender mr = MessageSupportFactory.getInstance().getMessageRender(); MessageProvider mp = MessageSupportFactory.getInstance().getMessageProvider(); mr.setMessageProvider(mp); mr.render(); } } Refactoring with Spring # main\npackage com.paladnix; import org.spring.framework.context.ApplicationContext; import org.spring.framework.comtext.support.ClassPathXmlApplicationContext; public class HelloWorldWithSpring{ public static void main(String[] args){ ApplicationContext ctx = new ClassPathXmlApplicationContext (\u0026#34;META-INF/spring/app-context.xml\u0026#34;); MessageRender mr = ctx.getBean(\u0026#34;render\u0026#34;, MessageRender.class); mr.render(); } } app-context:\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:p=\u0026#34;http://www.springframework.org/schema/p\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\u0026#34;\u0026gt; \u0026lt;bean id=\u0026#34;provider\u0026#34; class=\u0026#34;com.paladnix.HelloMessageProvider\u0026#34;/\u0026gt; \u0026lt;bean id=\u0026#34;render\u0026#34; class=\u0026#34;com.paladnix.StdOutMessageRender\u0026#34; \u0026gt; \u0026lt;property name=\u0026#34;messageProvider\u0026#34; ref=\u0026#34;provider\u0026#34;/\u0026gt; \u0026lt;/bean\u0026gt; \u0026lt;/beans\u0026gt; 这里配置的bean的装配方式。比如其中的StdOutMessageRender类是要依赖于HelloMessageProvider类的，所以就要配置property，使得messageProvider成员ref于provider， 也就是其依赖的bean的ID。 除了以来关系，我们还可以写value来初始化这个成员。\nMaven # 上面的这些代码都是我们抛开项目来说的，那么如何从Maven开始建立起这个项目作者并没有写，我在这里补充一下。\n首先在命令行建立一个maven项目：\nmvn archetype:generate 这个命令是用交互的方式进行配置项目基本信息的，想比较直接把配置信息写出来更便捷，尤其是在基础的Java项目结构中。 这个命令执行过程中第一个需要你填写或是选择的就是基本的项目结构，命令行中打印出了10个选项，每个项目选项都有一个说明，并且默认是第7个，我就是用的默认结构，最简单。\n随后还会有名字，也就是Maven项目的坐标信息了。\n建立完目录，接下来就把我们的代码放进去。把我们之前的代码都放在其中的src/main/java/com/paladnix，后面的目录是根据名字设定的，看情况就明白了。\n这个时候我们的配置文件我们需要建个文件夹来放。我们在main文件夹下建立一个resources目录，在其中建立路径：MEAT-INF/spring/app-context.xml。这个xml就是我们spring的配置文件了。\nresources文件夹默认是静态文件夹，在编译的时候这个文件夹中的东西会被原封不动的与class放在一起。所以内部的路径也就不会变，在java代码中，我们就直接引用这个子路径就可以了。\n然后目录基本上好了，接下来我们要配置一下pom.xml，主要就是两个事情，一个是添加spring的依赖；还有一个就是指定主类，因为我们打包以后执行这个包没有主类的话无法执行。配置成下面的样子：\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.paladnix\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springDemo\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;jar\u0026lt;/packaging\u0026gt; \u0026lt;name\u0026gt;springDemo\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.apache.org\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.3.3.RELEASE\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-shade-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;shade\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;transformers\u0026gt; \u0026lt;transformer implementation=\u0026#34;org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\u0026#34;\u0026gt; \u0026lt;mainClass\u0026gt;com.paladnix.HelloWorldWithSpring\u0026lt;/mainClass\u0026gt; \u0026lt;/transformer\u0026gt; \u0026lt;/transformers\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; 在其中我们只是配置了一个context的组件，但是mvn可以自己识别传递的依赖信息，将这个context需要的依赖默认添加进来，添加进来后大概有这些：\n├── dependency │ ├── commons-logging-1.2.jar │ ├── junit-3.8.1.jar │ ├── spring-aop-4.3.3.RELEASE.jar │ ├── spring-beans-4.3.3.RELEASE.jar │ ├── spring-context-4.3.3.RELEASE.jar │ ├── spring-core-4.3.3.RELEASE.jar │ └── spring-expression-4.3.3.RELEASE.jar 然后这些搞好以后我们就可以编译执行了：\nmvn clean package dependency:copy-dependencies # 将依赖的包一并打包进来。 然后执行jar包就可以看到HelloWorld了。\njava -jar target/xxxx.jar 以上就是第二章中的一些精华部分了，感觉这样跟着写下来会收获很多，比如工厂模式的实现方式，也更能借此实现来理解Spring是怎么做的。还有maven的一些使用细节，在编译的时候是怎么报错，如何看报错信息。在执行的时候发现spring的有个配置语法失效，然后换回了原始的方式去配置。\n整体的目录如下：\n. ├── pom.xml ├── src │ ├── main │ │ ├── java │ │ │ └── com │ │ │ └── paladnix │ │ │ ├── Hello.java │ │ │ ├── HelloMessageProvider.java │ │ │ ├── HelloWorldWithFactory.java │ │ │ ├── HelloWorldWithSpring.java │ │ │ ├── MessageProvider.java │ │ │ ├── MessageRender.java │ │ │ ├── MessageSupportFactory.java │ │ │ └── StdOutMessageRender.java │ │ └── resources │ │ └── META-INF │ │ └── spring │ │ └── app-context.xml │ └── test │ └── java │ └── com │ └── paladnix │ └── AppTest.java └── target ├── classes │ ├── com │ │ └── paladnix │ │ ├── Hello.class │ │ ├── HelloMessageProvider.class │ │ ├── HelloWorldWithFactory.class │ │ ├── HelloWorldWithSpring.class │ │ ├── MessageProvider.class │ │ ├── MessageRender.class │ │ ├── MessageSupportFactory.class │ │ └── StdOutMessageRender.class │ └── META-INF │ └── spring │ └── app-context.xml ├── dependency │ ├── commons-logging-1.2.jar │ ├── junit-3.8.1.jar │ ├── spring-aop-4.3.3.RELEASE.jar │ ├── spring-beans-4.3.3.RELEASE.jar │ ├── spring-context-4.3.3.RELEASE.jar │ ├── spring-core-4.3.3.RELEASE.jar │ └── spring-expression-4.3.3.RELEASE.jar ├── dependency-reduced-pom.xml ├── maven-archiver │ └── pom.properties ├── maven-status │ └── maven-compiler-plugin │ ├── compile │ │ └── default-compile │ │ ├── createdFiles.lst │ │ └── inputFiles.lst │ └── testCompile │ └── default-testCompile │ ├── createdFiles.lst │ └── inputFiles.lst ├── original-springDemo-1.0-SNAPSHOT.jar ├── springDemo-1.0-SNAPSHOT.jar ├── surefire-reports │ ├── com.paladnix.AppTest.txt │ └── TEST-com.paladnix.AppTest.xml └── test-classes └── com └── paladnix └── AppTest.class "},{"id":50,"href":"/posts/java/spring-1/","title":"每天读点Spring(1)--Introduction","section":"Java","content":"Java如果没有Spring，绝不会这么流行。 Spring将很多Java的设计模式框架化，使得Java的开发效率得到很大的增长。\n想系统的学习一下Java，但是又要与工作接轨，所以就选择了Spring这个中间的角色来开始学习。我学习的教材主要是英文版的《Pro Spring 4》，这本书在CSDN上有pdf版本，不是影印版，非常优质。 为什么不用中文的呢，一个是因为中文的书中在Introduction上就写得不好，无法从宏观上去解释这个框架的精髓，这个很致命，想比较外文版的读物，虽然偏长了一些，但是很对概念能够很清晰的表述，对于我这样的技术新人来说很重要。另一个原因是，本身的英语能力没有场景去使用，看看英文的技术专业书籍，有利于英语能力也更有利于以后看英文的代码注释。\n每天坚持看一点，是个很难的工作。\nWhat is Spring. # 在第一章中对Spring这个项目本身做了一些介绍。包括这个项目是在Java一片火热的情况下诞生的，并且诞生至今非常的优秀等等。\n我觉得最重要的是，作者解释了什么是轻量级这个问题。\n所谓轻量级并不是代码量很少也不是代码的框架设计很简单，而是一种传达除了Spring这个框架自己的思考哲学，就是让Java项目变得轻量化起来。\n随后介绍了Spring项目的两个最重要的技术基础，IOC(控制反转)或者在文中着重讲述的DI(依赖注入)的说法。在前面的文章中我已经介绍过这个概念，在设计模式上属于工厂模式的一种实现。还有一个就是AOP(面向切面编程)，也有人理解为面向方便编程。\n除了这两个重要的技术基础以外，介绍了Spring框架本身有非常多的方便的设计，兼容非常多的东西，在数据交互、xml、交互式脚本语言等方面都做了很多的工作，并且引起Java标准基金会的注意，影响了基金会的很多标准的制定等。\n介绍就是要这样，从宏观上去提纲挈领的介绍一个事物。\n"},{"id":51,"href":"/posts/self/alibaba/","title":"实习转正答辩","section":"Self","content":"今天下午进行了实习转正答辩，有很多经验总结下来。\n走进工作岗位的几个阶段 # 首先第一个是实习生面试，这个在每年的春招的时候会进行，也就是我进入阿里巴巴进行的第一次6轮面试。那个面试的经历想比较今天的经历其实是比较简单的。\n通过面试以后就算是一个试用期实习生了，大概会经历一个多月左右。实习生的试用期会做一些工作，并且这也是实习转正答辩的主要内容。\n如果通过了实习转正答辩，那就是正式的实习生了，我也是最近才知道的，原来这个实习转正是从试用期实习生转到正式的实习生，可见整个工作的流程是比较复杂的，压力也不小。\n在实习的后期跟你签了三方协议也只是一个录用意向的协议并没有法律效力。\n在你实习结束以后正式入职还有一段试用期，时间一般跟你的签约年限有关。签的时间长试用期也就相应的长。\n转正答辩的几点经验 # 在此次转正的答辩准备过程中，我觉得自己准备的比较好，但是忽略了一些情况，导致最后的发挥并不是很好。 这是经验的问题，因为接触的面试官不太多，所以在遇到某些问题的时候就脑子短路了。经验真的很重要，不同的面试官的关注重点都不一样，所以要不同的策略去应对。\n本次在做答辩的之前，我自知自己的工程功底不强，所以在准备做的工作的同时，还做了多一手的准备，那就是我最擅长的算法方向。打算以此作为自己的优势去提升自己在工程深度上的不足。 毕竟我是刚入行Java的新手，做工程一定不如很多一直做工程的人，另一方面自己这一个月接触的项目虽然多，但是并没有什么太深度的难点，所以也没有机会去解决，也就没有什么工作的亮点可以展现。\n我在工作的过程中自己学习了redis数据库中两个我认为比较有意义也比较有特点的算法，在我的博客中也写过。我通过这两个算法说明一个问题，就是数据库的发展方向可以脱离原本的通用解决方案，转为为特定场景设计实现算法来解决特定问题。\n用这样具有前瞻性的眼光来凸显自己的价值。\n这个方案在我做完ppt以后被我的师兄提出了没有意义。但是我坚持保留了这个东西。 随后在跟我的主管预汇报的过程中，主管表示很好，突出自己的优势而且这个思考很有价值。我觉得，这就是不同级别的人思维格局吧。东西就在那里，你能看到你才有可能拿到，看不到永远也拿不到。\n答辩的时候，其中一个人是FastJson项目的作者，这就是没有意料的地方。我以为会是一个偏管理+一个偏工程+一个hr的阵容。但是这个偏工程的又有点偏算法，面试官熟算法倒不是什么问题，关键是我们的算法认知不同。这就非常的尴尬。\n在第一个算法之后他问了一些算法的细节，尤其是在算法的最终实现是字符串还是int值的问题。 因为我本身是搞ACM的算法竞赛，这个竞赛的重点在于利用思维模型去解决问题，而不是去研究最底层的实现中节省掉的int和char之间的空间差距。当然我不是说这些东西不重要，当然重要。只是我并不去实现这个算法，所以也就没有去研究在实现的细节上是什么方式。另一方面，学习这个算法本身就不是我的工作范围，所以就没有时间去深究。 我只是想透过这个算法去发现数据库的最新发展方向。但是被面试官过于深入的带偏进入这么工程细节的问题是我没想到的。\n这就是面试中的一个常见的问题：\n同一个事情，关注点不同 # 我关注的是算法带给我的发展认知，面试官关注的是这个算法你有没有学的很深，有没有学到落地。 这很显然不是自己想去探讨的方向，所以这个时候要么你真的落地了，要么就要及时引导面试官到你的方向上去。但是最好的选择就是问不倒，无论你问什么我都能答出来，是最好。\n如果要在这个时候引导其实是不好引导的。因为面试官本身以为自己难住你了，你强行避开这个问题就会被打上学艺不精的标签。你还必须得正面的、恰到好处的回答这个问题。\n怎么回答这个问题呢，就要敢想，随机应变开始跟面试官讨论。比如面试官问你为什么不用int编码，这个时候你就要有个折中的回答，一般就要根据现实需要来选择存储的实现方式。随后千万不要贸然的回答问题，一定要把这个问题问的足够细以后再选择性的回答。在问问题的时候也要引导到你擅长的方向。当你说出根据不同的场景会有不同的实现方式的时候，就给了自己提问的主动权，就反问面试官你想比较他们两个之间的哪个方面，是解析时间上、计算上、存储上、取数据上等。然后不断的细化到一个用基础理论可以解决的问题，你就完成了完美的反杀。\n一般计算机上的实现总是这样的，在时间和空间上取舍、在存数据速度和取数据速度上取舍、在计算方式上取舍。所以这样的问题总是能够曲线来回答的，千万不要慌。然而当时我就慌了，回答不是很完美。\n有些面试官其实就是丢个问题给你，他自己也没有思考很多。所以当你开始跟他讨论的时候，把这个问题抛给他，如果他也没想清楚具体要问你什么，你就可以开始引导了。如果你熟悉算法的计算效率问题，那就往时间效率上引，你熟悉数据存储的东西就往存储上引。实在没有什么擅长的问题就跟他来这么几个来回，他也不会给你个差评的。往往有些时候深入下去，面试官本身也不擅长了，也就不深究了。\n扩展出来问你 # 当你提到一个东西以后，面试官往往会扩展出来问你一些东西，问你既然懂这个你懂不懂其他的相关的啥啥啥。\n这也是比较棘手的问题，事实上你也真的没有机会或时间去学习扩展那么多，毕竟你才学习了这几年，又要宽度又要深度是很难的，同样你也不能就直接避开这个问题。\n对于这个问题，其实就没有上面的那么好扭转，你只能打打心理战。毕竟扩展的知识有哪些，你不知道也没办法把问题细化到可以理论解决的地步。我推荐的做法是变成一个弱者。去请教对方，这个东西还有哪些扩展，自己可能精力有限，或不是专业搞这个，就没有覆盖到那些。对方如果是个门清儿的专家，回答了你，你就赚了，你还有个好学的印象。如果对方也不懂就诈诈你，那他也就不会在这个问题上继续了。自己不会的东西，别人也不会也不会就给你差评的。\n没见过的名词一定要问一下 # 然后在实现的细节上我们简单的交流了一些，他提到了前缀树。\n尼玛，后来我才知道这个前缀树是字典树的别名，而且是20年前的名字。我说我不知道，我知道后缀树。后缀树的复杂度是字典树的10倍，但是这个面试官不知道。。。很遗憾这个问题又GG了。\n所以遇到相关领域你没听说过的东西，就不太可能。面试官问出来的问题一定不会非常深入的东西，都应该是你至少听说过的东西。更何况我一个搞算法的怎么会没听过一种树结构呢？\n这个时候应该就是叫法不同，问一下这个东西有没有什么别名，或是实现方式是什么。应该很快你就知道这个东西是什么了，即使不是很清楚，从一些信息中也能知道个原理大概，跟面试官简单吹吹还是可以的。\n问我既然是学算法的，有哪些你会的不是教科书上的算法 # 这个问题，我草。我被问蒙了，我怎么知道哪个算法不是教科书上的算法啊！你说哪个不是书上的？ 然后这个问题我就跟没回答一样，说了一点疑惑和解释他就继续下一个了。\n其实，面试官本身想问的问题，重点不是教科书。而我抓错了重点。他事实上是想问你有什么算法是一般人不会的，而你会。再换句话说，是他不会而你会的。\n这样理解这个问题以后，尼玛，这不正中我下怀了。这简直就是装逼时刻，此时不装逼更待何时，打比赛的那些神奇算法名字往外扔就是喽，我特么能给你说一下午。\n然而，我当时没有反应过来。失策失策。。。\n总结了一下，一向唬得住面试官的我为什么犯这么低级的错误呢? 我认为就是被前面的几个问题给问虚了。几个出乎意料下来，整个人的气场都下来了。下面就开始被各种蹂躏。\n所以，一定要不能虚，虚个蛋蛋。\n一个堂堂金牌爷，总有你会他不会的东西，虚个蛋！就算他问的问题你不会，这又怎么了。要自信，老子又不干你的工作，干嘛会你的那套。况且我今天不会我明天就会，不行嘛！ 在此基础上，做到态度好，技术硬，来者不惧，能屈能伸。忽悠个面试官还是小菜一叠。\n"},{"id":52,"href":"/posts/java/java-5/","title":"Java 多线程实现异步调用","section":"Java","content":"异步调用最主要的特点就是调用方并不等待函数的结果，而是继续进行下面的动作，函数自己去完成相应的过程。在函数完成以后将结果以某种方式返回给调用者。\n实现异步的方式有很多，在前端的技术中使用的最多，这里我记录一下Java项目的内部自己异步调用某个函数的方式。\n角色 # 在异步调用中，有三个角色，分别是消费者、取货凭据、生产者。对应的就是调用方、数据返回方式、执行函数。\n举小蛋糕的例子非常好理解，订蛋糕、蛋糕店给你个取蛋糕的收据，或者也可以给你送到某个地方、蛋糕店生产蛋糕。\n消费者 # 首先来看一下调用方的代码应该怎么写。\npublic class Customer { public static void main(String[] args) { System.out.println(\u0026#34;main BEGIN\u0026#34;); CakeShop host = new CakeShop(); Cake cake1 = host.request(10, \u0026#39;A\u0026#39;); Cake cake2 = host.request(20, \u0026#39;B\u0026#39;); Cake cake3 = host.request(30, \u0026#39;C\u0026#39;); System.out.println(\u0026#34;main otherJob BEGIN\u0026#34;); try { Thread.sleep(2000); } catch (InterruptedException e) { } System.out.println(\u0026#34;main otherJob END\u0026#34;); System.out.println(\u0026#34;cake1 = \u0026#34; + cake1.getCake()); System.out.println(\u0026#34;cake2 = \u0026#34; + cake2.getCake()); System.out.println(\u0026#34;cake3 = \u0026#34; + cake3.getCake()); System.out.println(\u0026#34;main END\u0026#34;); } } 代码先实例化一个蛋糕店，然后再下了三个订单，然后去做其他的事情了。在睡眠了多久以后执行了单据的getCake方法获取蛋糕。\n所以这里就涉及到了三个类，分别是蛋糕店、消费者、蛋糕。\n蛋糕店 # 看一下蛋糕店在收到订单以后做了什么\npublic class CakeShop { public Data request(final int count, final char c) { System.out.println(\u0026#34;request(\u0026#34; + count + \u0026#34;, \u0026#34; + c + \u0026#34;) BEGIN\u0026#34;); // (1) 建立DeliveryOrder的实体 final DeliveryOrder order = new DeliveryOrder(); // (2) 为了建立RealData的实体，启动新的线程 new Thread() { public void run() { //在匿名内部类中使用count、order、c。 CakeBaker cakeBaker = new CakeBaker(count, c); order.setCakeBaker(cakeBaker); } }.start(); System.out.println(\u0026#34;request(\u0026#34; + count + \u0026#34;, \u0026#34; + c + \u0026#34;) END\u0026#34;); // (3) 取回FutureData实体，作为传回值 return order; } } 蛋糕店在收到订单以后就实例化了一个对应的篮子，我们假设这个蛋糕店是将蛋糕放在篮子里交付的。然后新起了一个线程去生产蛋糕，并且生产完以后将蛋糕放在篮子里。这些都是在新的线程中做的。\n线程一旦建立起来，这条语句就完成了，线程自己的生命周期就是操作系统和进程的事情了。所以在起完线程以后就直接将这个篮子返回给顾客，虽然这个时候篮子是空的。\n那么顾客在需要取蛋糕的时候就调用这个篮子的取蛋糕的方法就可以获得相应的蛋糕了。如果在消费者取的时候蛋糕还没有做完，那消费者就得决定是否要等，如果不等就浪费了，如果等的话就写个循环等好了。\n当然等的这个步骤可以不用用户自己写，在篮子的代码中我们要写一下，如果没有蛋糕在篮子里就等待，这样等待的步骤就回到了主线程中了。直到等到蛋糕才返回继续执行。\n"},{"id":53,"href":"/posts/java/spring-shell/","title":"spring-shell","section":"Java","content":"这是一个spring框架提供的编写shell命令的一个工具，能够让你用spring的编程模式编写命令支持在shell运行。\n看一下这个工具的框架是怎么样的。documentation地址。\n核心组件 # spring shell 的最核心的组件是三个：plugin model、built-in commands and converters。\nPlugin Model # 插件模块我理解的就是将你写的命令加载进去。你的每个jar模块都要包含一个文件：META-INF/spring/spring-shell-plugin.xml。这个文件会在shell启动的时候被加载并生成Spring的上下文。 在这个文件里你需要定义你的命令相关的类。当然你也可以用spring的扫描功能去自己扫描一个包，然后自己将相关的类进行加载。\n这个文件可以写成这样：\n\u0026lt;beans xmlns=\u0026#34;http://www.springframework.org/schema/beans\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns:context=\u0026#34;http://www.springframework.org/schema/context\u0026#34; xsi:schemaLocation=\u0026#34;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd\u0026#34;\u0026gt; \u0026lt;context:component-scan base-package=\u0026#34;org.springframework.shell.samples.helloworld.commands\u0026#34; /\u0026gt; \u0026lt;/beans\u0026gt; 这里官方的文档说：所有的类都是用同一个类加载器加载的，所以建议提供一个类加载器进行隔离。\n这些命令是Spring组件，使用@Component注解进行划分。例如，HelloWorldCommands类的示例应用程序是这样的\n@Component public class HelloWorldCommands implements CommandMarker { // use any Spring annotations for Dependency Injection or other Spring // interfaces as required. @CliCommand(value = \u0026#34;delete-group\u0026#34;, help = \u0026#34;delete group\u0026#34;) public String deleteGroup(@CliOption(key = {\u0026#34;id\u0026#34;}, mandatory = true, help = \u0026#34;The id of \u0026#34; + \u0026#34;the group\u0026#34;) final String id) { ClientResponse response = RestClient.delete(GROUPS_RESOURCE_URL + \u0026#34;/\u0026#34; + id); return response.getEntity(String.class); } } Converters 转换器 # 这个转换器是将输入的字符串转换为Java的对象，基本的转换器可以实现基础的对象的转换，包括Date、charactor、File等。\nBuild in Command # 是一些内置的命令，包括清空控制台、显示当前日期、帮助、退出等。\n总结 # 这个东西其实并不是用来开发终端命令的，一般我们的终端命令都是C语言开发的，或者是bash等。这个事实上是给一个Java项目提供一个更方便的交互途径，比如我们某个应用需要用Java来做交互来做控制，能够有一个终端命令的方式是最方便的，所以，是个加分项。等以后做的项目多了以后就会用到了。\n"},{"id":54,"href":"/posts/java/status/","title":"状态机编程","section":"Java","content":"状态机是一种程序设计模式。\n这种设计模式适合在一些场景下使用，比如一个任务可能拆开成不同的部分去做，这些动作可能是异步的也可能是同步的，这个时候我们用一个for循环来搞就会很麻烦，最重要的是很丑。\n我们希望能做成事件驱动的程序，这个时候一个很好的设计模式就是利用状态机的思路来写。\n问题特征 # 一个处理流程中一些部分都可以是异步的，并且每个步骤都有可能失败。\n其实最主要的就是这个问题可能失败，所以我们希望在我们将失败的原因搞定以后，再次启动这个程序的时候可以继续从上一次失败的地方继续执行而不是将原来的操作进行回退，然后再重新跑一遍。\n状态机编程 # 使用状态机的设计模式可以让程序直接跳到当前状态所处的位置，继续执行。\n其实是很简单的，我们给我们的每个步骤都设计几个状态，最常见的状态就是start、success、faild等。\n并且在一个状态结束以后会去回调一个函数去更改相关的事件的状态。将事件的状态保存在一个诸如数据库或是什么东西上。\n这种设计思路可以应用在很多场景下，比如一个用户的行为会触发一个后台流程，后台要在做完这个流程以后再把结果返回给用户。如果等待程序返回就会浪费很多时间，很可能中间的某个环节失败了，这样的话又要重新来搞一次。\n如果用状态机的设计模式，行为触发状态机的一个点，然后由状态机做后续的出发，等到收集到所有事件都成功以后再给用户返回个结果就可以了。同时用户也可以将这个请求做成异步的，不必等待程序的返回值。\n对于状态机编程的事件，有一个最重要的一个就是事件的触发是由于状态的改变来触发的，所以只要我们去更改一个事件的状态我们的这个动作就算是做完了，至于触发的动作什么时候做完我们不管，会有一个状态标识的方式的。\n思路就是这样的，具体的实现代码以后写其他的东西的时候再贴吧。\n"},{"id":55,"href":"/posts/c++/c/","title":"随想-关于语言的一些感受","section":"C","content":"以前觉得C语言很菜，因为连面向对象都没有，一本C语言的书也就200页撑死了。\n后来学习了C++，一本书动不动800页，多则1500多页，我以为C++很屌。\n后来我接触了Java，发现这个语言虽然用的人很多，但是，很不优美，是一个非工程师可以用的东西。我还是觉得C++很屌。\n再后来我接触了python，我觉得这个语言的作者是个奇葩，不过确实很多工具很方便，这个就是个功能偏强大的玩具了。但是确实很厉害，开发速度飞起来。不过我还是觉得C++很屌。\n后来接触了bash脚本，哎，这个语言很有趣，但是很鸡儿菜，写起来别别扭扭的，就像搭积木一样，还不能搭太高。不过我还是很喜欢它的，但是我还是觉得C++很屌。\n然后用起了php，虽然也是菜鸡儿，但是真的很直白嘛，是个人都能懂。所以C++还是屌。\n最近用起了Javascript。我操！这语言特么有毒，乱七八糟的问题，虽然应用范围越来越多，但是还不那么优美，还是C++比较屌。\n然后我发现了一个神奇的现象，Linux用C语言写的，mysql用C语言写的，各种驱动C语言写的，各种网关C语言写的，redis也是用C语言写的。为啥?\n这说明了，特么的C语言才是最屌的。短短200页就道尽C语言精髓，短短200页就构建起了这个世界的一半基础。C语言有的除了指针，就是指针，再花哨一点的就是有函数指针这个大杀器。\n那些说什么C语言指针难用应该都是傻逼吧。真正的程序员，指针就是万能的上帝之手好嘛！\n至于C++，很强是实话，能驾驭C++的程序员也很强，这是大实话。但是，能驾驭C++的不多，这就很尴尬了。要对象有对象，要指针有指针，要动态绑定有动态绑定，要多态有多态。。。但就是出了Bug不太好找，没办法，就有点失宠了，不过说到底还是因为人菜！语言是好语言，所以C/C++最屌！\n不要跟我说什么生产力，老子不Care！我不管！我就是喜欢，走不动道了。\n"},{"id":56,"href":"/posts/redis/redis-1/","title":"Redis 深度学习(1)","section":"Redis","content":"如果人生没有看过一个数据库的源码，那与咸鱼有什么区别。\n准确的说，我所会写的代码都是从别人那里看来的。但是我所会写的代码就那么点儿，实在不怎么拿得出手。刚好遇到这个源码只有2万多行的纯C语言的数据库项目，怎么都得读读，否则不敢说自己会写代码。\nRedis 简介 # 在之前有一篇关于redis的简介和安装的文章，所以就不从宏观上介绍了。\n与memcached相比有下面这几个特点：\nRedis不仅仅支持简单的k/v类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式的数据备份。 Redis支持数据的持久化，可以将内存中的数据保持在磁盘中，重启的时候可以再次加载进行使用。 Redis可以实现主从复制，实现故障恢复。 Redis的Sharding技术： 很容易将数据分布到多个Redis实例中 GitHub地址\nRedis是单线程的，运行在CPU的一个核上。所以在线程的思路上整个程序是很清晰的。我主要从代码中学习一些网络编程的方法，C语言数据结构的写法，内存操作。\n在redis4.0.1中一共有600多个文件，包含了C文件、bash脚本、Lua脚本、tcl脚本，额，，还有一些没见过的东西。太菜了，连文件后缀都没见过。\n但是这些并不都是redis的代码，在src/文件夹中可以看到只有120多个c文件，这些才是核心。600多个是包含了一些测试文件和单元测试等等。\nRedis的数据结构 # redis对外提供的数据结构在上一篇中也都介绍过，这里带着介绍一下其内部实现的方式。\n"},{"id":57,"href":"/posts/redis/hyperloglog/","title":"HyperLogLog 基数估计算法","section":"Redis","content":"在redis中还有一个很奇怪的部分，Hyperloglog。看到这个东西后我的第一反应跟大多数人一样，这个日志的东西是干什么的？\n然而这并不是日志，而是一个十分高深的玩意儿，他的主要功能是估算诸如一个集合中的不同元素的个数，也就是基数估计。\n这个算法号称用1.5Kb内存为十亿对象计数。\n下面就来看一下这个算法，其实我也没有完全搞懂这个算法的所有细节，就简单的介绍下就好了。\n背景 # 我们有很多场景，需要计算一个MultiSet的基数，如统计网站的访问IP数量等。\n传统做法 # 在传统的做法中，我们可以开辟一个数据表每次累加出来。但是这个开销无论从时间上还是空间上，当数据量变大以后会变得十分巨大。随着一个参数的增长所以整个系统的参数都应该在上升，也就是说整个数据库系统都在面临巨大的压力。这个时候如果还这样做就很不明智了。\nBitMap # 后来就聪明点了，这个应该就是程序员想出来的。\n就是把每个IP映射到一个内存bit上，出现了就置1，没出现就是0。然后统计一下个数就可以了，抑或一下嘛。但是这个在空间上只做了个常数优化，搞过ACM的都明白，常数优化不算优化。\nLinear Counting # 这个算法就是一个有一定数学基础的程序员搞出来的。\n将IP映射到m个内存bit上去，然后还是统计1的数量，但是用最大似然估计的方式来估计总数的大小。这个在数学上是说的通的。\n算法要求映射函数符合均匀分布，那么当基数很大的时候可以用正态分布逼近二项分布，正态分布的期望的最大似然估计是样本均值。所以我们就用这个最大似然估计来统计这个基数。\n但是这个理论在很多情况下会有很大的误差，并且其对于m的要求很多，所以其空间复杂度也没有优化到哪里去。\nLogLog Counting # 这个时候你应该懂标题中的LogLog是什么意思了吧，并不是日志的意思，而是算法复杂度。\n这个算法对于Hash函数有下面几个要求：\nH的结果具有很好的均匀性，也就是说无论原始集合元素的值分布如何，其哈希结果的值几乎服从均匀分布（完全服从均匀分布是不可能的，D. Knuth已经证明不可能通过一个哈希函数将一组不服从均匀分布的数据映射为绝对均匀分布，但是很多哈希函数可以生成几乎服从均匀分布的结果，这里我们忽略这种理论上的差异，认为哈希结果就是服从均匀分布）。\nH的碰撞几乎可以忽略不计。也就是说我们认为对于不同的原始值，其哈希结果相同的概率非常小以至于可以忽略不计。\nH的哈希结果是固定长度的。\n以上对哈希函数的要求是随机化和后续概率分析的基础。后面的分析均认为是针对哈希后的均匀分布数据进行。\n这个算法的基础是伯努利试验以及其推论。\n伯努利试验是说：一次实验的结果只有发生和不发生两种，重复做这个实验，直到结果发生为止，记录下实验的次数。\n然后讲与我们这个算法的联系。 算法的思路前面还是差不多，先把每个元素都Hash到一个固定长度的二进制串。那么这些二进制串最高位1的位置就符合这个定义。每个串都是一个伯努利过程，最高位1的位置就是第一次事件发生的试验次数。\n回到理论本身，理论本身并没有给出解决这个问题的结论。但是在其一些推论的公式中隐含了我们要求得的基数，也就是伯努利过程的数量。\n由两个问题引出这个公式：\n进行n次伯努利过程，所有投掷次数都不大于k的概率是多少？ 进行n次伯努利过程，至少有一次投掷次数等于k的概率是多少？ (公式回头补，页面不支持latex很鸡肋)\n这两个公式我们考虑极限情况的时候，就会发现，n就在2^k附近。这个就做为n的粗略估计。\n下面就是要做偏差修正了。\n"},{"id":58,"href":"/posts/self/internship/","title":"关于实习-alibaba Middle Ware","section":"Self","content":"阿里巴巴中间件团队是一个技术水平非常强的团队。\n首先想谈一谈，实习本身，我对实习的认识。\n作为一名技术向的学生，实习的经历是十分重要的。如果有机会，最好从大二的暑假就开始出去实习。事实上无论你是什么方向的学生，实习都是非常重要的。\n实习有这么几个目的，这几个目的也是我在选择实习单位的重要考虑因素。\n体验未来几十年的工作生活。 了解业界的真实现状。 学习新的技术。 检验自己的能力。 指导自己未来的路。 下面就具体的展开来说一说，个人见解。\n体验未来的工作生活 # 这真的是最最重要的事情，因为你未来将有40年的时光在工作的状态，在你真正要走进这段时间之前能有一个实习的机会去体验这样的生活会让你做好很多准备。\n在上学的时候特别渴望工作，觉得上学很无聊，也很不自由，也没有收入。但是从我听说的同学的工作经历，我看到的阿里巴巴杭州西溪园区的1万名员工的生活状态，我觉得实习的这重意义很重要。 不同的公司，不同的岗位，不同的同事，上级，城市\u0026hellip; 这些因素会让工作之间产生巨大的差异，你要在这段时间想清楚一些事情。\n你要在什么样的岗位工作 你想跟什么样的人共事 你要在什么样的城市 \u0026hellip;.\n而这些事情有一些原则，是我觉得在这些问题中很重要的东西。\n第一，一定要做一件你喜欢的工作。如果你做什么事情不开心，做什么都没有意义。这个工作不是非你不可，但是你自己的心情只是你自己的。至于心情好才能工作好这样的东西，谁都懂的大道理就不用我多说了。我想说的是，当你心情不好在工作的那段时间，在以后的你看，是极大的罪恶，对自己生命的美好时光的罪恶，所以一定要把自己的时间用来做让自己开心的工作。\n第二，一定要跟聪明人共事。因为与不聪明人共事会导致你工作的不开心。\n第三，要在一个有交流的队伍里工作，后面会讲到为什么。\n当你体验过后，就会明白自己想要的工作到底是什么样子。 这也是马云在前两年回应阿里校招大规模缩减时所说的：”我们想要的是清楚自己要什么的人，那些还不清楚自己的要什么的人让他们去其他地方搞清楚再来吧。“\n了解业界的真实情况 # 都说学校学习的东西与现实脱轨，那么到底现实是什么样子，这就是最真实的现实了。至于学校教的东西怎么样，下面也会讲到。\n但是了解业界真实情况并不是为了回答上面这个传闻，而是要清楚的明白自己所学所做的东西是否是正确的方向，\n举个例子，我所在的存储事业部是阿里的重要数据库的开发运维团队。其使用的数据库技术与我在大学接触的数据库技术有何差异？差异很大，但是我在大学学习的东西并非被淘汰，也并非没有用处。阿里的业务规模决定了其数据库的并发抗压能力到了业界的顶尖水平，这一点是在学校以及其他公司所见不到的，在这些技术的发展上确实与以前我所认识的数据库差距很大，包括数据库集群这些东西我都是没有接触过，也没有老师有这方面教学的尝试。对此我只能表示很遗憾。还有就是我学习数据库的时候Nosql这种数据库已经被阿里应用出来了，而我们只是简单的了解了一些。\n这些都是学校学习的不足。但是必须得说，学校中学习的数据库原理等课程是必须掌握，极其重要的，是这些技术的基石。所以学校的课程并没有脱离现实，只是我们可能更担忧自己跟不上技术潮流，其实没有必要，基础的知识是必须掌握的。\n那么知道了业界的现实，也知道了工作的要求，在以后的学习中就不会在去问：我该学底层技术还是上层应用。当然都要学，都要会。那么应该先学那个？有时间就多学学底层，时间少至少要会应用。\n学习新的技术 # 这就是在工作中的需要了，而不是自己的主观能动。 在工作的岗位上一定需要学习新的技术才能完成任务，所以这一点不必多解释。\n但是需要说的是，如果仅仅学习了完成工作的那些，就浪费了这个好机会。\n什么机会呢？应用场景。\n以前的学习，更多是在知识层面，现在的学习是依托于现实需求，有机会在这个应用场景中学习。在用中学往往有更好的效果，所以要更深入一些，更广泛一些。更何况你周围有一群相关技术的专家可以请教。\n这里就要讲一下上面提到的，要在一个有交流的队伍中工作。\n这个时候就要想一下，实习的共作给你提供了最有价值的的东西是什么？除了以上我们讲到的这些和工资以外，就是你周围的人。\n你周围的那些前辈给你简单的聊一聊的东西，都有可能需要别人很长时间才能获得，那些是可遇而不可求的\u0026ndash;经验。这个东西你能获得的越多，你要走的弯路就越少，对于一个在浩瀚技术点迷茫的人来说，可以节省好多时间。学习经验的代价比学习任何知识的代价都高，所以学技术不是最重要的，学经验才是真正要做的事情。\n检验自己的能力 # 这个能力当然不是你曾经学到的东西，而是你的适应能力与学习能力。\n新的环境，新的模式，新的技术。这些都在检验你的适应与学习能力，这决定了你换下一个工作之前要做的准备。\n换工作是一个很正常的事情，各种原因。一但当你需要换工作的时候，你是否有足够的底气去换就决定了你是否能解决面临的困境。一个依靠长期业务经验工作的人，是底气不足的，一个能快速掌握新的工作技巧的人是很容易做到快乐工作的，因为你可以走嘛。当然如果是个人原因不适合工作，去哪也没用。\n指导自己未来的路 # 接触了很多人，很多技术，很多经验。你就清楚的知道自己要去工作还是读书，是要去哪里工作去或是哪里读书。在未来的几年应该如何度过。\n我的实习经历 # 面试 # 在偶然的机会碰到辅导员，让他给我参考一下简历，刚好他有在阿里工作的同学，就帮我做了内推投递。本以为内推会很轻松就进去，后来才知道，几乎大家都是内推，没什么区别。\n面试一共6轮，5轮技术面试+hr面试。很吓人，确实是国内面试流程最长的公司之一了。\n第一轮面试开始以后我就意识到自己贸然用阿里的面试来做第一次面试不是什么明智的选择。因为我根本就没有任何准备，包括自我介绍。\n自我介绍是每次都要做的，因为每次都是不同的人。\n面试的技术问题偏基础知识，操作系统原理，计算机网络，数据结构，数据库，算法，编译原理等。还会问一问你做过的项目等。\n面试的过程有什么经验？不存在的，好好学习，多思考。\n在hr面试的时候，会考察你的价值观和性格等，决定你是否适合这个团队，当然也会问一下你的未来打算。\n入职工作 # 入职那天，有60人左右，10几个学生，2个本科生。还好，我跟他们聊的挺起劲。\n加入团队的第一天晚上集体聚餐，团队有17个人左右，反正都是土豪，要么就是在成为土豪的路上。什么3套房产专业房产中介业余工程师的老司机，一套400万房产追尾修车灯6万的道爷。。。\n每月团建出去吃饭，桌游这些是大多数公司标配，没啥好说。\n工作的内容我也没挑，听安排，反正都是搬砖。但是工作第一天就给了我3个项目和三台服务器让我部署上去，我真的很绝望。\n工作前期不是Java就是python，要么就是把一个python项目重写成java的。作为一个只会Java语法不会python语法的我，更绝望了。\n到了现在，后端接口也要写，前端页面也要做。心很累。羡慕某为的某谈同学每天可以打打游戏就完成工作还可以领奖金。更羡慕某软的同学每天吃吃零食按时下班回家开黑。\n但是自己选的公司，就算连续20天39度也要顶着烈日去上班。然后载坐在工位上抵抗这个夏天的严寒。\n阿里的工作生活怎么样？习惯就好。 每天大概9点半上班，迟到也没有什么关系，不过迟到总归是不太好的嘛。下午6点吃饭，吃完饭就是下班时间了，然而我们团队一般都会继续玩一会儿再回家，这也引得一位刚入职的研究生妹子在一次没有boss的周会上谈论起了这个问题。对于她们来说，这个问题值得思考，对于我来说，这个问题就算是有结论了。\n阿里这家公司与其他几家不同，技术实力很强是事实，但是与技术一起积淀下来的，还有代码的复杂性，系统的混乱性等。所以在阿里做一件别人做剩下的事情是很痛苦的，但如果你做的是别人没做的就舒服多了。\n最重要的还是开心，不开心就没有意义了。\n"},{"id":59,"href":"/posts/java/springmvc/","title":"SpringMVC","section":"Java","content":"本文是我的学习过程，但是我认为学习过程中并不适合写给别人看。所以本文只是一个临时的笔记，待以后进行深入整合。\nSpringMVC与Spring的关系是什么? SpringMVC是依托Spring框架开发的一个Web MVC框架，天生与Spring集成，也就是使用了Spring的依赖注入和切面编程。\n上一篇中讲解了Web.xml，这是Java Web的基础，也就是Servlet容器的工作方式，那个也作为本文的基础。\nSpringMVC整体可以看成是一个Servlet，事实上它就是一个Servlet。我们配置web.xml来启动这个Servlet，然后这个Servlet来负责处理每个请求。每个处理请求的类都是我们遵照SpringMVC的格式来写的类，由SpringMVC这个框架来调用完成整个请求的处理。\n与原本粗放的原生Java Web的开发模式相比，做了一个聚合。原本是每个请求你都写一个Servlet去处理，在web.xml中配置好一个请求与处理类的映射关系，由容器来完成调用。然后SpringMVC是分担了容器的压力，将容器的工作交给他来做，它利用Spring框架的依赖注入的特性，以及bean的工厂模式重新实现后端的实际处理流程。\n有好处也有坏处，我也不太清楚这样做的具体目的是什么，可能会有性能上的提升，因为毕竟工厂模式等特性的加入会提升一些性能和开发便利。坏处感觉也挺明显，首当其冲就是学习栈又深了，还不是深了一个单位是好几个单位。加入了新的配置等，开发过程的脑力成本又增加了。\n多说也没用，也是要以后逐步深入才能参透其中的奥妙。\nmaven 配置项目 # 命令行使用mvn构建项目很简单。\nmvn archetype:generate -DarchetypeGroupId=org.apache.maven.archetypes -DarchetypeArtifactId=maven-archetype-webapp -DarchetypeVersion=1.0 -DgroupId=com.demo -DartifactId=demo -Dversion=1.0 生成的目录如下：\n. ├── pom.xml └── src └── main ├── resources └── webapp ├── index.jsp └── WEB-INF └── web.xml 配置一下项目所需依赖关系pom.xml:\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;com.demo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt; \u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt; \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;name\u0026gt;demo Maven Webapp\u0026lt;/name\u0026gt; \u0026lt;url\u0026gt;http://maven.apache.org\u0026lt;/url\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;jdk.version\u0026gt;1.8\u0026lt;/jdk.version\u0026gt; \u0026lt;spring.version\u0026gt;4.3.9.RELEASE\u0026lt;/spring.version\u0026gt; \u0026lt;jstl.version\u0026gt;1.2\u0026lt;/jstl.version\u0026gt; \u0026lt;servletapi.version\u0026gt;3.1.0\u0026lt;/servletapi.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.8.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;commons-logging\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;commons-logging\u0026lt;/artifactId\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-context\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-beans\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-web\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-webmvc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-aop\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${spring.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jstl\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jstl.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- compile only, deployed container will provide this --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${servletapi.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;finalName\u0026gt;demo\u0026lt;/finalName\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;!-- Eclipse project --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-eclipse-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.9\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- Always download and attach dependencies source code --\u0026gt; \u0026lt;downloadSources\u0026gt;true\u0026lt;/downloadSources\u0026gt; \u0026lt;downloadJavadocs\u0026gt;false\u0026lt;/downloadJavadocs\u0026gt; \u0026lt;!-- Avoid type mvn eclipse:eclipse -Dwtpversion=2.0 --\u0026gt; \u0026lt;wtpversion\u0026gt;2.0\u0026lt;/wtpversion\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;!-- Set JDK Compiler Level --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;${jdk.version}\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;${jdk.version}\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;!-- For Maven Tomcat Plugin --\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.tomcat.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;tomcat8-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.2\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;path\u0026gt;/CounterWebApp\u0026lt;/path\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; web.xml 配置 # 下面就是要在这里配置启动SpringMVC，需要配置两个东西。\n\u0026lt;!DOCTYPE web-app PUBLIC \u0026#34;-//Sun Microsystems, Inc.//DTD Web Application 2.3//EN\u0026#34; \u0026#34;http://java.sun.com/dtd/web-app_2_3.dtd\u0026#34; \u0026gt; \u0026lt;web-app\u0026gt; \u0026lt;display-name\u0026gt;learning springMVC\u0026lt;/display-name\u0026gt; \u0026lt;!-- 配置该监听器，使得其在容器启动时就去加载SpringMVC的配置文件 --\u0026gt; \u0026lt;!-- 如果没有配置下面的这个contextConfigLocation参数，则默认加载同目录下的applicationContext.xml --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring-configuration/*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;!-- 配置SpringMVC的请求分发处理Servlet --\u0026gt; \u0026lt;!-- 在项目启动的时候就启动该Servlet --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;Dispatch\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;Dispatch\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;/\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;/web-app\u0026gt; 可以配置多个Dispatch来拦截不同格式的请求，不同的Dispatch要使用不同的配置文件，没错，又来一个配置。 这就是个前端请求拦截器，然后那过来到自己的配置文件里重新路由到要到达的Handler。所以每配置一个就要一个配置文件。默认的配置文件是/WEB-INF/\u0026lt;servlet-name\u0026gt;-servlet.xml\nurl-pattern：表示哪些请求交给Spring Web MVC处理， / 是用来定义默认servlet映射的。也可以如*.html表示拦截所有以html为扩展名的请求。\n这样拦截请求会将静态文件的请求都拦截掉，所以我们在配置DispatchServlet之前加上一个配置， 这个配置是使用tomcat容器的默认Servlet来处理静态文件请求，让这个servlet先拦截请求就不会被SpringMVC拦截掉了：\n\u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.css\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.swf\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.gif\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.jpg\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.png\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.js\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.html\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.xml\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.json\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; \u0026lt;servlet-mapping\u0026gt; \u0026lt;servlet-name\u0026gt;default\u0026lt;/servlet-name\u0026gt; \u0026lt;url-pattern\u0026gt;*.map\u0026lt;/url-pattern\u0026gt; \u0026lt;/servlet-mapping\u0026gt; 还有一种方式就是将静态文件全部放在CDN结点服务器上，也可以分担服务器压力，速度还快，就是要花钱。\n除了上面的这些基础配置，我们还会配置一些过滤器，比较典型的就是字符过滤，防止乱码:\n\u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;characterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;forceEncoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;characterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; 还有一些错误页的配置：\n\u0026lt;welcome-file-list\u0026gt;\u0026lt;!--指定欢迎页面--\u0026gt; \u0026lt;welcome-file\u0026gt;login.html\u0026lt;/welcome-file\u0026gt; \u0026lt;/welcome-file-list\u0026gt; \u0026lt;error-page\u0026gt; \u0026lt;!--当系统出现404错误，跳转到页面nopage.html--\u0026gt; \u0026lt;error-code\u0026gt;404\u0026lt;/error-code\u0026gt; \u0026lt;location\u0026gt;/nopage.html\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt; \u0026lt;error-page\u0026gt; \u0026lt;!--当系统出现java.lang.NullPointerException，跳转到页面error.html--\u0026gt; \u0026lt;exception-type\u0026gt;java.lang.NullPointerException\u0026lt;/exception-type\u0026gt; \u0026lt;location\u0026gt;/error.html\u0026lt;/location\u0026gt; \u0026lt;/error-page\u0026gt; \u0026lt;session-config\u0026gt;\u0026lt;!--会话超时配置，单位分钟--\u0026gt; \u0026lt;session-timeout\u0026gt;360\u0026lt;/session-timeout\u0026gt; \u0026lt;/session-config\u0026gt; applicationContext.xml # spring配置文件是用于指导Spring工厂进行Bean生产、依赖关系注入（装配）及Bean实例分发的\u0026quot;图纸\u0026quot;。Java EE程序员必须学会并灵活应用这份\u0026quot;图纸\u0026quot;准确地表达自己的\u0026quot;生产意图\u0026quot;。Spring配置文件是一个或多个标准的XML文档，applicationContext.xml是Spring的默认配置文件，当容器启动时找不到指定的配置文档时，将会尝试加载这个默认的配置文件。\n这个是Spring 的全局配置文件，并不是SpringMVC的。\n"},{"id":60,"href":"/posts/web/web/","title":"web.xml","section":"Web","content":"其作用就是配置一个web程序的基本功能。容器在启动一个web项目的时候先读取这个配置文件，在配置文件读取无误后开始按照配置启动剩余的服务。\n加载顺序 # \u0026lt;context-param\u0026gt; -\u0026gt; \u0026lt;listener\u0026gt; -\u0026gt; \u0026lt;filter\u0026gt; -\u0026gt; \u0026lt;servlet\u0026gt; 容器会创建一个ServletContext，整个项目都会共用这个上下文。而\u0026lt;context-param\u0026gt;的内容以键值对的形式存在这个上下文中。 然后对读取\u0026lt;listener\u0026gt;，并实例化listener类，并初始化。 listener类中会有contextInitialized(ServletContextEvent args)初始化方法，启动Web应用时，系统调用Listener的该方法，在这个方法中获得：\nServletContext application = ServletContextEvent.getServletContext(); context-param的值 = application.getInitParameter(\u0026#34;context-param的键\u0026#34;); 得到这个context-param的值之后，你就可以做一些操作了。 举例：你可能想在项目启动之前就打开数据库，那么这里就可以在\u0026lt;context-param\u0026gt;中设置数据库的连接方式（驱动、url、user、password），在监听类中初始化数据库的连接。这个监听是自己写的一个类，除了初始化方法，它还有销毁方法，用于关闭应用前释放资源。比如:说数据库连接的关闭，此时，调用contextDestroyed(ServletContextEvent args)，关闭Web应用时，系统调用Listener的该方法。\n所以归根结底，这个\u0026lt;context-param\u0026gt;就是用来存一些配置数据的地方。\n比如：定义一个管理员email地址用来从程序发送错误，或者与你整个应用程序有关的其他设置。使用自己定义的设置文件需要额外的代码和管理；直接在你的程序中使用硬编码（Hard-coding）参数值会给你之后修改程序带来麻烦，更困难的是，要根据不同的部署使用不同的设置；通过这种办法，可以让其他开发人员更容易找到相关的参数，因为它是一个用于设置这种参数的标准位置。\nweb-app # 根元素，不用多说\ndisplay-name # 应用的名称，这个在tomcat的维护信息中会出现。\nsession # \u0026lt;session-config\u0026gt; \u0026lt;session-timeout\u0026gt;120\u0026lt;/session-timeout\u0026gt; \u0026lt;/session-config\u0026gt; listener # \u0026lt;!--****************************监听器配置*********************************--\u0026gt; \u0026lt;!-- Spring的log4j监听器 --\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.util.Log4jConfigListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; 监听器用来监听各种事件，比如：application和session事件，所有的监听器按照相同的方式定义，功能取决去它们各自实现的接口，常用的Web事件接口有如下几个：\nServletContextListener：用于监听Web应用的启动和关闭； ServletContextAttributeListener：用于监听ServletContext范围（application）内属性的改变； ServletRequestListener：用于监听用户的请求； ServletRequestAttributeListener：用于监听ServletRequest范围（request）内属性的改变； HttpSessionListener：用于监听用户session的开始和结束； HttpSessionAttributeListener：用于监听HttpSession范围（session）内属性的改变。 listener类是实现了以下两个接口中任何一个接口的简单java类：javax.servlet.ServletContextListener或javax.servlet.http.HttpSessionListener，如果想让你的类监听应用的启动和停止事件，你就得实现ServletContextListener接口；想让你的类去监听Session的创建和失效事件，那你就得实现HttpSessionListener接口。\n有两种为应用配置listener的方式：\n使用@WebListener修饰Listener实现类即可。 在web.xml文档中使用\u0026lt;listener\u0026gt;进行配置。 在下一节配置spring的加载类的时候会给出例子。\nspring相关配置 # 配置spring，必须需要\u0026lt;listener\u0026gt;，\u0026lt;context-param\u0026gt;如果有就去加载配置的路径，没有就默认是/WEB-INF/applicationContext.xml。\n\u0026lt;!-- spring config --\u0026gt; \u0026lt;!-- if this node is not exist, --\u0026gt; \u0026lt;context-param\u0026gt; \u0026lt;param-name\u0026gt;contextConfigLocation\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;/WEB-INF/spring-configuration/*.xml\u0026lt;/param-value\u0026gt; \u0026lt;/context-param\u0026gt; \u0026lt;listener\u0026gt; \u0026lt;listener-class\u0026gt;org.springframework.web.context.ContextLoaderListener\u0026lt;/listener-class\u0026gt; \u0026lt;/listener\u0026gt; 事实上，spring的配置也是有两种不同的方式的，一种是上面的这种使用listener的方式，还有一种是使用servlet的方式，这两种方式的区别在与什么时候加载。 使用listener的方式，是在web启动的时候加载，并且加载的顺序是在filter之前。所以在filter中就可以使用spring的类，否则其中的对象就是空的，就无法使用。所以我们一般选用上面的这种配置方式来启动spring。\n另外一种方式也放出来：\n\u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;context\u0026lt;/servlet-narne\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.context.ContextLoaderServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; Filter # Filter可认为是Servle的一种“加强版”，主要用于对用户请求request进行预处理，也可以对Response进行后处理，是个典型的处理链。使用Filter的完整流程是：Filter对用户请求进行预处理，接着将请求HttpServletRequest交给Servlet进行处理并生成响应，最后Filter再对服务器响应HttpServletResponse进行后处理。Filter与Servlet具有完全相同的生命周期，且Filter也可以通过\u0026lt;init-param\u0026gt;来配置初始化参数，获取Filter的初始化参数则使用FilterConfig的getInitParameter()。\n换种说法，Servlet里有request和response两个对象，Filter能够在一个request到达Servlet之前预处理request，也可以在离开Servlet时处理response，Filter其实是一个Servlet链。以下是Filter的一些常见应用场合，\n(1)认证Filter (2)日志和审核Filter (3)图片转换Filter (4)数据压缩Filter (5)密码Filter (6)令牌Filter (7)触发资源访问事件的Filter (8)XSLT Filter (9)媒体类型链Filter Filter可负责拦截多个请求或响应；一个请求或响应也可被多个Filter拦截。 Filter必须实现javax.servlet.Filter接口，在该接口中定义了三个方法：\nvoid init(FilterConfig config)：用于完成Filter的初始化。FilteConfig用于访问Filter的配置信息。 void destroy()：用于Filter销毁前，完成某些资源的回收。 void doFilter(ServletRequest request,ServletResponse response,FilterChain chain)：实现过滤功能的核心方法，该方法就是对每个请求及响应增加额外的处理。该方法实现对用户请求request进行预处理，也可以实现对服务器响应response进行后处理\u0026mdash;它们的分界线为是否调用了chain.doFilter(request，response)，执行该方法之前，即对用户请求request进行预处理，执行该方法之后，即对服务器响应response进行后处理。 filter配置 # Filter配置与Servlet的配置非常相似，需要配置两部分：配置Filter名称和Filter拦截器URL模式。区别在于Servlet通常只配置一个URL，而Filter可以同时配置多个请求的URL。配置Filter有两种方式：\nAnnotation注解相应类 web.xml \u0026lt;filter\u0026gt;用于指定Web容器中的过滤器，可包含\u0026lt;filter-name\u0026gt;、\u0026lt;filter-class\u0026gt;、\u0026lt;init-param\u0026gt;、\u0026lt;icon\u0026gt;、\u0026lt;display-name\u0026gt;、\u0026lt;description\u0026gt;。\n\u0026lt;filter-name\u0026gt;用来定义过滤器的名称，该名称在整个程序中都必须唯一。 \u0026lt;filter-class\u0026gt;元素指定过滤器类的完全限定的名称，即Filter的实现类。 \u0026lt;init-param\u0026gt;为Filter配置参数，与\u0026lt;context-param\u0026gt;具有相同的元素描述符\u0026lt;param-name\u0026gt;和\u0026lt;param-value\u0026gt;。 \u0026lt;filter-mapping\u0026gt;元素用来声明Web应用中的过滤器映射，过滤器被映射到一个servlet或一个URL 模式。这个过滤器的\u0026lt;filter\u0026gt;和\u0026lt;filter-mapping\u0026gt;必须具有相同的\u0026lt;filter-name\u0026gt;，指定该Filter所拦截的URL。过滤是按照部署描述符的\u0026lt;filter-mapping\u0026gt;出现的顺序执行的。\nExample # \u0026lt;!-- 字符集过滤器 --\u0026gt; \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;org.springframework.web.filter.CharacterEncodingFilter\u0026lt;/filter-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;encoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;UTF-8\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;forceEncoding\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;true\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;CharacterEncodingFilter\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt; Servlet # Servlet通常称为服务器端小程序，是运行在服务器端的程序，用于处理及响应客户的请求。Servlet是个特殊的java类，继承于HttpServlet。客户端通常只有GET和POST两种请求方式，Servlet为了响应则两种请求，必须重写doGet()和doPost()方法。大部分时候，Servlet对于所有的请求响应都是完全一样的，此时只需要重写service()方法即可响应客户端的所有请求。 另外HttpServlet有两个方法:\ninit(ServletConfig config)：创建Servlet实例时，调用该方法的初始化Servlet资源。 destroy()：销毁Servlet实例时，自动调用该方法的回收资源。 通常无需重写init()和destroy()两个方法，除非需要在初始化Servlet时，完成某些资源初始化的方法，才考虑重写init()方法，如果重写了init()方法，应在重写该方法的第一行调用super.init(config)，该方法将调用HttpServlet的init()方法。如果需要在销毁Servlet之前，先完成某些资源的回收，比如关闭数据库连接，才需要重写destory()。 生命周期 # 创建Servlet实例有两个时机： 客户端第一次请求某个Servlet时，系统创建该Servlet的实例，大部分Servlet都是这种Servlet。 Web应用启动时立即创建Servlet实例，即load-on-start Servlet。\n每个Servlet的运行都遵循如下生命周期：\n创建Servlet实例。 Web容器调用Servlet的init()方法，对Servlet进行初始化。 Servlet初始化后，将一直存在于容器中，用于响应客户端请求，如果客户端发送GET请求，容器调用Servlet的doGet()方法处理并响应请求；如果客户端发送POST请求，容器调用Servlet的doPost()方法处理并响应请求。或者统一使用service()方法处理来响应用户请求。 Web容器决定销毁Servlet时，先调用Servlet的destory()方法，通常在关闭Web应用时销毁Servlet实例。 配置 # 为了让Servlet能响应用户请求，还必须将Servlet配置在web应用中。 从Servlet3.0开始，配置Servlet有两种方式：\n在Servlet类中使用@WebServlet Annotation进行配置。 在web.xml文件中进行配置。 我们用web.xml文件来配置Servlet，需要配置\u0026lt;servlet\u0026gt;和\u0026lt;servlet-mapping\u0026gt;。 \u0026lt;servlet\u0026gt;用来声明一个Servlet。\u0026lt;icon\u0026gt;、\u0026lt;display-name\u0026gt;和\u0026lt;description\u0026gt;元素的用法和\u0026lt;filter\u0026gt;的用法相同。\u0026lt;init-param\u0026gt;元素与\u0026lt;context-param\u0026gt;元素具有相同的元素描述符，可以使用\u0026lt;init-param\u0026gt;子元素将初始化参数名和参数值传递给Servlet，访问Servlet配置参数通过ServletConfig对象来完成，ServletConfig提供如下方法：\njava.lang.String.getInitParameter(java.lang.String name)：用于获取初始化参数\nServletConfig获取配置参数的方法和ServletContext获取配置参数的方法完全一样，只是ServletConfig是取得当前Servlet的配置参数，而ServletContext是获取整个Web应用的配置参数。\n\u0026lt;description\u0026gt;：为Servlet指定一个文本描述。\n\u0026lt;display-name\u0026gt;：为Servlet提供一个简短的名字被某些工具显示。\n\u0026lt;icon\u0026gt;：为Servlet指定一个图标，在图形管理工具中表示该Servlet。\n\u0026lt;servlet\u0026gt;必须含有\u0026lt;servlet-name\u0026gt;和\u0026lt;servlet-class\u0026gt;，或者\u0026lt;servlet-name\u0026gt;和\u0026lt;jsp-file\u0026gt;。 描述如下：\n\u0026lt;servlet-name\u0026gt;用来定义servlet的名称，该名称在整个应用中必须是惟一的 \u0026lt;servlet-class\u0026gt;用来指定servlet的完全限定的名称。 \u0026lt;jsp-file\u0026gt;用来指定应用中JSP文件的完整路径。这个完整路径必须由/开始。 如果load-on-startup元素存在，而且也指定了jsp-file元素，则JSP文件会被重新编译成Servlet，同时产生的Servlet也被载入内存。\u0026lt;load-on-startup\u0026gt;的内容可以为空，或者是一个整数。这个值表示由Web容器载入内存的顺序。 举个例子：如果有两个Servlet元素都含有\u0026lt;load-on-startup\u0026gt;子元素，则\u0026lt;load-on-startup\u0026gt;子元素值较小的Servlet将先被加载。如果\u0026lt;load-on-startup\u0026gt;子元素值为空或负值，则由Web容器决定什么时候加载Servlet。如果两个Servlet的\u0026lt;load-on-startup\u0026gt;子元素值相同，则由Web容器决定先加载哪一个Servlet。 \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt;表示启动容器时，初始化Servlet。\n\u0026lt;servlet-mapping\u0026gt;\n\u0026lt;servlet-mapping\u0026gt;含有\u0026lt;servlet-name\u0026gt;和\u0026lt;url-pattern\u0026gt;\n\u0026lt;servlet-name\u0026gt;：Servlet的名字，唯一性和一致性，与\u0026lt;servlet\u0026gt;元素中声明的名字一致。 \u0026lt;url-pattern\u0026gt;：指定相对于Servlet的URL的路径。该路径相对于web应用程序上下文的根路径。\u0026lt;servlet-mapping\u0026gt;将URL模式映射到某个Servlet，即该Servlet处理的URL。 加载Servlet的过程 容器的Context对象对请求路径(URL)做出处理，去掉请求URL的上下文路径后，按路径映射规则和Servlet映射路径i\u0026lt;url- pattern\u0026gt;做匹配，如果匹配成功，则调用这个Servlet处理请求。\nDispatcherServlet在web.xml中的配置： # \u0026lt;!-- Spring view分发器 对所有的请求都由business对应的类来控制转发 --\u0026gt; \u0026lt;servlet\u0026gt; \u0026lt;servlet-name\u0026gt;business\u0026lt;/servlet-name\u0026gt; \u0026lt;servlet-class\u0026gt;org.springframework.web.servlet.DispatcherServlet\u0026lt;/servlet-class\u0026gt; \u0026lt;init-param\u0026gt; \u0026lt;param-name\u0026gt;publishContext\u0026lt;/param-name\u0026gt; \u0026lt;param-value\u0026gt;false\u0026lt;/param-value\u0026gt; \u0026lt;/init-param\u0026gt; \u0026lt;load-on-startup\u0026gt;1\u0026lt;/load-on-startup\u0026gt; \u0026lt;/servlet\u0026gt; "},{"id":61,"href":"/posts/git/git/","title":"git实战指南","section":"Git","content":"今天在往公司的gitlab上push项目的时候死活无法push上去，总是显示没有权限。报错信息上显示sshkey的问题，但是我在github上面都是好好的，搞了半天，我都翻出里git的配置文件改了好几遍都没有用，总之就是个垃圾。。。，后来我放弃了git协议，使用http协议手动认证身份就可以了。傻逼的错误信息如下：\nsign_and_send_pubkey: signing failed: agent refused operation Permission denied (publickey). fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 虽然体验不是很好但是用到了很多以前没有机会用的命令，实践出真知，今天就来总结一下实战中的git是怎么玩的。\n安装 # $ sudo apt install git 配置config # 在终端直接输入以下命令：\n$ git config --global user.name \u0026#34;John Doe\u0026#34; $ git config --global user.email johndoe@example.com 这个一般我们安装好就会配置一下，这个是全局的配置，如果你的项目中没有自己的配置就会使用这个配置。关于git的配置，你可以用如下的命令查看都有那些信息：\n$ git config -l 这会列出全局+当前目录下的git仓库的信息。如果你所在的目录不是个git仓库就只列出全局的配置信息。 当你不加-l的选项的时候，就会列出config常用的选项，其中有一些选项可以用来修改配置信息。这个当你需要用的时候自己在终端看一下就可以了。\n其中也告诉我们，git的配置可以每个项目都有一个配置，这个配置就在你的仓库.git/文件夹下的config文件中。全局的配置在~/.gitconfig文件中。\nssh key # 在终端生成一个ssh key的命令如下：\n$ ssh-keygen -t rsa -C \u0026#34;e-mail@xxx.com\u0026#34; 生成的密钥和公钥在~/.ssh/文件夹下，你需要将你的后缀.pub的那个文件的内容复制出来，放到你的github或是公司的gitlab上。当然了，gitlab就算了吧，因为貌似不会起作用。\n工作区 \u0026amp; 本地仓库 \u0026amp; 远程仓库 # 初学git的人往往分布清楚这几个的概念。那就画个图来说明一下简单直观。 （此处有图）\n工作区 # 首先你要知道的是你写的文件，并不在git的概念中。啥意思呢，就是你写的文件就是你写的文件，git又不管你在这个文件夹下面写了什么东西，git的第一个空间是：工作区。当你将你的修改或是新写的文件通过git add的命令提交的时候这写文件才会被git记录下来，这时候是放到了工作区了。\n既然是工作区，相对的自由度就大一些，你可以添加进去，然后当你要提交的时候觉得这个东西写的还不是很好，你想再继续开发一段时间再发布出去，这个时候你就可以使用 git checkout \u0026lt;文件\u0026gt;... 来丢弃工作区的改动。 相当于工作区放的都是你完成的产品，即将被发布。\n本地仓库 # 当你觉得这次开发完成了，所有完成的作品也都放到工作区了。你就可以将整个工作区整体提交给本地仓库，使用如下命令：git commit -m 'say something'。 say something就是你在提交的时候简单的说一下这次你做了哪些东西。\n仓库才是真正的git的领域，也是git的精髓所在，版本控制的集大成者。\n一个仓库可以有很多个分支。这个分支是我们经常用到的，想比较而言，版本回退我们倒不是经常用到。什么时候会用版本回退呢？就是在我们发布的版本出现一些问题的时候，这个时候不能让一个有问题的东西给人用啊，所以就只好暂时版本回退到一个稳定版本，新功能暂时没有，不就没有问题了嘛！没错，程序员就是这样的逻辑，把报错信息删掉不就没有错误了嘛！ 那么什么时候用分支呢？就是在开发的过程中嘛。多人协作，大家做的东西可能是不同的模块的，有的人做的模块可能要在未来的很多版本以后才能上线，这个时候总不能把自己的半成品也放到项目里发出去吧，所以干脆，你拉一个分支出去，等你开发结束了，再把这个分支合进主分支里好了。还有一些是什么情况呢？比如你开发到一定程度，接下来有两个方案，你不确定要做哪个，你可以都开发看看嘛，一般就是两波人。怎么办呢，两波人各拉一个分支出去，各自开发测试，等到开发完了，比较一下用哪个好，再合进主分支里发布。\n关于git开发流的使用，有那么几个主流的使用方式，这个下次再补充进来。\n本地仓库有很多分支喽，那么我这次提交要提交到哪个分支呢？\n你当然要看一下当前有哪些分支喽：\n$ git branch # 结果如下: * master 带*号的分支就是你当前的默认分支，如果你不指明提交到哪个分支就是这个分支了。 master就是你建仓库时的主分支了。\n你现在只有一个分支，突然这一刻你林纳斯灵魂附体，你有个绝佳的想法，于是你新建了一个分支要开发一个新的小功能，于是你就建了一个分支, 并把当前的默认分支改成了你的新分支，因为你觉得这个想法太棒了，你留着之前的那段代码只是为了纪念自己曾经傻逼过：\n$ git branch Linux $ git checkout Linux 一切行云流水的结束了，因为只是简单的两个命令而已。同时结束的当然还有林纳斯投错胎的灵魂附体，于是你看着这个新的分支陷入了沉思，不过并没有关系，这个伟大的名字并不能改变你的命运，毕竟你曾经傻逼过嘛，都是可以原谅的，于是你删掉了这个分支，继续傻逼下去：\n$ git branch -D Linux 远程仓库 # 你可以看到有哪些远程仓库：\n$ git remote 或是更详细看看，你从哪些仓库同步代码和向那些仓库推送变更：\n$ git remote -v 你也可以看看有哪些远程分支：\n$ git branch -a # 结果如下: * master remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/developing remotes/origin/master remotes 就是远程分支, HEAD指明了这个远程仓库的当前分支是哪一个。 在下面有这个远程仓库的分支描述：remotes/仓库名/分支名\n当然这个命令不报错是在你有远程仓库的前提下，如何建立远程仓库呢？别天真了，我怎么会告诉你呢？我也不会在本地建出来远程仓库，不过我会在远程建好了再建立连接。 先去github上建一个，反正没有钱搞gitlab这个垃圾。在建完仓库的页面中有一些提示的，其中有个这样的命令\n$ git remote add origin git@git... 你可以用这个命令将本地仓库与这个远程仓库建立连接，其中origin是你给这个仓库起的名字，一般我们都是这个名字，毫无新意但是管用。\n当然你也可以有多个远程仓库，就用上面这个命令就可以了，像个多面间谍一样向不同的仓库推送不同的代码。\n注意啦！ 怎么给不同的仓库推送不同的代码？如果你问了这个问题，说明你好像跟之前的我一样笨。 推送代码并不是仓库与仓库之间的行为，而是分支与分支的行为。\n也就是说你可以推送本地的某个分支给远程的某个仓库的某个分支，用这个命令，很简单的:\n$ git push -u origin master:developing origin就是你要推的远程仓库，master是你本地的分支名，developing是origin仓库中的分支。如果不加冒号及后面的东西，就是推到目标远程仓库的默认当前分支。\n这样这几个的关系应该就明白了。\n本地如何优雅的使用git # 经常用下面这个命令\n$ git status 这会列出当前这个文件夹下你有哪些修改过的文件还没有add到工作区，有哪些文件是新的还没有add到工作区。。。 貌似就是这样了吧，再优雅的姿势我就不太会了。\n如何解决问题哒？ # 将git协议的连接转换成http协议的连接并没有相应的命令可以使用，我是找到了仓库文件夹下的.git/config文件，文件内容如下：\n[core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true [remote \u0026#34;origin\u0026#34;] url = http://gitlab.alibaba-inc.com/tair/xxxxxx.git fetch = +refs/heads/*:refs/remotes/origin/* [user] email = bai@xxx.com name = bai 将其中的url从git协议链接改成了http协议的链接就可以了。\n有冲突怎么办？ # 业界潜规则嘛，早提交的早下班，晚提交的改冲突。\n当push的时候发现跟上面版本不一致了，落后于远程的仓库，就得先同步下来。 当我们pull下来的时候，发现跟本地的内容有冲突。这个时候就会在本地的文件中多出许多标记，标记如下：\n\u0026lt;\u0026lt;\u0026lt;\u0026lt; head // 这里是你本地的内容 ======== // 这里是远程pull下来的内容 \u0026gt;\u0026gt;\u0026gt;\u0026gt; 02XSFDDFDFA123A 手动合并，然后再pull。\n错误的git pull怎么办 # 在你同步远端的时候，发现远端与你的不同太多，你需要新拉一个分支，保留自己目前的分支的时候，你需要回退到之前的某个版本。一般就会退到pull之间的版本，所以下面的命令：\ngit reset --hard HEAD\n回退两个commit：\ngit reset --hard HEAD^\n查看历史的commit记录，选择退到某个版本： git log\n上面命令中的HEAD 可以换成任何一个历史commit的编号ID。like this : 40a85d646d6f6b05bac2bf5ce2b9a1f44ed74d4d\n"},{"id":62,"href":"/posts/web/angular/","title":"angular","section":"Web","content":"Angularjs 和Angular2 的区别，就像雷锋和雷峰塔的区别。 笑尿了。\n我是跟着它的官方文档学习的，文档还是比较健全的，也很细致。地址：[Quick Start](npm install -g @angular/cli)\nAngularJS 与 Angular2 # 关于二者的区别，可以肯定的是angular2一定更好。\n在细节上，先来说一下angular的特别之处。\n其诞生于09年，提出了双向绑定等新特性的概念使得它一出现就被追捧。然而由于09年移动端还没有大规模出现，所以其不支持移动应用的使用。并且其数据绑定使用的是扫描的方式，性能瓶颈很难突破，所以被更适应时代的angular2代替是历史的必然。\n所以angular2就拥有了这些它的小弟做的不好的特性。 性能快，支持移动应用开发等。其实现的方式也有很大的区别，所以就出现了雷锋和雷锋塔的区别。\n直接来学习angular2的使用 # 首先在什么都不懂的时候先来构建一个实例应用打个招呼：\n以下的部分需要：node 6.9.x and npm 3.x.x 及以上。这部分可以去看我的node相关的文章。\nStep 1. Install the Angular CLI globally.\nnpm install -g @angular/cli Step 2. Create a new project\nng new my-app Step 3: Serve the application\ncd my-app ng serve --open 你可以看到效果，现在我们来看文件目录。\n你的应用需要的内容都在src文件夹中。其他的文件都是用来支撑这个应用的框架代码。下面我们看一下src文件夹的结构：\nsrc # File Purpose app/app.component.{ts,html,css,spec.ts} 定义组件。HTML模板，CSS，Unit Test。这是一个root组件 app/app.module.ts 声明应用如何装配 assets/ 静态资源 environments/ 存放你应用在不同环境下的配置文件。例如在开发环境还是在发布环境 index.html 入口，也是你经常要编辑的文件，angular默认加载所有的js和css，所以不需要写任何的\u0026lt;script\u0026gt;和\u0026lt;link\u0026gt; main.ts 应用的主要入口，你可以用just-in-time编译模式或者ahead-in-time模式进行调试开发。 polyfills.ts 不同浏览器支持的文件 style.css 全局的样式，对所有的应用都起作用的 test.ts 单元测试的入口， 你貌似并不需要编辑这个文件 tsconfig.{app spec}.json 其他目录 # File Purpose e2e end-to-end 测试，是个独立的模块 node_modules/ Node.js 创建这个文件夹，用于存放第三方组件，组建列表在package.json 文件中 .angular-cli.json 你可以修改哪些文件需要在build的时候被包含进去 .gitignore 用来将自动生成的文件不纳入资源管理的范围内 package.json npm 配置文件，用于配置第三方的组件 protractor.conf.js 在点对点测试的时候的配置文件 tsconfig.json Typescript 编译配置文件，对IDE有作用 tslint.json 标准化你的代码风格 从头开始开发一个Angular Application # 第一步都是建立工程，所谓建立工程就是建立一个像样的文件夹目录，angular有一个git项目用于快速搭建目录环境，所以第一步的构建需要这样做：\nSetup # git clone https://github.com/angular/quickstart.git quickstart cd quickstart npm install npm start 然后你会看到一个Hello， 说明建立完成，但是此时有很多没有用的文件我们可以删掉，包括之前的git相关的文件：\nxargs rm -rf \u0026lt; non-essential-files.osx.txt rm src/app/*.spec*.ts rm non-essential-files.osx.txt 一些不重要的文件都在一个上面命令中的这个文件中了，以空格分开。\n"},{"id":63,"href":"/posts/web/react/","title":"react 初探-一些基础概念","section":"Web","content":"（这一篇写的很杂，因为自己也是没有章法的断断续续的看了react的东西，所以内容没有组织好。勉强有个认知就好了）\n前端的技术现在发展的其实相对简单了很多，但是我觉得这才是正常的前端，以前的前端发展的太混乱，光是屏幕适配的问题就要搞出很多的工作量。而且以前的前后端的耦合过大，使得前端想发展也不发展不动，不过设计总是在进步，异步请求的普适催生了新的前后端设计模式，使得前后端完全解耦成为可能，前端的事情在前端搞定，后台的事情在后台封装掉。前端发展到今天主要就是接下来我要学习的几个js的框架，利用js实现动态的数据绑定，以及异步的请求，所有的前端操作都在封装在前端，开发的脑智压力开始下降，所以现在的全栈也并不是太难。\n这样前端框架会用的人一般都比较多，因为学习栈比较浅，很多人自学一天就可以了。所以相对的资料也就非常完善，网上的学习教程编写教学例子也很方便，所以在这里我主要就是偏理论一些的认知，其背后的设计实现等。\n简介 # React是Facebook出品的一款开源框架，虽说是开源，但是其在标准的BSD协议后添加了一些条款，使得现在很多公司并不敢使用这个框架了，其添加条款中说明，如果使用该开源项目的产品威胁到facebook的商业产品，facebook有权起诉该产品。不过没有并那么可怕，因为貌似想威胁到也不太容易。\nReact这类框架主要的注意力放在的是用户的交互界面上，最突出的就是内容的动态绑定，内容变化后的高效刷新。并且屏蔽了DOM。\nReact使用的是JSX语法，是一种将js与html混合编写的语言。\nJavascript # 在学习使用这个框架之前，必须对Javascript有所了解，因为这是一个Javascript框架。对于这部分了解的就直接跳过去看JSX的语法部分。\n这门语言传说是被人误解最深的语言，确实貌似大家的学习路线都没有关注过这个东西，以为就是前端脚本搞着玩的语言，但是其语言还是有很多优点并且应用的场景正越来越多。\nJavaScript 是一种面向对象的动态语言，它的语法来源于 Java 和 C，所以这两种语言的许多语法特性同样适用于 JavaScript。需要注意的一个主要区别是 JavaScript 不支持类，类这一概念在 JavaScript 通过对象原型（object prototype）得到延续。另一个主要区别是 JavaScript 中的函数也是对象，JavaScript 允许函数在包含可执行代码的同时，能像其他对象一样被传递。\n类型 # Number（数字） String（字符串） Boolean（布尔） Symbol（符号）（第六版新增） Object（对象） Function（函数） Array（数组） Date（日期） RegExp（正则表达式） Null（空） Undefined（未定义） 等\n更多基础的语法不冗余重复了。\nJavascript对象 # 如果你知道Json的全称，你就理解了这个东西：JSON(JavaScript Object Notation, JS 对象标记)。一个符合Json协议的字符串可以直接解析为Javascript对象。\n对于Object的成员访问可以使用链式访问：\nvar obj = { name: \u0026#34;Carrot\u0026#34;, \u0026#34;for\u0026#34;: \u0026#34;Max\u0026#34;, details: { color: \u0026#34;orange\u0026#34;, size: 12 } } obj.details.color; // orange obj[\u0026#34;details\u0026#34;][\u0026#34;size\u0026#34;]; // 12 下面的例子创建了一个对象原型，Person，和这个原型的实例，You。\nfunction Person(name, age) { this.name = name; this.age = age; } // 定义一个对象 var You = new Person(\u0026#34;You\u0026#34;, 24); // 我们创建了一个新的 Person，名称是 \u0026#34;You\u0026#34; // (\u0026#34;You\u0026#34; 是第一个参数, 24 是第二个参数..) // 字段可以使用点操作符操作也可以使用下标操作。 数组 # var a = [\u0026#34;dog\u0026#34;, \u0026#34;cat\u0026#34;, \u0026#34;hen\u0026#34;]; a.length; // 3 a[100] = \u0026#34;fox\u0026#34;; a.length; // 101 typeof(a[90]); // undefined a.push(item); // 在后面追加元素 遍历数组\nfor (var i = 0; i \u0026lt; a.length; i++) { // Do something with a[i] } for (var i in a) { // Do something with a[i] } 剩余的部分再补充吧。\nReact 元素与组件 # 在元素在react中就是一个对象，只不过，不是简单的js对象，是jsx混合编写的对象。 for example:\nconst element = \u0026lt;div className=\u0026#34;element\u0026#34;\u0026gt;I\u0026#39;m element\u0026lt;/div\u0026gt; 这样就创建了一个react元素，但是没有经过渲染是不会成为DOM中的元素的。\n组件是由对象组成的，组建是一个类或者是无状态函数。\nJSX 语法简述 # JSX是在javascript之上扩展而来的，最终还是会被编译成为javascript来运行的。 要学习其语法有很多地方可以看，这里就主要总结一下特点就好了。\n优点：\n速度快，在编译成为js的时候做了优化。 类型安全，在前期编译阶段就可以发现错误。 编写简单。 一些语法特点：\n可以直接使用html代码。 可以使用js表达式，表达式用大括号括起来。 没有if-else ， 可以使用三目运算符。 注释算是js表达式，所以要写在大括号中。 其他的一些注意点：\n当给组件传递Props参数的时候，如果不是字符串类型，值就要用打括号扩起来，如果是一个对象的时候就会出现两层括号的现象：style={ {color:\u0026quot;red\u0026quot;} }。 "},{"id":64,"href":"/posts/acm/fft/","title":"FFT 快速傅立叶变换","section":"Acm","content":"快速傅立叶变换是离散傅立叶变换的加速版。 傅立叶的一个用途是用来计算多项式乘法。先讲一下多项式乘法。\n多项式乘法 # 多项式有两种表示方法：\n系数表示法 # $$A = a0 + a1x^1 + a2x^2 + \u0026hellip; + anx^n$$\n点值表示法 # A ={ (x1, y1), (x2, y2),...,(x3, y3) } 点值表示法相当与用点值来求得各项的系数，所以要准确表示一个多项式就必须至少与多项式未知数的数量一致才可以。\n传统的系数表示法求多项式乘法的方式复杂度是O(n^2)。 如果使用点值来计算多项式乘法，就会有一些可优化的地方。首先两个n次多项式相乘得到的结果多项式有2n项，这个是确定的，也就是说要用点值表示法就要有2n个点。如何用点值表示法求多项式相乘呢？我们取点的时候就取x相同的点值，这样对应的y值相乘的结果就是结果多项式的y。所以我们在取两个多项是的点的时候就要取2n个点，然后得到2n个结果点。然后剩余的任务就是将这个点值表示法转换成系数表示法得到了我们要的多项式。这个由点值转换为系数的方式称之为插值。\n但是这样的算法，在第一步的时候就崩溃了，因为求一个点的值就要至少O(n)， 我们要求2n×2个点复杂度就O(n^2)了。然后就需要一些数学手段。\n秦九韶算法 # 这个算法的中心思想是通过选取特殊的点来简化计算，什么点是特殊的呢，用复数点。\n介绍这个之前需要先复习一下复数。 高中数学的基础还是比大学的更有用。 复数的基本表示方法：z = x + yi。在复平面上的从原点到点(x,y)的向量是其对应的几何解释。 利用直角坐标与极坐标之间关系，复数还有一种三角表示：z = r(cosθ + isinθ)，θ代表极角，r是复数向量的模|z|=sqrt(x^2+y^2)。 另一种表示法是指数表示法，见下图. 然后有一个棣莫弗公式能够将两个复数相乘简化：\n设两个复数（用三角形式表示）: z1 = r1(cosθ1 + isinθ1) z2 = r2(cosθ2 + isinθ2) 那么相乘的结果就是： z1*z2 = r1*r2[cos(θ1+θ2) + isin(θ1+θ2)] 这个过程很好证明，三角函数就可以了。 这个公式可以进行推广，数学归纳法，得到： z1*z2*...*zn = r1*r2*...*rn[cos(θ1+θ2+...+θn) + isin(θ1+θ2+...+θn)] 这个公式再变化一下，另z1=z2=...=zn， 就得到复数的幂次公式： z^n = r1^n[cos(nθ) + isin(nθ)] 然后我们用指数形式换一下: z^n = r1^n e^(nθi) 然而现在还不够，下面引入复数开根计算。\n对于一个复数做开n次根计算会得到n个复数。这n个复数的几何意义： z^(1/n) 的 n 个值是以原点为中心，r^(1/n) 为半径的圆的内接正 n 边形的 n 个顶点。\n开根公式：\nz^(1/n) = r^(1/n)[cos(θ+2k*pi)/n + isin(θ+2k*pi)/n] , k=0,1,2,...,n-1 z^(1/n) = r^(1/n)* e^(i(θ+2k*pi)/n), k=0,1,2,...,n-1\n现在回到我们的主题，在求n次多项式乘法的时候，我们要选取2n个点。这2n个点我们选取2n个复数点。我们令w^(2n) = 1，这2n个复数点我们就选在w的位置上。从上面我们知道了对于复数1 开2n次方根会得到2n个复数的，这些复数就是我们选的x。这些复数也叫做单位复根，因为是复数1+0i这个单位复数的根。\n下面再进一段简单的公式规范。\n由于我们要计算的结果多项式是2n项，所以我们先将A和B这两个多项式补成2n次多项式，没有的项系数为0就好了。 下面我们令: n = 2n; 对于我们取的单位复根wi，其对应的yi = a0wi^0 + a1wi^1 + ... + a(n-1)wi^(2n) 我们定义：y向量是系数向量a的 离散傅立叶变换(DFT)。\n这个定义其实就是一个矩阵相乘嘛，多项式值计算的向量表示。 我们要做的事情就是快速计算出y向量。因为计算y向量在原来的算法中是个O(n^2)的算法。下面就是快速傅立叶变换(FFT)\n快速傅立叶变换的主要思路十分简单，就是分治。由于其使用分治算法，所以其有一个特殊的要求，就是项数必须是2的幂次。之所以有这个要求，是因为这个分治策略是基于下面的公式：\n对于多项式 A(x) = a0 + a1x^1 + a2x^2 + ... + a(n-1)x^(n-1), 这里保证n是2的幂，也就是总的项数是2的幂，也就是系数向量的长度是2的幂。 现在利用A的奇数位系数和偶数位系数分别构造两个多项式： A[0](x) = a0 + a2x^1 + a4x^2 + ... + a(n-2)x^(n/2-1) A[1](x) = a1 + a3x^1 + a5x^2 + ... + a(n-1)x^(n/2-1) 那么 A(x) = A[0](x^2) + xA[1](x^2); 这个的证明很简单，不证明了。 这样求A(x) 就转化为求 A[0](x^2) + xA[1](x^2) 。 在上面我们将了这么多就是为了选取特殊的x，那么现在就是要发挥其特殊性的时候了。\n再来梳理几点，\nx^n = 1 （复数） x = 1^(1/n) = e^(i2kpi/n) 从上面我们构造的两个式子可以很明显的知道，需要知道x和x^2 之间的神秘关系嘛。\n这个时候我们需要在引入一段证明：\n我们令：w_n 表示 1的n次复根，即 w_n = 1^(1/n) 我们可以得到一个关系： (w_2n)^2 = 1^(1/n) 即我们得到了一个关系： (w_n) = (w_2n)^2 也即： w_(n/2) = (w_n)^2 上面我们所用的x是1的n次单位复根，即w_n。那么x^2 就是1的(n/2)次单位复根。 通过这个关系我们可以得到：x^(n/2) = 1^(1/2) = e^(ipi) = cos(pi)+isin(pi) = -1注意这里指数中有复数，拆回到三角形式计算才是正确的。 这里我的证明貌似有些乱，这个引理叫做：相消引理。\n上面我们说过，这n个单位复根是正n边形的顶点。而通过上面这个式子，我们又发现我们平方以后将这个正n边形变成了正n/2边形。也就意味着，x的真正的取值数量被我们缩减到一半了。根据分治递归的思维，你知道会一直这么缩减下去，于是复杂度就降低到了O(lgn). 那么是怎么缩减的呢？表现在公式上是什么样子？ 这里n是2的幂，下面我们令n=4. 由于需要表示单位复根的次数，现在的编辑格式不允许上下标。所以引入一张图，其中：\nW的下标表示单位复根的次数，上标表示这是第i个取值。 这里通过公式可以发现其重复的顺序是前n/2 与后n/2一致。新的完整公式如下： 其实不通过这个公式，从上面的几何意义中我们也可以找到规律。因为点的值就跟k有关嘛，正n边形缩小为正n/2边形，其角度的分子变成2倍，那么对应的角度就会呈现一轮接一轮的规律。例如原本是正8边形，这八个点分布在8个方向上，角度分别是0，45，90，135，180，\u0026hellip; 然后我们将每个的角度都乘以2.，就变成了0，90，180，270，0\u0026hellip;.\n这部分就是折半引理\n总结 # 到这里我们介绍了其中的一些数学原理，虽然这个对于写代码来说并没有多少用处。但是知道原理搞起来更爽，不断的探寻世界的真理，如果其他的东西不好探究，至少某些数学的原理还是好探究的。\n这只是整个过程的一半呢，从我们计算多项式乘法的步骤来看，\n计算点值（求值） 点乘 计算计算系数（插值） 现在我们只是讲完了计算点值的理论还没有写计算点值的分治代码。但是接下来不打算直接写代码，因为理论还没有结束，过程非常巧妙。\n点乘的部分就不用说了，就是扫一遍就好了。\n插值 # 求值的过程其实就是一个矩阵乘法这个我们说过了, 如下，其中下标两个数分别表示n次单位复根 和第i个单位复根 我们知道这里的n个变量之间是有关系的，所以我们可以进行消掉一些变量。这时候我们引入一个特殊的变量叫做：主单位复根，并使用该复根替代其他的变量。主单位复根是指k取1时的那个复根，值为：W1 = cos(2pi/n) + isin(2pi/n)。 这个可以直接计算出来的，所以这个矩阵就变成了一个新的范徳蒙德矩阵。新式子如下： 在引入一个求和引理：\n对于任何n\u0026gt;=1 和不能被n整除的非零整数k，有： SIGMA{i=0,n-1}{(Wn,k)^i} = 0; 这里引理暂时看不懂没有关系。这个引理主要用来求这个矩阵的逆矩阵的。因为要插值可以直接用逆矩阵来搞。\n我觉得这部分的证明就没太有意思了，因为我看的证明是特么直接给出结论然后证明的，跟不证明没有什么区别。 我们只要知道这个矩阵的逆矩阵很有规律，而且跟原矩阵有很大关系，待会儿写代码的时候会说。\n从程序设计的角度理解 # 还是问这个问题，就是快速傅立叶变换到底做什么以及到底做了什么？ 答： 快速傅立叶变换是用来快速求向量卷积的。 在本例中就是求多项式乘法。两个向量的卷积仍然是一个向量，长度为原向量长度之和-1。\n对于程序设计来说，知道输入和输出，就可以拿封装好的代码拿来用了。\n"},{"id":65,"href":"/posts/web/cgi/","title":"CGI 通用网关协议","section":"Web","content":"这是实现Web服务的最基础程序。目前只是看到了一些比较，但是我还没有时间去Read the fucking source code.\n这样的程序算是计算机网络中比较有学习意义的代码。\n在此简单的介绍一下先。\ntcp通信过后，服务端需要有一个程序做为衔接程序，来将请求进一步转发给逻辑服务程序，并将结果返回给浏览器，做了个信使的角色。\n"},{"id":66,"href":"/posts/web/servlet/","title":"Servlet","section":"Web","content":"这里有一些概念非常的恶心，一开始的时候不太好理解是什么。通过一段时间的实践，我逐渐理解，所以直到今天才开始写这一篇。\n容器Container # 这个概念从我一开始接触Java就让我很困惑。 首先你需要先去看一下我在后面的一篇关于tomcat的配置文件：server.xml。在那里了解一下配置文件的结构，你可以看懂下面的这张图片。 首先，容器这个东西是针对servlet来说的，也就是我们说的容器都是放置和运行servlet的程序。tomcat是个容器。但是上面的每一级都算是一种容器，只是大小不同。\n为什么要有容器 # 其实对于计算机软件体系来说，一切的东西的出现都是因为标准和规定。 所谓容器其实就是一个程序，这个程序按照servlet需要的标准实现了一些接口，使得当你写了一个servlet以后可以成功的放在这个程序中运行，再直白一点就是，你把你的servlet程序交给这个容器，容器可以成功的运行你的程序。\n他们之间通过约定一些标志物信息来实现无缝对接。 所以学习这写东西就是在学习了解他们之间约定的事物，以及，为什么这么约定，这样的约定有什么好处和坏处。\n容器是一段程序吗？ # 在tomcat中，并没有容器这个东西，所以容器并不是一个东西，就像水果并不是一个具体的苹果一样。容器是一个抽象的概念。\n在tomcat中，如上图，有很多的层。这些层就是一个容器结构。他们一起构成了一个完整的容器。\nEngine 是一段基础的引擎程序。我认为是整个tomcat的基础，所有的其他容器都在其的调度控制之下。\nHost 这是一个逻辑概念，但也有对应的实体。在讲tomcat的配置文件servers.xml 的时候，有提到这个host是什么回事。有了这一层，可以在一个tomcat容器中部署不同的项目，这些项目的域名都是不同的。也就是这个容器可以容纳很多的servlet并且这些servlet可以是几种粒度的。\n你可以是完全不同的两个网站，域名都不同，放在一个容器中运行。你也可以是一个网站的不同组件，放在不同的Context内运行。\n所以容器是个体系，不是一个东西。 其实按照这个思路，一切皆容器。因为一切的这些都是调度管理，操作系统调度进程，进程调度线程。一切都是接口和约定。所以万物皆容器。\n什么是servlet # 这是一个标准，你的程序符合这个标准就是一个servlet程序。 一个类其实就是一个servlet，但是很多个类在一起只要有一个servlet的接口，也是一个servlet。 （在此我们不再讨论tomcat的启动过程，我们更关心一个servlet放入tonmcat容器以后的过程）\n来看一下这个图片，这就是servlet主要关联的几个类。 **摘抄：** 从上图可以看出 Servlet 规范就是基于这几个类运转的，与 Servlet 主动关联的是三个类，分别是 ServletConfig、ServletRequest 和 ServletResponse。这三个类都是通过容器传递给 Servlet 的，其中 ServletConfig 是在 Servlet 初始化时就传给 Servlet 了，而后两个是在请求达到时调用 Servlet 时传递过来的。\n我们很清楚 ServletRequest 和 ServletResponse 在 Servlet 运行的意义，但是 ServletConfig 和 ServletContext 对 Servlet 有何价值？ 仔细查看 ServletConfig 接口中声明的方法发现，这些方法都是为了获取这个 Servlet 的一些配置属性，而这些配置属性可能在 Servlet 运行时被用到。 而 ServletContext 又是干什么的呢？ Servlet 的运行模式是一个典型的“握手型的交互式”运行模式。所谓“握手型的交互式”就是两个模块为了交换数据通常都会准备一个交易场景，这个场景一直跟随个这个交易过程直到这个交易完成为止。这个交易场景的初始化是根据这次交易对象指定的参数来定制的，这些指定参数通常就会是一个配置类。所以对号入座，交易场景就由 ServletContext 来描述，而定制的参数集合就由 ServletConfig 来描述。而 ServletRequest 和 ServletResponse 就是要交互的具体对象了，它们通常都是作为运输工具来传递交互结果。\n一个web应用是如何被初始化的 # 对于tomcat来说，会一层一层的往下进行初始化，第一件要做的事情就是去找配置文件。 对于一个应用来说，首先会找到他的web.xml。tomcat会把这个文件解析成一个属性的类的对象WebXml。随后根据这个WebXml去设置这个context的容器环境。 这个时候就会创建对应的servlet对象，filter，listener等等。\n这里有一个小的点，我看到了，写一下： 创建servlet对象的时候，并不是直接实例化成一个servlet对象，而是包装成StandardWrapper。 为什么要将 Servlet 包装成 StandardWrapper 而不直接是 Servlet 对象。这里 StandardWrapper 是 Tomcat 容器中的一部分，它具有容器的特征，而 Servlet 为了一个独立的 web 开发标准，不应该强耦合在 Tomcat 中。\n但是初始化还并没有完成。\n创建servlet对象 # 如果 Servlet 的 load-on-startup 配置项大于 0，那么在 Context 容器启动的时候就会被实例化, 在 conf 下的 web.xml 文件中定义了一些默认的配置项，其定义了两个 Servlet，分别是：org.apache.catalina.servlets.DefaultServlet 和 org.apache.jasper.servlet.JspServlet 它们的 load-on-startup 分别是 1 和 3，也就是当 Tomcat 启动时这两个 Servlet 就会被启动。\n创建 Servlet 实例的方法是从 Wrapper. loadServlet 开始的。 loadServlet 方法要完成的就是获取 servletClass 然后把它交给 InstanceManager 去创建一个基于 servletClass.class 的对象。如果这个 Servlet 配置了 jsp-file，那么这个 servletClass 就是 conf/web.xml 中定义的 org.apache.jasper.servlet.JspServlet 了。\n初始化 Servlet # 初始化 Servlet 在 StandardWrapper 的 initServlet 方法中，这个方法很简单就是调用 Servlet 的 init 的方法，同时把包装了 StandardWrapper 对象的 StandardWrapperFacade 作为 ServletConfig 传给 Servlet。Tomcat 容器为何要传 StandardWrapperFacade 给 Servlet 对象将在后面做详细解析。\n如果该 Servlet 关联的是一个 jsp 文件，那么前面初始化的就是 JspServlet，接下去会模拟一次简单请求，请求调用这个 jsp 文件，以便编译这个 jsp 文件为 class，并初始化这个 class。\n这样 Servlet 对象就初始化完成了，事实上 Servlet 从被 web.xml 中解析到完成初始化，这个过程非常复杂，中间有很多过程，包括各种容器状态的转化引起的监听事件的触发、各种访问权限的控制和一些不可预料的错误发生的判断行为等等。我们这里只抓了一些关键环节进行阐述，试图让大家有个总体脉络。\nservlet 是如何工作的 # 当用户从浏览器向服务器发起一个请求，通常会包含如下信息： http://hostname: port /contextpath/servletpath， hostname和 port 是用来与服务器建立 TCP 连接，而后面的 URL 才是用来选择服务器中那个子容器服务用户的请求。那服务器是如何根据这个 URL 来达到正确的 Servlet 容器中的呢？\nTomcat7.0 中这件事很容易解决，因为这种映射工作有专门一个类来完成的，这个就是 org.apache.tomcat.util.http.mapper，这个类保存了 Tomcat 的 Container 容器中的所有子容器的信息，当 org.apache.catalina.connector. Request 类在进入 Container 容器之前，mapper 将会根据这次请求的 hostnane 和 contextpath 将 host 和 context 容器设置到 Request 的 mappingData 属性中。所以当 Request 进入 Container 容器之前，它要访问那个子容器这时就已经确定了。\n下面这幅图就解释了整个流程 我们现正知道了请求是如何达到正确的 Wrapper 容器，但是请求到达最终的 Servlet 还要完成一些步骤，必须要执行 Filter 链，以及要通知你在 web.xml 中定义的 listener。\n接下去就要执行 Servlet 的 service 方法了，通常情况下，我们自己定义的 servlet 并不是直接去实现 javax.servlet.servlet 接口，而是去继承更简单的 HttpServlet 类或者 GenericServlet 类，我们可以有选择的覆盖相应方法去实现我们要完成的工作。\n上面是基础的servlet原理，现在也很少有人直接这样用了，大多数会使用spring这样的框架来完成，在我的每天读点spring中去详细解释。\n在使用spring的时候，我们往往只要配置一个spring的分发器的servlet。然后剩余的工作就交给这个分发器继续管理。所以我们可以使用注解来定义spring框架下的servlet。以及其他的特性。\n"},{"id":67,"href":"/posts/redis/geohash/","title":"GeoHash","section":"Redis","content":"在做Redis页面控制台命令支持的过程中，对于Redis的GEO模块突然很感兴趣，不明白这个数据结构为什么突然就跟Set、Sorted Set一起出现了。然后发现这个数据结构居然是用来存地理位置信息的，很不简单，要看一下到底是什么幺蛾子。\nGeo模块专用于存储地理位置信息，突出的有点是可以快速获取某一地理位置附近的相关位置信息。比如你要在某个地方找吃的，搜索附近2km的餐厅，后台使用的就是GeoHash的算法，Redis原生就支持这个数据算法结构，可见其应用场景支持非常丰富，有很大的应用空间。\nGeoHash算法 # 其实这个原理是很简单的，对于地理位置信息，一般我们用经纬度来表示，这就将球面转换成了一个二维平面。在二维平面快速的定位一个位置并查找周围位置信息，就是这个算法解决的主要问题。、\n传统的我们可能用一种树结构来搞，但是那样的时间效率和空间效率都不高。\nGeoHash过程 # Geohash的主要过程就是将经纬度信息Hash成一个字符串。\n将经纬度各自Hash成一个二进制串。 将两个串插叠，奇数位插维度串，偶数位插经度串。 将该串用base32进行编码生成字符串。 原理 # 在第一步中主要用二分的方法来Hash生成二进制串。例如对于维度：北纬30，其在北纬第一位设成1，由位于0-45所以第二位为0，这样一直做20次二分，就可以得到一个长度是20的串。 对于精度同样这样做一遍。\n然后插叠得到一个长度为40的二进制串，然后用base32方式编码生成一个长度为8的字符串。\n将这个字符串存下来就好啦。\nGeohash特性 # 由过程可以看出来，这个Hash出来的字符串的特性，就是相同区域的两个点的Hash结果前缀一致。这样当我们要查找某个位置周围2km的餐厅只要匹配到字符串的前5位相同就可以了。\n边缘误差 # 这个算法是存在边缘误差的，因为如果两个点相距的很近，但是在二分的过程中分在不同的两块中，这样的Hash结果就相差很大, 如下图中的红点位置与两个绿点位置。\n解决这个问题的方式也很直观。\n当我们在查找某一点周围的地理位置的时候，将其对应的周围8块区域的点都取出来，然后计算一下距离做个筛选就可以了。 这个区域的点并不会太大。\n这些小算法还是很好玩的。\n"},{"id":68,"href":"/posts/java/spring/","title":"spring","section":"Java","content":"这篇文章原本是要完整的讲SpringMVC，现在觉得Spring自己要单独讲一下，SringMVC要单独写个瞎搞教程，混在一起不利于理解，而且写的太乱，所以本问只是介绍一些Spring的特性和一些概念。\nSpring 是为了解决企业应用程序开发复杂性而创建的。框架的主要优势之一就是其分层架构，分层架构允许选择使用哪一个组件，同时为 J2EE 应用程序开发提供集成的框架。\n之前在学习Spring框架的时候主要研究了两个概念，一个是：控制反转(IOC)，还有一个是：面向切面编程(AOP)。今天来整理一下。\nSpring 模块 # 学习框架或是其他的库，先概览一下这个东西是由什么组成，然后顺着这个设计思路就可以理解其工作方式。 据说Spring的模块化做的很好，每个模块都可以单独存在。下面这附图很直观的描述了其体系结构。 分两层，共7个模块，其他模块工作在Core模块之上。 每个模块的功能如下:\n核心容器：核心容器提供 Spring 框架的基本功能。核心容器的主要组件是 BeanFactory，它是工厂模式的实现。BeanFactory 使用控制反转 （IOC） 模式将应用程序的配置和依赖性规范与实际的应用程序代码分开。 Spring Context：Spring 上下文是一个配置文件，向 Spring 框架提供上下文信息。Spring 上下文包括企业服务，例如 JNDI、EJB、电子邮件、国际化、校验和调度功能。 Spring AOP：通过配置管理特性，Spring AOP 模块直接将面向切面的编程功能集成到了 Spring 框架中。所以，可以很容易地使 Spring 框架管理的任何对象支持 AOP。Spring AOP 模块为基于 Spring 的应用程序中的对象提供了事务管理服务。通过使用 Spring AOP，不用依赖 EJB 组件，就可以将声明性事务管理集成到应用程序中。 Spring DAO：JDBC DAO 抽象层提供了有意义的异常层次结构，可用该结构来管理异常处理和不同数据库供应商抛出的错误消息。异常层次结构简化了错误处理，并且极大地降低了需要编写的异常代码数量（例如打开和关闭连接）。Spring DAO 的面向 JDBC 的异常遵从通用的 DAO 异常层次结构。 Spring ORM：Spring 框架插入了若干个 ORM 框架，从而提供了 ORM 的对象关系工具，其中包括 JDO、Hibernate 和 iBatis SQL Map。所有这些都遵从 Spring 的通用事务和 DAO 异常层次结构。 Spring Web 模块：Web 上下文模块建立在应用程序上下文模块之上，为基于 Web 的应用程序提供了上下文。所以，Spring 框架支持与 Jakarta Struts 的集成。Web 模块还简化了处理多部分请求以及将请求参数绑定到域对象的工作。 Spring MVC 框架：MVC 框架是一个全功能的构建 Web 应用程序的 MVC 实现。通过策略接口，MVC 框架变成为高度可配置的，MVC 容纳了大量视图技术，其中包括 JSP、Velocity、Tiles、iText 和 POI。 就这一段我copy过来的东西就有很多新鲜的东西。解释一下： 工厂模式和bean 这个东西就很大，简单说，工厂模式是一种设计模式。程序设计，搞到现在终于体会到什么是程序设计了吧。跟工业革命是一个道理，从手工作坊到工厂生产。这种设计模式无非就是要简化你写代码的过程，而这个工厂模式就是用来简化对象创建过程的一个设计模式。 在创建一个复杂对象的时候，往往我们要先建一些辅助对象，然后把辅助对象塞进去才能把对象真正new出来。这就是传统手工生产。 但是工厂模式也不是就那么简单的，这个工厂模式还有一个发展过程\n1）简单工厂模式（Simple Factory） 又称静态工厂方法模式 2）工厂方法模式（Factory Method） 3）抽象工厂模式（Abstract Factory） 简单工厂模式就是有一个工厂类，他专门负责生产对象，但是只能生产某1个对象。 工厂方法模式就是有一个抽象的工厂类或是工厂接口，各个派生工厂类各自生产某一个对象。有一个抽象产品类，然后派生多个产品类。 抽象工厂模式就是有多个抽象工厂类和多个抽象产品类，然后每个工厂类可以生产很多种产品。\n其实这就跟现实生活中的工厂发展类似，最初刚有工厂的时候，建这一个工厂只能生产一种特性的产品，这个产品改个颜色都可能实现不了。然后这个产品不断的发展有不同的型号，就开多个工厂，或是多个生产线。对于销售部们来说，工厂怎么生产并不重要，他们只需要发个请求给抽象工厂类，说自己要什么型号工厂就会送过来。 然后对于企业高层整体来说，这样的管理还是太乱了，自己要同时管理这么多工厂，每个工厂在什么时候做什么还要管。他们最希望的就是能有一种综合工厂出现，这个综合工厂什么都能生产，然后这个工厂的管理单独交给一个人来做。当然这是一个抽象的概念了，不存在什么都能生产的工厂，但是抽象以后就把工厂管理这件事情留在了底层，上层不需要插手。这就是工厂的发展思路。 对下工作细分，对上接口统一。这是作为一个组件所必须具有的特性。记住这个原则，就能明白了。\n对与写程序来说，刚开始我们会写一个方法，做到传几个参数就返回给我一个类。后来渐渐的每个类都要写这个方法很累。你就想写一个类，在这个类里写一个通用的方法，并设计一种规则来准确描述你的需求，也就是你要生成的对象。然后这个类就根据你的描述流程化的生产出来这个类给你，这样你只要编写描述语句就可以了。也能够一定程度上实现动态配置，因为文本文件变化不需要编译，只需要打包就好了，非常快。再往上就超出了我目前的理解范围，哈。 我的理解也只是一种形象的认识，很浅显。参考自两篇文章:文章1、文章2。有兴趣的可以去看看。\nJava bean是一个规范，符合这个规范的类可以称为Bean。这个规范使用在基础可重用组建的开发中。其特点是类中实现一些：isXX()、setXX()、getXX()、addXX()、removeXX()等。其主要解决的问题是向后兼容性问题。通俗的讲就是你要保证你的类在更改了内部实现方法以后其接口不变。也就原来怎么获取一个值，现在还怎么获取这个值，无论你类内的实现是实时计算还是实时记录。可以看这个描述\nORM框架 我认为这不是一个好的设计，也不是一个好的组建，最好不用。 这个就是在数据库的SQL上做一层封装，屏蔽数据库SQL之间的差异，用一种ORM语言来进行数据操作。 好处就那么一些，但是坏处：\n第一 这是设计给不懂数据库的人用的。但是学习ORM语言和体系本身也要成本，不如直接学习SQL。 第二 效果不理想，无法覆盖问题，速度还慢。 第三 错误不好定位。 IOC 控制反转 # 这些框架和规范，其最终的目的都无非这么几个：解耦、兼容、加速。 控制反转也称为依赖注入。 这个控制反转不是很好理解，但是依赖注入就很好理解了。 所谓依赖就是一的一个类中要依赖很多其他的类，那么在实例化的时候就要把这些依赖的类都实例化掉。当然很麻烦了，而且实例化越多程序就越慢！这个依赖注入就是上面的工厂模式的实现方式。 通过配置文件，描述类之间的依赖关系，然后由工厂，也可以认为是IOC容器来读取这个文件，并帮你组装好你要的实例，你只要申请一下就行了。在Spring中你都不需要申请，他会监测你的需求。\n依赖具体指什么呢？ 如果我们写一个汽车的类，那么这个汽车的类就会以其他的类做为成员，比如方向盘类。当我方向盘类中的参数发生变化的时候，不同的代码写法就会有不同的效果。我们肯定希望我们要改动的地方越少越好，最好是不用改代码。下面举例子来说明两种注入方式：构造注入、工厂注入\nclass Car { P pan; Car(){ pan = new P(10); } } /* 如果我们需要一个直径是10的方向盘，我们可以这样写。 但是如果这个P类的构造方法发生了变化，这个类也要改，因为你调用了这个构造方法。 构造注入的方式是下面这种： */ class Car { P pan; Car(P _pan){ pan = _pan; } } /* 这就解决了上面的问题。 下面这个例子是工厂注入的方式。 */ class Factory{ Car c = new Car(); Car getCar(){ return c; } } main(String[] args){ Car car = Factory.getCar(); } // 其本质就是工厂设计模式，只是在Spring中有了特殊的角色而已。 AOP 面向切面编程 # 面向对象已经不能满足的程序员对程序设计的追求了。 什么是切面呢。 对于一个程序来说，一旦我们启动就顺序执行，这个是没有问题的。然而面向切面编程的方式能够在你的程序中运行一些特定的程序，但是这些程序是你没有写的，就比如说日志。 其可以将日志等组件，原本是是要分散在程序中各个地方的模块化，在需要使用的部件中配置一下就可以了完成其使命。使得日志对编写程序的工程师来说是透明的。 所以所谓切面就是程序运行流程的切面。\nAOP技术是建立在Java语言的反射机制与动态代理机制之上的。其原理也并不复杂，当运行过程中我们要调用一个类的时候，其实我们调用的并不是原始的类，AOP动态创建了一个代理类给你调用，并且将预先配置的例如日志组件插入到目标方法中，从而实现将组建复合进程序切面中同时执行。\n关于这方面的东西，底层的东西我也不太懂。有几个概念需要知道：\n连接点（Joinpoint）：就是程序在运行过程中能够插入切面的地点。例如，方法调用、异常抛出或字段修改等，但spring只支持方法级的连接点。 切入点（Pointcut）：用于定义通知应该切入到哪些连接点上。不同的通知通常需要切入到不同的连接点上，这种精准的匹配是由切入点的正则表达式来定义的。 （用于定义：啥时候干） 通知（Advice）：是切面的具体实现。以目标方法为参照点，根据放置的地方不同，可分为前置通知（Before）、后置通知（AfterReturning）、异常通知（AfterThrowing）、最终通知（After）与环绕通知（Around）5种。在实际应用中通常是切面类中的一个方法，具体属于哪类通知，同样是在配置中指定的。 （用于定义：干啥） 相比之下，面向对象是细腻的，用继承和组合的方式，绵绵编织成一套类和对象体系。 面向切面是豪放的，大手一挥：凡某包某类某开头的方法，一并如斯处理！\n没有依赖注入，面向切面就失去立足之本。 没有面向切面，依赖注入之后也只好在各个方法里下死力气写重复代码，或者搞出来一个超级复杂的抽象基类。\n同时有了这两者，才真正能履行拆分、解耦、模块化、约定优于配置的思想，才真正能实现合并重复代码、专注业务逻辑的愿望。\n概念都介绍的差不多了，下面来用吧。 需要说明的是，Spring是个广泛应用的框架，在软件的各个场景都可以使用，在Web上，有Spring MVC的组合使用方式。\n"},{"id":69,"href":"/posts/bash/commands/","title":"真正的老司机如何用Linux文本命令","section":"Bash","content":"Tomcat是最烂的软件，没有之一！Over! 因为日志系统冲突的问题，这两天跟Tomcat斗争了好久，最终被其无耻下流卑鄙所折服，自信点，你就是最烂的！于是就诞生了上一篇长文来叙述日志是怎么搞，现在这一篇也是在实战中学习到的。\n曾经学这些命令的时候只知道这些命令有很多功能，也很困惑，一个命令搞这么多参数干嘛，有什么用啊，我反正不会用。然后今天就脸红了，是我不会用。 不得不说设计这些命令的前辈真的很厉害，然后发现windows就这么丢弃这些东西真的是自断后路。盖茨肯定意识到电脑以后会是标配，但是他一定没有意识到自己在让计算机变傻。或许他本身就很傻吧，不是很能懂，自己一个号称最优秀的程序员之一的人，在设计计算机的时候就这么把这些东西屏蔽掉，自己真的打算用吗？计算机是越来越多了，但是其真正强大的功能都被windows阉割了，也阉割了真正的优雅，一定程度上，我认为盖茨理解错了计算机处理信息的价值。\n我喜欢vim、latex、linux他们都有一个共同的特点，就是连通性非常强，而且操作简单。在工作过程中除了浏览网页，我基本上不会用鼠标，快捷键加命令可以无所不达。\n一般我会开两个终端窗口，一屏左右各占一个。开发服务器相关的应用的时候左边终端在本地，右侧终端ssh连进服务器。就单单这一个操作，在windows下就要复杂N倍，要安装软件才能支持ssh协议，还要软件模拟服务器终端，丑的要死不说，各种切换操作都要依靠鼠标\u0026hellip; 而在linux的终端下，每个操作都只是简单的一个命令的事情，可以用命令完整精准的描述你的想法，所想即所得。\n下面几个命令，很强大。 ps、less、head、tail、grep、watch\u0026hellip;\nps # 你知道Tomcat自己的bin/shutdown.sh是无法把自己关闭的吗？很抱歉，我特么这么用了一天了。然后ps发现一堆tomcat进程在跑，顿时恐惧袭上心头。关不掉你就别写个shutdown.sh啊，坑死爸爸了。 下次要关tomcat就特么直接kill，就不用那么麻烦了。\nps 命令是一个系统进程的快照。他通过读取/proc文件的方式获取信息。 使用man 命令获取内置说明文档：man ps，就可以看到各个参数的说明。这里会介绍一些参数的用法，但是仅仅是做个记录而已，有价值的东西是后面的实战例子。\n在参数中，ps命令支持三种命令格式：\nUnix 带短线(dash)：-a 参数 BSD 不带短线(dash)：a 参数 GNU 两个连续短线(two dash)：--a 参数 一般我用Unix格式的参数。 在解释这个命令之前还要解释一个东西就是Linux的进程。 在Linux中，一个进程组(process group)都是独一无二的会话(session)，这个session的ID就是这个session的第一个process的ID。这个进程也叫做the session leader。\n-e 获取所有的进程，与-A 一毛一样。 -aux 获取所有的进程的详细信息。包括没有tty的进程和leader进程。 包含一下信息： USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND -C cmdlist 获取对应cmd的进程 -p pidlist 获取对应pid的进程 -u userlist 获取对应user的进程 -f 获取格式化信息 --sort spec 根据spec排序输出，example：ps jax --sort=uid,-ppid,+pid + - 代表增序和降序 example: 按cpu时间排序 ps -aux --sort -pcpu example: 按内存使用排序 ps -aux --sort -pmem example: ps -aux --sort -pcpu,+pmem 多标准排序 k 与sort同等作用 -L pid 获取特定进程的所有线程 -jaxf 以树形显示进程 -eo 控制输出，可用来产看特定字段信息 example: ps -eo pid,user,args 查看谁登录了你的机器 -m 在进程后面输出线程 上面这些只是基础知识，下面在补充一些： 进程状态STAT代码\nD uninterruptible sleep (usually IO) R running or runnable (on run queue) S interruptible sleep (waiting for an event to complete) T stopped by job control signal t stopped by debugger during the tracing W paging (not valid since the 2.6.xx kernel) X dead (should never be seen) Z defunct (\u0026#34;zombie\u0026#34;) process, terminated but not reaped by its parent \u0026lt; high-priority (not nice to other users) N low-priority (nice to other users) L has pages locked into memory (for real-time and custom IO) s is a session leader l is multi-threaded (using CLONE_THREAD, like NPTL pthreads do) + is in the foreground process group -o 输出格式 example： ps -eo \u0026ldquo;%p %y %x %c\u0026rdquo;\nCODE NORMAL HEADER %C pcpu %CPU %G group GROUP %P ppid PPID %U user USER %a args COMMAND %c comm COMMAND %g rgroup RGROUP %n nice NI %p pid PID %r pgid PGID %t etime ELAPSED %u ruser RUSER %x time TIME %y tty TTY %z vsz VSZ less # 是一个文本查看器，more的升级版，且以vi命令为基础。 类似的命令有下面几个：\ncat 由第一行开始显示内容，并将所有内容输出 tac 从最后一行倒序显示内容，并将所有内容输出 more 根据窗口大小，一页一页的现实文件内容 less 和more类似，但其优点可以往前翻页，而且进行可以搜索字符 head 只显示头几行 tail 只显示最后几行 nl 类似于cat -n，显示时输出行号 tailf 类似于tail -f less 选项参数\n-N 显示每行的行号 空格 向下翻页 d 向后翻半页 u 向前滚动半页 / 向下搜索 ? 向上搜索 ma 使用 a 标记文本的当前位置 \u0026#39;a 导航到标记 a 处 文件参数有多个的时候可以打开多个文件，使用:n下一个文件，:p上一个文件。 也可以在less中:e file 打开新的文件。\nhead # head -n 10 # 显示前10行 tail # 显示文件最后几行，最关键是当文件尾内容在增加的时候会在这里动态更新出来。 看示例你就明白用来做什么了。\ntail -f xxx.log grep # 这是个匹配命令，明天详细写。\nwatch # watch可以帮你监测一个命令的运行结果，周期性的执行下个程序\n-n 间隔秒数，默认2s -d 高亮发生变化的位置 -d=cumulative 将历史中变化过的地方都标记出来 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 Example\nwatch -d -n 1 netstat -ntlp watch -n 1 ”df -i;df” #监测磁盘inode和block数目变化情况 watch -n 60 -d du -ah # 查看usb3.0拷贝到该目录下面的速度 watch -n 1 ‘ps -aux --sort -pmem, -pcpu’ # 动态查看进程排序信息 watch -n 1 ‘ps -aux --sort -pmem, -pcpu | head 20’ # 动态查看前10名 查看库是否安装 # ldconfig -p | grep libnccl\n"},{"id":70,"href":"/posts/java/log/","title":"Java-Log日志","section":"Java","content":"日志以我目前使用到的，有两个功能。 第一，在上线调试的时候查看问题所在。 第二，在线上运行的时候，出现故障回看日志查询问题所在。 总之就是查问题出在哪里，因为编译型的程序没有办法直接搞中间输出来确定问题所在，写在文件里是最好的方式了。\nJava中有很多日志系统，但是根据经验，一定有一个日志的抽象层来统一各个日志系统。没错，今天就直接来用这个抽象层的日志工具：SLF4J(Simple logging facade for Java)。它允许你在后台使用任意一个日志类库。如果是在编写供内外部都可以使用的API或者通用类库，那么你真不会希望使用你类库的客户端必须使用你选择的日志类库。\n如果一个项目已经使用了log4j，而你加载了一个类库，比方说 Apache Active MQ——它依赖于于另外一个日志类库logback，那么你就需要把它也加载进去。但如果Apache Active MQ使用了SLF4J，你可以继续使用你的日志类库而无需忍受加载和维护一个新的日志框架的痛苦。\n日志原理 # 一般的日志都是由三个部分组成：logger、appenders、layouts。logger负责捕获记录信息，转给appender去转发到配置的目的地，layouts负责定义日志的格式。\n下面就具体的介绍一下Log4j帮助理解。\nLog4j # log4j 有很多优点：\nLog4j是高度可配置的，并可通过在运行时的外部文件配置。它根据记录的优先级别，并提供机制，以指示记录信息到许多的目的地，诸如：数据库，文件，控制台，UNIX系统日志等。 已经扩展到C/C++、C#、Perl、Python等语言中。 线程安全、速度快 多输出 也有一些缺点，比如不能保证所有日志信息都送到目的地在其出现故障的时候，会减慢程序的速度，不过这是所有日志都面临的问题，貌似也没有什么好的解决办法。\nlog4j 在使用的时候需要一个配置文件：log4j.properties或log4j.xml。\n如果是java project项目，则在项目的根目录下创建log4j.properties而不是在src目录下。 如果是java web项目，则在src目录下创建log4j.properties配置文件，因为这个时候tomcat会去默认的加载这个配置文件，而不需要我们手动的加载log4j的配置文件。 两种配置的基本配置选项都是一样的，log4j.properties的格式是更好理解的，奈何我拿到的是个该死的xml格式的项目。直观看很丑！非常丑！xml在我这的印象分又掉了一半。 还是先介绍各个选项的内容吧，形式不重要。\n选项参数 # 上面讲了日志的三个组成部分，其配置也就是针对这三个部分来搞的。 以properties的格式先介绍一下。\n#配置根Logger (Loggers) log4j.rootLogger = [ level ] , appenderName1 , appenderName2 , … #配置日志信息输出目的地 (Appenders) log4j.appender.appenderName = fully.qualified.name.of.appender.class log4j.appender.appenderName.option1 = value1 … log4j.appender.appenderName.optionN = valueN #配置日志信息的格式（Layouts） log4j.appender.appenderName.layout = fully.qualified.name.of.layout.class log4j.appender.appenderName.layout.option1 = value1 … log4j.appender.appenderName.layout.optionN = valueN 其中 [level] 是日志输出级别，共有5级：\nFATAL 0 ERROR 3 WARN 4 INFO 6 DEBUG 7 Appender 为日志输出目的地，Log4j提供的appender有以下几种：\norg.apache.log4j.ConsoleAppender （控制台） org.apache.log4j.FileAppender （文件） org.apache.log4j.DailyRollingFileAppender （每天产生一个日志文件） org.apache.log4j.RollingFileAppender （文件大小到达指定尺寸的时候产生一个新的文件） org.apache.log4j.WriterAppender （将日志信息以流格式发送到任意指定的地方） Layout 日志输出格式，Log4j提供的layout有以下几种：\norg.apache.log4j.HTMLLayout （以HTML表格形式布局）， org.apache.log4j.PatternLayout（可以灵活地指定布局模式）， org.apache.log4j.SimpleLayout （包含日志信息的级别和信息字符串）， org.apache.log4j.TTCCLayout （包含日志产生的时间、线程、类别等等信息） 输出格式控制符\n%m 输出代码中指定的消息 %p 输出优先级，即DEBUG，INFO，WARN，ERROR，FATAL %r 输出自应用启动到输出该log信息耗费的毫秒数 %c 输出所属的类目，通常就是所在类的全名 %t 输出产生该日志事件的线程名 %n 输出一个回车换行符，Windows平台为“/r/n”，Unix平台为“/n” %d 输出日志时间点的日期或时间，默认格式为ISO8601，也可以在其后指定格式，比如：%d{yyy MMM dd HH:mm:ss , SSS}，输出类似：2002年10月18日 22 ： 10 ： 28 ， 921 %l 输出日志事件的发生位置，包括类目名、发生的线程，以及在代码中的行数。举例：Testlog4.main(TestLog4.java: 10 ) Example 下面这个例子配置了一个Logger三个Appender，并给每个Appender分别配置。\n### set log levels ### log4j.rootLogger = debug , stdout , D , E ### 输出到控制台 ### log4j.appender.stdout = org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target = System.out log4j.appender.stdout.layout = org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern = %d{ABSOLUTE} %5p %c{ 1 }:%L - %m%n # %5p 的用法与c语言有相似之处，此处指在前面加入5个空格。 ### 输出到日志文件 ### log4j.appender.D = org.apache.log4j.DailyRollingFileAppender log4j.appender.D.File = logs/log.log log4j.appender.D.Append = true log4j.appender.D.Threshold = DEBUG ## 输出DEBUG级别以上的日志 log4j.appender.D.layout = org.apache.log4j.PatternLayout log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n ### 保存异常信息到单独文件 ### log4j.appender.D = org.apache.log4j.DailyRollingFileAppender log4j.appender.D.File = logs/error.log ## 异常日志文件名 log4j.appender.D.Append = true log4j.appender.D.Threshold = ERROR ## 只输出ERROR级别以上的日志!!! log4j.appender.D.layout = org.apache.log4j.PatternLayout log4j.appender.D.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n # 可以在%与模式字符之间加上修饰符来控制其最小宽度、最大宽度、和文本的对齐方式。如： # 1)%20c：指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，默认的情况下右对齐。 # 2)%-20c:指定输出category的名称，最小的宽度是20，如果category的名称小于20的话，\u0026#34;-\u0026#34;号指定左对齐。 # 3)%.30c:指定输出category的名称，最大的宽度是30，如果category的名称大于30的话，就会将左边多出的字符截掉，但小于30的话也不会有空格。 # 4)%20.30c:如果category的名称小于20就补空格，并且右对齐，如果其名称长于30字符，就从左边较远输出的字符截掉。 在代码中，我们需要先初始化Logger，然后直接使用。不过一般都不是这样用的，基本上都是servlet来自动初始化，基本上是Tomcat的锅。还有就是我们代码使用Slf4j来操作，也不需要自己初始化。\npublic class TestLog4j { public static void main(String[] args) { PropertyConfigurator.configure( \u0026#34; D:/Code/conf/log4j.properties \u0026#34; ); Logger logger = Logger.getLogger(TestLog4j. class ); logger.debug( \u0026#34; debug \u0026#34; ); logger.error( \u0026#34; error \u0026#34; ); } } Another Example 当我们一个系统中有多个部件的时候，我们会希望不同的部件日志打到不同的地方去。典型的就是一些十分重要的紧急错误需要能够直接发短信给运维人员报警，一些运维正常信息就可以先直接打进日志文件待日后查看即可。所以对于不同的类我们可以配置不同的Logger，还记得Logger的作用是捕获异常信息吧。 我们在需要用到某种Logger的时候只要在程序中GetLogger(LoggerName)即可。然后就可以在这个程序中使用某种Logger了。下面给一个这样的例子：\nlog4j.rootLogger = debug, log # All Loggers log4j.logger.com.apa.test.startUpListener = debug, appendListener log4j.logger.com.apa.test.brain.common = debug, appendCommon log4j.logger.com.apa.test.brain.middle = debug, appendMiddle log4j.logger.com.apa.test.brain.northboundif.restif = debug, appendNorthboundifRestif log4j.logger.com.apa.test.brain.compute = debug, appendNorthboundifHandle log4j.logger.com.apa.test.addition.onekey = debug, appendOnekey log4j.logger.com.apa.test.brain.api.v1private.serviceController = debug, serviceController log4j.logger.com.apa.test.brain.common.serviceController = debug, serviceController log4j.logger.com.apa.test.brain.compute.serviceController = debug, serviceController # All Appenders log4j.appender.stdout = org.apache.log4j.ConsoleAppender log4j.appender.stdout.Target = System.out log4j.appender.stdout.layout = org.apache.log4j.PatternLayout log4j.appender.stdout.layout.ConversionPattern = %-d{yyyy-MM-dd HH:mm:ss} [ %t:%r ] - [ %p ] %m%n log4j.appender.appendCommon = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendCommon.layout = org.apache.log4j.PatternLayout log4j.appender.appendCommon.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendCommon.File = ${catalina.home}/logs/tiddo/common/common.log log4j.appender.appendCommon.Append = true log4j.appender.appendCommon.Threshold = DEBUG log4j.appender.serviceController = org.apache.log4j.RollingFileAppender log4j.appender.serviceController.MaxFileSize = 300MB log4j.appender.serviceController.MaxBackupIndex = 10 log4j.appender.serviceController.layout = org.apache.log4j.PatternLayout log4j.appender.serviceController.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.serviceController.File = ${catalina.home}/logs/tiddo/serviceController/api.log log4j.appender.serviceController.Threshold = DEBUG log4j.appender.appendListener = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendListener.layout = org.apache.log4j.PatternLayout log4j.appender.appendListener.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendListener.File = ${catalina.home}/logs/tiddo/listener/listener.log log4j.appender.appendListener.Append = true log4j.appender.appendListener.Threshold = DEBUG log4j.appender.appendMiddle = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendMiddle.layout = org.apache.log4j.PatternLayout log4j.appender.appendMiddle.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendMiddle.File = ${catalina.home}/logs/tiddo/middle/middle.log log4j.appender.appendMiddle.Append = true log4j.appender.appendMiddle.Threshold = DEBUG log4j.appender.appendNorthboundifRestif = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendNorthboundifRestif.layout = org.apache.log4j.PatternLayout log4j.appender.appendNorthboundifRestif.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendNorthboundifRestif.File = ${catalina.home}/logs/tiddo/northboundif/restif/restif.log log4j.appender.appendNorthboundifRestif.Append = true log4j.appender.appendNorthboundifRestif.Threshold = DEBUG log4j.appender.appendNorthboundifHandle = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendNorthboundifHandle.layout = org.apache.log4j.PatternLayout log4j.appender.appendNorthboundifHandle.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendNorthboundifHandle.File = ${catalina.home}/logs/tiddo/northboundif/handle/handle.log log4j.appender.appendNorthboundifHandle.Append = true log4j.appender.appendNorthboundifHandle.Threshold = DEBUG log4j.appender.appendOnekey = org.apache.log4j.DailyRollingFileAppender log4j.appender.appendOnekey.layout = org.apache.log4j.PatternLayout log4j.appender.appendOnekey.layout.ConversionPattern = [%d{yyyy-MM-dd HH:mm:ss}]--[%t] [%p] -%l -%m%n%n log4j.appender.appendOnekey.File = ${catalina.home}/logs/tiddo/onekey/onekey.log log4j.appender.appendOnekey.Append = true log4j.appender.appendOnekey.Threshold = DEBUG log4j.appender.qpsWaterLevel=org.apache.log4j.RollingFileAppender log4j.appender.qpsWaterLevel.MaxFileSize=100MB log4j.appender.qpsWaterLevel.MaxBackupIndex=10 log4j.appender.qpsWaterLevel.layout=org.apache.log4j.PatternLayout log4j.appender.qpsWaterLevel.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss}|%m%n log4j.appender.qpsWaterLevel.file= ${catalina.home}/logs/tiddo/healthReport/qpsWaterLevel.log log4j.appender.abnormalQpsTenant=org.apache.log4j.RollingFileAppender log4j.appender.abnormalQpsTenant.MaxFileSize=100MB log4j.appender.abnormalQpsTenant.MaxBackupIndex=10 log4j.appender.abnormalQpsTenant.layout=org.apache.log4j.PatternLayout log4j.appender.abnormalQpsTenant.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss}|%m%n log4j.appender.abnormalQpsTenant.file= ${catalina.home}/logs/tiddo/healthReport/abnormalQpsTenant.log 关于其输出到其他地方的做法，留待以后探索，参考自Blog。\nlog4j.xml 当你对properties的规则有所了解之后，再看xml格式的就很好理解了。本质是一样的，只是换了一种组织形式。 在其中我们找到root、appender、layout\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE log4j:configuration SYSTEM \u0026#34;log4j.dtd\u0026#34;\u0026gt; \u0026lt;log4j:configuration\u0026gt; \u0026lt;appender name=\u0026#34;event4j\u0026#34; class=\u0026#34;org.apache.log4j.DailyRollingFileAppender\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;File\u0026#34; value=\u0026#34;logs/com.test.event.third.event4j.log\u0026#34; /\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.PatternLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %m%n\u0026#34; /\u0026gt; \u0026lt;!-- value=\u0026#34;%d %-5p [%t] %C{2} (%F:%L) - %m%n value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p [%t] %C{2} (%F:%L) - %m%n --\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;Console\u0026#34; class=\u0026#34;org.apache.log4j.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.PatternLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;%d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %m%n\u0026#34; /\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;root\u0026gt; \u0026lt;priority value=\u0026#34;info\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;event4j\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;Console\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/log4j:configuration\u0026gt; 留作参考的另外一个例子\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;GBK\u0026#34; ?\u0026gt; \u0026lt;!DOCTYPE log4j:configuration SYSTEM \u0026#34;log4j.dtd\u0026#34;\u0026gt; \u0026lt;log4j:configuration xmlns:log4j=\u0026#34;http://jakarta.apache.org/log4j/\u0026#34;\u0026gt; \u0026lt;!-- 输出日志到控制台 ConsoleAppender --\u0026gt; \u0026lt;appender name=\u0026#34;console\u0026#34; class=\u0026#34;org.apache.log4j.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;Threshold\u0026#34; value=\u0026#34;info\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.TTCCLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;TTCCLayout\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 输出日志到文件 每天一个文件 --\u0026gt; \u0026lt;appender name=\u0026#34;dailyRollingFile\u0026#34; class=\u0026#34;org.apache.log4j.DailyRollingFileAppender\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;Threshold\u0026#34; value=\u0026#34;info\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;ImmediateFlush\u0026#34; value=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;File\u0026#34; value=\u0026#34;c:/logs/dailyRollingFile.log\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;DatePattern\u0026#34; value=\u0026#34;\u0026#39;.\u0026#39;yyyy-MM-dd\u0026#39;.log\u0026#39;\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.PatternLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;[%d{yyyy-MM-dd HH:mm:ss\\} %-5p] [%t] {%c:%L}-%m%n\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 输出日志到文件 文件大小到达指定尺寸的时候产生一个新的文件 --\u0026gt; \u0026lt;appender name=\u0026#34;railyFile\u0026#34; class=\u0026#34;org.apache.log4j.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;File\u0026#34; value=\u0026#34;c:/logs/railyFile.log\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;ImmediateFlush\u0026#34; value=\u0026#34;true\u0026#34;/\u0026gt; \u0026lt;param name=\u0026#34;Threshold\u0026#34; value=\u0026#34;info\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;Append\u0026#34; value=\u0026#34;true\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;MaxFileSize\u0026#34; value=\u0026#34;30KB\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;MaxBackupIndex\u0026#34; value=\u0026#34;100\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.PatternLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;[%d{yyyy-MM-dd HH:mm:ss\\} %-5p] [%t] {%c:%L}-%m%n\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 输出日志到文件 --\u0026gt; \u0026lt;appender name=\u0026#34;file\u0026#34; class=\u0026#34;org.apache.log4j.FileAppender\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;File\u0026#34; value=\u0026#34;c:/logs/file.log\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;param name=\u0026#34;Threshold\u0026#34; value=\u0026#34;info\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;layout class=\u0026#34;org.apache.log4j.PatternLayout\u0026#34;\u0026gt; \u0026lt;param name=\u0026#34;ConversionPattern\u0026#34; value=\u0026#34;[%d{yyyy-MM-dd HH:mm:ss\\} %-5p] [%t] {%c:%L}-%m%n\u0026#34;\u0026gt;\u0026lt;/param\u0026gt; \u0026lt;/layout\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 定义全局的日志输出级别,但是在输出目的地的配置中配置的具体输出级别优先级高于全局定义的优先级。 如果在railyFile中定义\u0026lt;param name=\u0026#34;Threshold\u0026#34; value=\u0026#34;info\u0026#34;\u0026gt;\u0026lt;/param\u0026gt;，那么将会把info以上级别的信息输出 --\u0026gt; \u0026lt;root\u0026gt; \u0026lt;priority value=\u0026#34;debug\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;console\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;dailyRollingFile\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;railyFile\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;file\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/log4j:configuration\u0026gt; Slf4j 使用 # 其maven依赖如下：\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 后台使用log4j日志系统 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-log4j12\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 一般我们是以log4j作为底层的日志系统，代码中使用slf4j来编写。所以下面就直接上程序实例了。\nexample: Hello World\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; public class HelloWorld { public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(HelloWorld.class); logger.info(\u0026#34;Hello World\u0026#34;); } } /* file.log: 0 [main] INFO HelloWorld - Hello World */ 占位符的使用：（该方式减小了频繁字符串拼接的多余开销）\nimport org.slf4j.Logger; import org.slf4j.LoggerFactory; public class Wombat { final Logger logger = LoggerFactory.getLogger(Wombat.class); Integer t; Integer oldT; public void setTemperature(Integer temperature) { oldT = t; t = temperature; logger.debug(\u0026#34;Temperature set to {}. Old temperature was {}.\u0026#34;, t, oldT); if(temperature.intValue() \u0026gt; 50) { logger.info(\u0026#34;Temperature has risen above 50 degrees.\u0026#34;); } } } /* {} 是占位符 */ 从上面可以看出来log有这么几种：info()、debug()、warn()、error()\nSLF4j 结合其他日志系统 # 在前期看的时候，我一直纠结于这个slf4j是如何知道用哪个log来做底层日志系统的。\n在应用中，通过LoggerFactory类的静态getLogger()获取logger。通过查看该类的代码可以看出，最终是通过StaticLoggerBinder.SINGLETON.getLoggerFactory()方法获取LoggerFactory然后，在通过该具体的LoggerFactory来获取logger的。类org.slf4j.impl.StaticLoggerBinder并不在slf4j-api-1.5.2.jar包中. 仔细查看每个与具体日志系统对应的jar包，就会发现，相应的jar包都有一个org.slf4j.impl.StaticLoggerBinder的实现，不同的实现返回与该日志系统对应的LoggerFactory，因此就实现了所谓的静态绑定，达到只要选取不同jar包就能简单灵活配置的目的。\nlogback # 就记录这一个了，因为他传说比log4j更好用。\nMaven dependency\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.slf4j\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;slf4j-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.7.5\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0.13\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 配置logback.xml 大家都是日志系统，所以配置起来也就很像，log4j的配置文件可以直接转换成logback的配置，据说使用某工具，不过这样不保险，也不打算学。\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!--debug=\u0026#34;true\u0026#34; : 打印logback内部状态（默认当logback运行出错时才会打印内部状态 ），配置该属性后打印条件如下（同时满足）： 1、找到配置文件 2、配置文件是一个格式正确的xml文件 也可编程实现打印内部状态，例如： LoggerContext lc = (LoggerContext) LoggerFactory.getILoggerFactory(); StatusPrinter.print(lc); --\u0026gt; \u0026lt;!-- scan=\u0026#34;true\u0026#34; ： 自动扫描该配置文件，若有修改则重新加载该配置文件 --\u0026gt; \u0026lt;!-- scanPeriod=\u0026#34;30 seconds\u0026#34; : 配置自动扫面时间间隔（单位可以是：milliseconds, seconds, minutes or hours，默认为：milliseconds）， 默认为1分钟，scan=\u0026#34;true\u0026#34;时该配置才会生效 --\u0026gt; \u0026lt;configuration debug=\u0026#34;false\u0026#34; scan=\u0026#34;true\u0026#34; scanPeriod=\u0026#34;30 seconds\u0026#34; packagingData=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;!-- 设置 logger context 名称,一旦设置不可改变，默认为default --\u0026gt; \u0026lt;contextName\u0026gt;myAppName\u0026lt;/contextName\u0026gt; \u0026lt;appender name=\u0026#34;STDOUT\u0026#34; class=\u0026#34;ch.qos.logback.core.ConsoleAppender\u0026#34;\u0026gt; \u0026lt;!-- encoders are by default assigned the type ch.qos.logback.classic.encoder.PatternLayoutEncoder --\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;appender name=\u0026#34;FILE\u0026#34; class=\u0026#34;ch.qos.logback.core.rolling.RollingFileAppender\u0026#34;\u0026gt; \u0026lt;!-- 当前活动日志文件名 --\u0026gt; \u0026lt;file\u0026gt;./my_log.log\u0026lt;/file\u0026gt; \u0026lt;!-- 文件滚动策略根据%d{patter}中的“patter”而定，此处为每天产生一个文件 --\u0026gt; \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.TimeBasedRollingPolicy\u0026#34;\u0026gt; \u0026lt;!-- 归档文件名“.zip或.gz结尾”,表示归档文件自动压缩 --\u0026gt; \u0026lt;FileNamePattern\u0026gt;./my_log%d{yyyyMMdd}.log.zip\u0026lt;/FileNamePattern\u0026gt; \u0026lt;maxHistory\u0026gt;30\u0026lt;/maxHistory\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;!--rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.FixedWindowRollingPolicy\u0026#34;\u0026gt; \u0026lt;fileNamePattern\u0026gt;renhai%i.log\u0026lt;/fileNamePattern\u0026gt; \u0026lt;minIndex\u0026gt;1\u0026lt;/minIndex\u0026gt; \u0026lt;maxIndex\u0026gt;10\u0026lt;/maxIndex\u0026gt; \u0026lt;/rollingPolicy\u0026gt; \u0026lt;triggeringPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy\u0026#34;\u0026gt; \u0026lt;maxFileSize\u0026gt;20MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;/triggeringPolicy--\u0026gt; \u0026lt;!-- \u0026lt;rollingPolicy class=\u0026#34;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\u0026#34;\u0026gt; rollover daily \u0026lt;fileNamePattern\u0026gt;mylog-%d{yyyy-MM-dd}.%i.log\u0026lt;/fileNamePattern\u0026gt; each file should be at most 30MB, keep 60 days worth of history, but at most 20GB \u0026lt;maxFileSize\u0026gt;30MB\u0026lt;/maxFileSize\u0026gt; \u0026lt;maxHistory\u0026gt;60\u0026lt;/maxHistory\u0026gt; \u0026lt;totalSizeCap\u0026gt;20GB\u0026lt;/totalSizeCap\u0026gt; \u0026lt;/rollingPolicy\u0026gt; --\u0026gt; \u0026lt;encoder\u0026gt; \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS}[%-5level][%thread]%logger{36} - %msg%n\u0026lt;/pattern\u0026gt; \u0026lt;!-- \u0026lt;pattern\u0026gt;%d{HH:mm:ss.SSS}[%-5level][%thread] - %msg%n\u0026lt;/pattern\u0026gt; --\u0026gt; \u0026lt;/encoder\u0026gt; \u0026lt;/appender\u0026gt; \u0026lt;!-- 日志级别若没显示定义，则继承最近的父logger（该logger需显示定义level,直到rootLogger）的日志级别--\u0026gt; \u0026lt;!-- logger的appender默认具有累加性（默认日志输出到当前logger的appender和所有祖先logger的appender中），可通过配置 “additivity”属性修改默认行为--\u0026gt; \u0026lt;logger name=\u0026#34;com.yinz\u0026#34; level=\u0026#34;debug\u0026#34; additivity=\u0026#34;false\u0026#34; \u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34;/\u0026gt; \u0026lt;/logger\u0026gt; \u0026lt;!-- 至多只能配置一个root --\u0026gt; \u0026lt;root level=\u0026#34;debug\u0026#34;\u0026gt; \u0026lt;appender-ref ref=\u0026#34;STDOUT\u0026#34; /\u0026gt; \u0026lt;appender-ref ref=\u0026#34;FILE\u0026#34; /\u0026gt; \u0026lt;/root\u0026gt; \u0026lt;/configuration\u0026gt; 放在哪 # src/main/resources 日志系统的配置文件都放在这就好了。\n"},{"id":71,"href":"/posts/java/java-4/","title":"java 线程与池","section":"Java","content":"线程与池这两个东西在很多语言中都存在，这是一种编程模式。 池的思维是根本。举个例子，如果某个数据库有一个远程交互的API允许你写代码来远程操作，那么你如果不用池，每条命令都重新发起一个连接，然后要数据库认证身份，然后执行命令。这样的效率不高，你会很当然的想到我要把连接保持住，让多个命令的执行只进行一次身份认证。这个时候就引入池的概念。每次从池中取出对应的连接，执行完命令再放回到池里。 同样的思维在ACM比赛中我们常用内存池的方法来避免频繁申请内存。\n线程作为一种资源，也需要申请，申请也要开销，所以能将申请次数降低就可以提高效率，所以我们搞个池。 线程是一个进程的执行单元。一个进程中可以有若干线程，每个线程都是独立的执行单元。线程的调度比进程调度要快很多，因为线程调度的资源涉及更小。\n那么为什么要多线程？\n先来讲一下并行和并发。 并行：“真正的两个机器同时工作”； 并发：“看上去的同时执行的，实际上在同一个cpu上轮转执行的”； 并发的场景非常多，最基本的就是同时过来两个请求需要做，如果你是单线程的程序，就必须等待前一个完全做完再处理后面一个。如果你是多线程程序，就可以从线程池里取一个线程来处理新的请求，可以保证工作效率。这个地方其实有两个东西，一个是用户体验，一个是异步操作。前一个好理解，后一个讲一下我的理解。 现在很多时候我们都要将处理步骤拆成异步的来做，异步处理的实现方式其中就有多线程。同步就是我前一句代码没有做完，后面的代码后面的步骤就阻塞在那里了。如果我们用异步的方式，开一个新的线程来搞某个步骤。例如写日志和返回执行结果，我们就可以起一个线程去写日志，然后主线程直接返回处理结果，这个处理结果对日志是弱依赖的，日志写的如何并不影响我返回结果的操作，不能因为我日志写失败了我就不把结果返回去，有可能磁盘页被其他程序上锁了，一时半会儿都搞不完，这个时候多线程的优势就显现出来了。\n感觉到这里讲了很多东西，都可以讲的很细的，但是讲的太细看的人都没兴趣了，我自己也不需要写太多。\n如何实现多线程 # 在Java中封装的很好，用起来也很简单。实现多线程有两种方法，一种是继承Thread类，一种是实现Runable 接口。\nThread # class Thread1 extends Thread{ private String name; public Thread1(String name) { this.name=name; } public void run() { for (int i = 0; i \u0026lt; 5; i++) { System.out.println(name + \u0026#34;运行 : \u0026#34; + i); try { sleep((int) Math.random() * 10); } catch (InterruptedException e) { e.printStackTrace(); } } } } public class Main { public static void main(String[] args) { Thread1 mTh1=new Thread1(\u0026#34;A\u0026#34;); Thread1 mTh2=new Thread1(\u0026#34;B\u0026#34;); mTh1.start(); mTh2.start(); } } 这种方法就是继承Thread类并重写run() 方法，在执行这个run的时候并不是直接调用，而是直接调用start() 方法。这里是个跟正常思维不一样的地方，因为涉及到线程的状态问题。因为线程是在进程下面的，所以你新起一个线程需要被进程管控的，新加入一个线程并不能立即被执行，而是要将其状态置成“就绪”状态，进程会将其挂进队列里，进行调度。\nRunable # class Thread2 implements Runnable{ private String name; public Thread2(String name) { this.name=name; } @Override public void run() { for (int i = 0; i \u0026lt; 5; i++) { System.out.println(name + \u0026#34;运行 : \u0026#34; + i); try { Thread.sleep((int) Math.random() * 10); } catch (InterruptedException e) { e.printStackTrace(); } } } } public class Main { public static void main(String[] args) { new Thread(new Thread2(\u0026#34;C\u0026#34;)).start(); new Thread(new Thread2(\u0026#34;D\u0026#34;)).start(); } } 感觉差不多的。调用的时候也是用start。\nThread 与 Runable的区别 # Runable实现的多线程能够在同一个实例上运行，而Thread的不可以。\npublic class Main { public static void main(String[] args) { Thread2 my = new Thread2(); new Thread(my, \u0026#34;C\u0026#34;).start(); new Thread(my, \u0026#34;D\u0026#34;).start(); new Thread(my, \u0026#34;E\u0026#34;).start(); } } 这样的调用，会让三个线程在同一个实例上运行，比如售票系统中，不同的线程是不同的用户，但是减的票数在同一个实例上。\n关于线程还有很多东西，才疏学浅，暂时不深究，因为没用到，在造轮子的时候就会用到了。\n线程池 # 上面只是简单的写写多线程，并没有涉及到池，也就是一种暴力的多线程。 线程池在Java中也是封装好的一个类，也很方便。\n创建线程池 # ThreadPoolExecutor executor = new ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAliveTime, milliseconds,runnableTaskQueue, threadFactory,handler); 参数说明\n- corePoolSize：核心池的大小，这个参数跟后面讲述的线程池的实现原理有非常大的关系。在创建了线程池后，默认情况下，线程池中并没有任何线程，而是等待有任务到来才创建线程去执行任务，除非调用了prestartAllCoreThreads()或者prestartCoreThread()方法，从这2个方法的名字就可以看出，是预创建线程的意思，即在没有任务到来之前就创建corePoolSize个线程或者一个线程。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到缓存队列当中； - maximumPoolSize：线程池最大线程数，这个参数也是一个非常重要的参数，它表示在线程池中最多能创建多少个线程； - keepAliveTime：表示线程没有任务执行时最多保持多久时间会终止。默认情况下，只有当线程池中的线程数大于corePoolSize时，keepAliveTime才会起作用，直到线程池中的线程数不大于corePoolSize，即当线程池中的线程数大于corePoolSize时，如果一个线程空闲的时间达到keepAliveTime，则会终止，直到线程池中的线程数不超过corePoolSize。但是如果调用了allowCoreThreadTimeOut(boolean)方法，在线程池中的线程数不大于corePoolSize时，keepAliveTime参数也会起作用，直到线程池中的线程数为0； 创建完线程池，要向线程池提交程序，跟多线程一样，你的类实现Runable接口，重写run() 函数就可以了。\nexecutor.execute(myTask); // myTask 是你要多线程执行的类的实例 简述了一些这方面的东西。一般我们在开发项目使用的时候都会初始化很多个线程池，不同的业务代码用不同的线程池，用线程的时候最重要的就是线程安全的问题。这个下次遇到再写，没有碰到过就理解不深刻。\n"},{"id":72,"href":"/posts/others/diary/","title":"Latex写工作日志的实践","section":"Others","content":"最近1个月手里同时在日常环境上跑通6个应用，脑内存实在不够用，现实在召唤新的工作模式的诞生。于是有了这篇文章。\n一直在寻找一种方法，能满足我记录各种东西的需求又不要太凌乱，还要不时画一下软件结构图等。我需要一种可以一站解决这个问题的解决方案，但是很遗憾，貌似并没有。所以还是决定自己搞最原始的方案，使用latex直接写工作日志吧。\n工作日志不同于其他笔记，相对比较机密，也不好写在其他地方。也为以后开发日志打个基础。\nLatex的Ubuntu安装 # 除了体积略大以外，并没有什么太大的缺点。latex支持的东西貌似更多，用户也更多。\n顺序执行以下命令：\nsudo apt install texlive-latex-base sudo apt install latex-cjk-all sudo apt install texlive-latex-extra sudo apt install texlive-xetex 四个包加起来不到2G，其中第二个是中文支持包。我使用的方式是用命令行直接编译，用vim写代码。\n在后续的使用过程中，你有可能会遇到有些包没有，这些包都是以xxx.sty 的形式命名的，这个时候这样来安装缺少的包：\nsudo apt search xxx # 查找到对应的包名，因为有的时候软件库中的名字可能不一致，有些前缀什么的。 # 从查出来的列表中选择你要的那个包然后安装就可以了 sudo apt install xxx 缺少包的情况会在编译的时候报错报出来。 还有的时候是因为缺少一些字体，在Ubuntu 上安装字体的方式如下：\n# 下载你的字体包到本地。 # 你可以将自己的字体都放在一起，例如~/.share/fonts/ 文件夹中，没有这个文件夹就自己建。 # 然后将字体放进来，终端进入这个文件夹后执行下面的命令 sudo mkfontscale sudo mkfontdir sudo fc-cache -fv 提醒你success就安装成功了，重新编译就可以了。\n编译Latex # 编译的命令是xelatex filename.tex。编译完成以后可以打开来看效果，我一般直接使用一个makefile文件来完成这一系列操作: 编译、后台打开，清除多余文件 Makefile代码如下：\nall: xelatex T.tex evince T.pdf \u0026amp; clean: rm *.aux *.log 就是这么简单。\n工作日志样式 # 回去加。\n"},{"id":73,"href":"/posts/vim/vim/","title":"VIM 花式进阶","section":"Vim","content":"据说Vim在程序员鄙视链的顶端，呵呵，连编辑器都能用来鄙视别人的程序员肯定是个菜鸡。 但是一个Vim修炼之路真的是挺好玩的，一个编辑器居然能这么炫酷的写代码，这么强的扩展能力，和这么顺畅的操作，站上顶端也不是空有其名的，当然用Vim写代码的工程师的代码能力也不是浪得虚名。\nIDE有IDE的好处，个人喜欢Vim。\n所谓花式，就是没有章法，一点一点积累。\nVim的剪切板-寄存器 # Vim有大概47块剪切板，牛逼坏了。也就是说你可以存N份不同的东西在不同的剪切板中，当要用那个东西的时候直接一键粘出来。这其中有一个误会，就是以前总以为Vim默认不支持系统剪切板，其实系统剪切板是这N块中的一块，只不过不是默认剪切板而已，怎么想都不可能没有系统剪切板的，只是自己不会用。 在Vim中，这些其实并不叫剪切板，而叫寄存器，功能比剪切板大很多。\nVim中有10种寄存器，命令模式下：:help registers 就可以调出帮助文档。至于这10种寄存器具体的区别就不说了，列举一下都有那些寄存器。 寄存器的标志是\u0026quot;开头加寄存器名称。\n默认的无名寄存器\u0026quot;\u0026quot;，就是引号所代表的寄存器 \u0026quot;0-\u0026quot;9号寄存器 \u0026quot;a-\u0026quot;z 或\u0026quot;A-Z\u0026quot; 字母寄存器 \u0026quot;+ 寄存器，就是系统剪切板 其中默认的无名寄存器是我们平时剪切dd和复制yy用的剪切板。 如果我们要把一个东西存到某个寄存器，例如将某两行存在1号寄存器中，在普通模式下： 2\u0026quot;1y 这个命令地一个2是要复制的行数，然后是1号寄存器，然后是y复制。 要粘贴1号寄存器中的内容就在普通模式下： \u0026quot;1p 要想将系统剪切板的内容剪切到vim中就把\u0026quot;1换成\u0026quot;+ 就可以了。\n"},{"id":74,"href":"/posts/acm/acm-vim/","title":"VIM 在ACM/ICPC中的非最佳实践","section":"Acm","content":"5月份在看今年的Final直播，看到了ITMO队的屏幕的时候，看到一些骚操作，感觉自己是拿着冲锋枪当鸟枪使了。\nVim确实十分强大，其强大是有原因的。最主要的原因是他本是依托终端存在的，他与终端有着非常强的联通。终端的强大一定程度上让vim变的很牛逼。不需要插件就可以在内置命令行。\n打比赛两年了，现在也算是个退役狗了，才发现自己并没有好好用vim这个神器，不仅仅是装逼。 第一年的时候简单会用vim来写代码，会简单的配置，会用一点点的快捷键。 第二年的时候会用更多的快捷键，并没有什么本质上的突破，除了会用一点bash脚本来加快测试等。\n本文将以ACM比赛场景作为线索，介绍一下Vim应该怎么用，以及，你为什么不要用IDE。\n比赛开始 # 按照我们队的分工，我在前2分钟负责配置vim环境和代码环境。这里推荐一个简明配置清单：\nvim ~/.vimrc set nu \u0026#34; 行号 set mouse=a \u0026#34; 鼠标可用 set shiftwidth=4 \u0026#34; 与tab宽度相关的 set tabstop=4 \u0026#34; tab宽度 set cindent \u0026#34; c语言风格缩进 set autoindent \u0026#34; 自动缩进 set cul \u0026#34; 高亮当前行 colorscheme desert \u0026#34; 配色，选用你平时用的最好 syntax on \u0026#34; 开启语法高亮 \u0026#34; 以下配置自己酌情 set noswapfile \u0026#34; 不产生交换文件，在意外退出没有保存的情况下刚写的代码就没有了。 \u0026#34; 好处就是不会在打开文件的时候提醒你交换文件，下面会讲怎么处理这种请况。 在配置完vim后，我会写一个头文件和主函数的模板，然后命令行给每一题都复制一份。 模板会写：所有会用到的头文件、主函数、输入格式、输出Case、常用的#define、typedef、const等。\n用一个四行的脚本来复制：\n#!/bin/bash for name in {A..M}; do cp a.cpp $name.cpp done # 我写的模板文件是a.cpp # 脚本名为copy.sh 执行这个脚本有两个选择，一个是命令：bash copy.sh。 还有一个是先给脚本执行权限，然后直接运行脚本：chmod +x copy.sh、./copy.sh。\n至此比赛已经开始2分钟了，一个队友应该已经看完一题了，开始玩吧。\n测样例 # 写完代码就要开始测样例了。并不需要离开vim环境，直接一个命令搞定。 先来写一个脚本，这个脚本也可以在比赛开始就写掉：\n#!/bin/bash g++ $1.cpp -std=gnu++11 \u0026amp;\u0026amp; cat $1.IN | ./a.out 这个脚本极其简单了，我们遵循一个规则来做就好了。 先解释一下脚本内容：脚本可以接受一个参数，按照我们上面的命名方式，这个参数就是题号的大写字母。我们默认编译输出文件为a.out， 你也可以换成对应的字母，这个没有关系。有两个命令，中间用逻辑操作符链接起来，只有在编译通过的时候才执行后面一句。第二句读取命名格式如A.IN的文件，并用管道输出给编译出来的程序。 结果会直接显示在终端，按Enter可以直接回到vim代码中。\n这个脚本和输入文件写完以后，当你要测试的时候，不要退出vim。切换到vim的命令模式，冒号后输入例如A题:!bash case.sh A 然后回车就可以看到输出结果或是编译报错，按Enter键回到代码。\n这个命令只需要手动输入一次，下一次你要测试的时候进入命令模式后，按上键就可以翻出来历史命令，回车就行了。\n这些都是VIM与脚本结合所做的提速工作。下面介绍一些写代码过程中常用的快捷键。\n编写代码 # 比赛环境十分紧张，快捷键这种东西等你想到再用其实也快不了多少，基本上都是条件反射的快捷键才真正起到了快捷的作用，所以平时就要经常用。\n常用 Top N # （下面的快捷键都是在普通模式下）\n在当前行之前插入新行：k + o 或O 在当前行下面插入新行：o 复制当前行：yy，复制当前光标开始的N行：Nyy(N是数字) 剪切当前行：dd，剪切当前光标开始的N行：Ndd(此功能也可用作删除) 粘贴刚刚复制或剪贴的内容到光标处：p 回退刚刚做的修改：u，注意这个不能反回退，也就是用此方式回退的步骤不能再被回退。 全选：ggVG 所有代码自动对齐：ggVG + = 交换文件 # 有的时候队友不小心强行关闭了其他队友没保存的终端，就会产生交换文件。当你再打开这个文件的时候就会提醒你要不要恢复之类的。这个时候你就先选Q退回到命令行，然后使用命令：vim -r filename 来将交换文件中没有保存的内容保存进原文件中。然后你需要删除这个交换文件，否则下次打开还提醒你。\n删除交换文件很简单，首先终端命令查看隐藏文件 ls -a 这个时候你会看到你文件对应的.filename.cpp.swp文件，然后命令 rm .filename.cpp.swp 就删除了，你也可以批量删除所有的交换文件：rm .*.sw*，因为如果你反复产生交换文件，交换文件也不互相覆盖，而是改个后缀变成.swo、.swn等。\n结语 # 上面的那些技巧都没有什么卵用，该做不出来还是做不出来。 这些东西都是些锦上添花的技巧，我个人觉得最大的好处就是在代码出问题的时候测试调试比较快，心情会稍微好受点。一个命令出结果可以保持代码在脑子里的连惯性，快速定位问题。有的时候写代码只要10分钟，找bug可能要半小时。 归根结底，还是要能做出来。当你的能力能做出9道题的时候，这些可以一定程度上保证你能做完9道题。\n"},{"id":75,"href":"/posts/java/iterator/","title":"iterator 迭代器","section":"Java","content":"迭代器是一种对数据结构数据进行遍历的模式，也成为游标(Cursor)模式。这种模式为了适应各种被封装了的复杂数据结构的完全顺序遍历而设计。其设计思想依旧是封装的思想，屏蔽各种数据结构底层的存储差异，使用统一的方法来遍历所有的数据。\nC++ # 先以C++中的迭代器的使用来说一下。举两个常用的容器的例子。\nvector # 遍历、删除元素 # vector\u0026lt;int\u0026gt;::iterator it; for( it = A.begin(); it!=A.end(); it++){ cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; if(*it == 3){ A.erase(it); } } /* 上面这种写法是有问题的，当你删掉3这元素的时候，it再++，直接就到了5了，4就跳过去了。 因为erase后，后面的元素都会前移。 从这里我们可以看到，vector中的迭代器应该就是指针。 正确的写法如下： */ vector\u0026lt;int\u0026gt;::iterator it; for( it = A.begin(); it!=A.end(); it++){ cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; if(*it == 3){ vector\u0026lt;int\u0026gt;::iterator it_tmp = it; it--; A.erase(it_tmp); } } set # set\u0026lt;int\u0026gt;::iterator it; for(it = S.begin(); it!=S.end(); it++){ cout \u0026lt;\u0026lt; *it \u0026lt;\u0026lt; endl; if(*it == 3){ set\u0026lt;int\u0026gt;::iterator it_tmp=it; it--; S.erase(it_tmp); } } 复杂的部分，暂时我也用不到。很尴尬，说明写的东西比较简单吧。以我目前的认知，写一些封装的数据结构的时候会使用迭代器比较多，我不写那些东西，就基本上不怎么用迭代器，何况我还是C/C++混合型的程序员。\n下面介绍个不常用的语法，其实现是基于迭代器的。\nfor # // 接上面的set部分 for(int item : S){ cout \u0026lt;\u0026lt; item \u0026lt;\u0026lt; endl; } 这个遍历起来代码就少很多了。编译的时候用选项参数-std=gnu++11 或-std=c++11\nJava # java中有一个Iterator接口类，所有提供迭代器的类需要实现这个接口。这个接口定义了一个迭代器所具有的功能。我觉得这里我们可以很好的理解接口的意义，就是给出定义。\n定义如下：\npackage java.util; public interface Iterator\u0026lt;E\u0026gt; { boolean hasNext(); E next(); void remove(); } 三个函数十分好理解。常用的用法如下：\nwhile(it.hasNext()){ System.out.println(it.next()); } 还有一个接口Iterable。这个接口更加简单，只有一个函数，产生一个迭代器并返回这个迭代器。对于提供迭代遍历的类，必须实现的接口。\n迭代器的使用：\nList list=new ArrayList(); Map map=new HashMap(); for(int i=0;i\u0026lt;10;i++){ list.add(new String(\u0026#34;list\u0026#34;+i) ); map.put(i, new String(\u0026#34;map\u0026#34;+i)); } Iterator iterList= list.iterator(); //List接口实现了Iterable接口 while(iterList.hasNext()){ String strList=(String)iterList.next(); System.out.println(strList.toString()); } Iterator iterMap=map.entrySet().iterator(); while(iterMap.hasNext()){ Map.Entry strMap=(Map.Entry)iterMap.next(); System.out.println(strMap.getValue()); } for each 语法 # 在JAVA1.5后添加了一个循环结构，语法与C++的一样。\nfor(String str:list){ System.out.println(str); } 不是很深入，但是应该算有用。从我找资料的过程中就可以看出Java的生态圈要比C++大不少，而且Java体系的思维也会简单一些。很多文章都是Java的内容，C++就比较少，而且C++很多只是介绍怎么用像我这样。深入到STL源码来解释怎么写迭代器的不多。\n"},{"id":76,"href":"/posts/web/chrome/","title":"chrome 控制台","section":"Web","content":"chrome是一个非常好用的Web开发的工具，而不仅仅是个好用的浏览器。 按下就可以调出控制台，控制台可以与页面分离成为一个单独的窗口。这个在调试大屏效果的时候很方便，但是我不是搞前端设计的，所以不管这个。\n这里可以看到有很多选项，常用的有以下几个：Elements、Console、Sources、Network。\nElements 审查元素 # 这里可以看到你的HTML源码，和对应的css。在前端工程师的工作中经常会用到，不过现在自动化的工具越来越多了，也不一定非用这个了，但是这个一定是很强大的功能。 在这个框的最左上角有一个鼠标箭头的标志，点一下就可以到页面上定位某个元素的代码，很好用。 这一块没有什么技术含量\nConsole 控制台 # 这是一个命令交互的控制台，语言是Javascript。下面就介绍一下常用的几个命令。\nconsole.log() # 这是一组四个命令分别是：console.log()、console.info()、console.error()、console.warn()。其作用就是在控制台中打印信息，在编写前端工程的时候可以这样在js代码中打印log信息来排查问题。\n$.cookieStorage.set(\u0026lsquo;id\u0026rsquo;, 1234) # 这是一个cookie操作函数。可以对应的设置cookie的参数值，如上，如果某个网站的用户登录验证使用cookie来做的，你又猜到了其参数的名字，就直接设置cookie就可以登录上去了，免密码呢。\nSources # 这个在调试的时候可以看到自己的页面的每个资源的加载情况，包括时间、来源、是否加载成功等，也可以把资源down下来。\nNetWork # 这个我感觉是最好用的一个，他会记录你的异步请求。可以记录请求的地址，参数，返回值等等。\nAnything more?\nNothing more\u0026hellip;\n"},{"id":77,"href":"/posts/acm/acm-contest-1/","title":"比赛题解-2017苏大暑假集训个人赛(13)","section":"Acm","content":"比赛现场传送门。此次比赛共8道题目如下：\nA. HDU 5777 签到题 B. Poj 3581 后缀数组 + 细节处理 C. Poj 2228 DP+循环情况处理 D. Poj 2155 二维树状数组/二维线段树(区域修改，单点查询) E. UVA 11853 DFS乱搞 F. HDU 4609 FFT基础题 G. HDU 5676 DFS + 二分 H. Poj 2728 最优比例生成树(0-1分数规划)/二分 题目整体偏难，除签到题外应该都是银牌及以上题目，基本上要掌握到这个程度才算可以。\nA. HDU 5777 签到题 # 某一场BestCoder的B题，很简单的思维小题目。\n#include\u0026lt;iostream\u0026gt; #include\u0026lt;cstdio\u0026gt; #include\u0026lt;cstring\u0026gt; #include\u0026lt;algorithm\u0026gt; using namespace std; typedef long long ll; int n,k; int a[100006]; ll sum=0; bool cmp(int a,int b) { return a\u0026gt;b; } int main() { int T; scanf(\u0026#34;%d\u0026#34;, \u0026amp;T); while(T--) { scanf(\u0026#34;%d%d\u0026#34;, \u0026amp;n,\u0026amp;k); for(int i=0;i\u0026lt;n-1;i++) scanf(\u0026#34;%d\u0026#34;, \u0026amp;a[i]); sort(a,a+n-1,cmp); sum=n; for(int i=k-1;i\u0026lt;n-1;i++) sum+=a[i]; printf(\u0026#34;%lld\\n\u0026#34;,sum); } return 0; } B. Poj 3581 后缀数组 + 细节处理 # 题意： # 给一个序列，让你分成三段，段内反转一下，然后使得新拼接成的序列字典序最小，字典序的意思就是你懂得。题目保证第一个数字最大。\n分析： # 思路很直白，分三段就是找两个切分点。开始到第一个切分点的部分就是第一段，要整体字典序最小，这个第一段一定要足够小。由于第一段是由原串第一段反转过来得到的，所以就可以将原来的串先直接整体反转一下，这样问题就转化成了我们要找个字典序最小的后缀，所以后缀数组搞一下。至于这么贪心是对的，下一段说明。 那么对于第二个切分点，就不能直接这么来了。因为第一段的贪心思路我们是可以证明的，至少你提不出反例，对于贪心算法的证明，提不出反例就默认是对的。为什么第一个贪心是对的，因为题目有一个条件保证了，就是第一个数是最大的。保证了什么情况呢？就是这个样例：4 2 2 1 1 10，最小的后缀是1 1 10, 而不是1 10。你匹配到的最小后缀一定是最长的那个。同样这个样例，对于第二个切分点来说就不是这样了，没有一个大头来保证后缀第一的是最长的串，直接搞就会得到2这一个元素，显然不是最优解。 这个时候我们还有一个可以作为思维出发点的东西，就是剩余的这两个串的位置关系。对于abcd来说(原串反转过后去掉第一段后的剩余部分)，如果我们将其分成两段，其在结果串中真正的顺序应该是cdab，这个点抓住了就很直观了，我们先将原串复制一遍，搞成：abcdabcd, 然后求一个字典序最小的后缀就是我们要的了，一样后缀数组搞一下。 注意后缀中长度小于原串长的都过滤掉，因为我要的是cdab这个串，起点要一定在前一段中，所以后缀长度要大于原串长度。还有就是要一定分三份，所以最长的后缀一定不能做为结果。\n代码暂时不在手边，回头补。 C. Poj 2228 DP+循环情况处理 # 题意： # 就是给N个数，选B个，问和最大是多少。 限制：N个数围成环，每个数的值被计算当其前面一个数被选择的时候，也就说一段连续的数中第一个是不算的。\n分析： # 先来看线性问题，就是不成环的问题。很简单，定义Dp[i][j]为：前i个数选择了j个数且第i个数必选的最优解。 Dp[i][j] = max( Dp[i-1][j-1]+a[i], max(Dp[k][j-1]) ), k\u0026lt;i-1\n对于环的情况Dp转移不变，但是要特殊处理一下。环的处理就那么两种，第一种是搞成直的，还有就是讨论一下。这里显然只要讨论一下就可以，因为无非就是跨天和不跨天的区别，也就是最后一个取的时候地一个取不取的问题。 所以搞两次就好了。\n有两个优化，一个是循环清0,还有就是记录前面的Max。\n#include\u0026lt;iostream\u0026gt; #include\u0026lt;cstdio\u0026gt; #include\u0026lt;cstring\u0026gt; #include\u0026lt;algorithm\u0026gt; using namespace std; const int MAX_N = 4000; int Dp[MAX_N][MAX_N], v[MAX_N]; int main() { int N, B; while( scanf( \u0026#34;%d %d\u0026#34;, \u0026amp;N, \u0026amp;B) != EOF ){ for(int i = 1; i \u0026lt;= N; i ++ ) scanf(\u0026#34;%d\u0026#34;, \u0026amp;v[i]); for(int i = 0; i \u0026lt;= N; i ++) for(int j = 0; j \u0026lt;= B; j++ ) Dp[i][j] = 0; int Max = 0; for(int j = 2; j \u0026lt;= B ; j ++ ){ Max = 0; for(int i = j; i \u0026lt;= N ; i ++){ Dp[i][j] = max( Max, Dp[i-1][j-1] + v[i] ); Max = max( Max, Dp[i-1][j-1] ); } } int ans = 0; for( int i = B; i \u0026lt;= N; i ++ ) ans = max( ans, Dp[i][B] ); for(int i = 0; i \u0026lt;= N; i ++) for(int j = 0; j \u0026lt;= B; j++ ) Dp[i][j] = 0; Dp[2][2] = v[2]; for( int j = 3; j \u0026lt;= B ; j++ ){ Max = 0 ; for( int i = j; i \u0026lt;= N ; i ++ ){ Dp[i][j] = max( Max, Dp[i-1][j-1] + v[i] ); Max = max( Max, Dp[i-1][j-1] ); } } if( B \u0026gt; 2 ) ans = max( ans, Dp[N][B] + v[1] ); printf(\u0026#34;%d\\n\u0026#34;, ans); } return 0; } D. Poj 2155 二维树状数组/二维线段树(区域修改，单点查询) # 会二维的都能秒出。不会的也是可以推出来的，只有一点点的难度，距离真正的二维操作差得还远，如果有时间建议学习一下二维树状数组的区间改值与区间加值区间求和等操作。 手边没有，暂时不送了。\nE. UVA 11853 DFS乱搞 # 题意很简单，一个1000×1000的方格上有一些圆，不能从圆范围经过，问是否有从左到右的一条路。这是大连2016的热身赛最后一题。\n先判断有没有，这个从上边界往下DFS能到下边界的就说明没有路。 每次DFS的时候都记录与左边和右边的交点，在dfs过程中更新答案。 代码回头再补。 F. HDU 4609 FFT基础题 # 给n个线段，求取三个组成三角形的概率，就是组成三角形的个数。 离散化+fft。FFT入门题。\nG. HDU 5676 DFS + 二分 # 这一题就是打个表，然后二分答案就可以了。打表就DFS。最大的那个数会爆，特判一下。\nH. Poj 2728 最优比例生成树(0-1分数规划)/二分 # 这一题二分答案去判断是可以过的。正解是0-1分数规划，不过这个不是我出这一题的本意，本意就是想让你们二分做掉。\n总结 # 题目很看功力，结果跟预料的差不多。 比赛不重要，但是希望你们能掌握上面的东西。 有的时候就是到了赛场上，发现题目很熟悉，但就是跟你的能力隔了一点点的小沟，如果当时学这个东西能学的深一点，这题就过了。这就是我出这场题目的意思。 上班写的，比较粗糙，晚上再补补。\n"},{"id":78,"href":"/posts/redis/redis/","title":"redis","section":"Redis","content":"redis 是一个高速的高级的键值对存储系统。开源的，高可用，高效。 其将数据完全保存在内存中，磁盘只做持久化。并且支持多种数据结构：list、set、hashtable等，使用方便。 使用的场景主要有:\n如排行榜、计数器缓冲、数据统计（如TopN，交集，并集等）、最新项目检索、地理位置存储及range查询 实时统计和过期处理，如用户投票及排序；复杂的数据结构缓存及内存数据库 缓存，消息队列(Redis本地支持发布/订阅)，应用程序中的任何短期数据，例如，web应用程序中的会话，网页命中计数等。 由于其属于内存数据库，所以成本比较大，冈起来比较爽一点。\nInstall on Ubuntu # sudo apt-get install redis-server Startup # redis-server Work on it # redis-cli # 出现命令提示符即正常工作 支持的数据结构 # 正时因为支持这些数据结构才易用。\n字符串 # Redis中的字符串是一个字节序列。Redis中的字符串是二进制安全的，这意味着它们的长度不由任何特殊的终止字符决定。因此，可以在一个字符串中存储高达512兆字节的任何内容。\nset name `Paladnix` # 存入key-value get name # 获取key对应的value Hash散列 # Redis散列/哈希(Hashes)是键值对的集合。Redis散列/哈希是字符串字段和字符串值之间的映射。因此，它们用于表示对象。\nHMSET key uname \u0026#34;Paladnix\u0026#34; password \u0026#34;123\u0026#34; level 0 # key 对应一个对象 列表List # Redis列表只是字符串列表，按插入顺序排序。可以向Redis列表的头部或尾部添加元素。\nlpush alist redis # 插入字符串 lpush alist Paladnix # 插入字符串 lrange alist 0 10 # 获取字符串 集合Set # Redis集合是字符串的无序集合。在Redis中，可以添加，删除和测试成员存在的时间O(1)复杂性。\nsadd yiibailist redis # 添加字符串 smembers yiibailist # 输出结果 可排序集合 # Redis可排序集合类似于Redis集合，是不重复的字符集合。 不同之处在于，排序集合的每个成员都与分数相关联，这个分数用于按最小分数到最大分数来排序的排序集合。虽然成员是唯一的，但分数值可以重复。\nzadd yiibaiset 0 redis ZRANGEBYSCORE yiibaiset 0 1000 # 输出结果 命令 # 其实redis的使用跟数据库差不多。 具体的数据操作命令其实非常的简单就不一一介绍了，我自己也用的不熟。那些命令都能很容易获得，介绍一点好玩的命令就好了。\n远程链接 # 示例显示如何连接到Redis远程服务器，在主机(host)127.0.0.1，端口(port)6379上运行，并使用密码为 mypass\nredis-cli -h 127.0.0.1 -p 6379 -a \u0026#34;mypass\u0026#34; 发送订阅 # Redis发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。 Redis 发布订阅(pub/sub)实现了消息系统，发送者(在redis术语中称为发布者)在接收者(订阅者)接收消息时发送消息。传送消息的链路称为信道。\n在Redis中，客户端可以订阅任意数量的信道。\nSUBSCRIBE redisChat # 订阅名为\u0026#34;redisChat\u0026#34;的信道。 PUBLISH redisChat \u0026#34;Redis is a great caching technique\u0026#34; 程序连接Redis # 跟使用数据库一样，不过不一样的是这个比较统一和简单。\njava # /* Java 连接Redis. 字符串操作。 */ import redis.clients.jedis.Jedis; public class RedisStringJava { public static void main(String[] args) { //Connecting to Redis server on localhost Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); System.out.println(\u0026#34;Connection to server sucessfully\u0026#34;); //set the data in redis string jedis.set(\u0026#34;tutorial-name\u0026#34;, \u0026#34;Redis tutorial\u0026#34;); // Get the stored data and print it System.out.println(\u0026#34;Stored string in redis:: \u0026#34;+ jedis.get(\u0026#34;tutorialname\u0026#34;)); } } /* Java Redis List 操作 */ import redis.clients.jedis.Jedis; public class RedisListJava { public static void main(String[] args) { //Connecting to Redis server on localhost Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); System.out.println(\u0026#34;Connection to server sucessfully\u0026#34;); //store data in redis list jedis.lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Redis\u0026#34;); jedis.lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Mongodb\u0026#34;); jedis.lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Mysql\u0026#34;); // Get the stored data and print it List\u0026lt;String\u0026gt; list = jedis.lrange(\u0026#34;tutorial-list\u0026#34;, 0 ,5); for(int i = 0; i\u0026lt;list.size(); i++) { System.out.println(\u0026#34;Stored string in redis:: \u0026#34;+list.get(i)); } } } /* Java Redis Key 操作 */ import redis.clients.jedis.Jedis; public class RedisKeyJava { public static void main(String[] args) { //Connecting to Redis server on localhost Jedis jedis = new Jedis(\u0026#34;localhost\u0026#34;); System.out.println(\u0026#34;Connection to server sucessfully\u0026#34;); //store data in redis list // Get the stored data and print it List\u0026lt;String\u0026gt; list = jedis.keys(\u0026#34;*\u0026#34;); for(int i = 0; i\u0026lt;list.size(); i++) { System.out.println(\u0026#34;List of stored keys:: \u0026#34;+list.get(i)); } } } PHP-Redis on Ubuntu # 下载phpredis项目代码并安装。\ncd phpredis sudo phpize sudo ./configure sudo make sudo make install 现在，将“modules”文件夹的内容复制并粘贴到PHP扩展目录中，并在php.ini中添加以下行extension = redis.so。\n// Connect \u0026amp; String \u0026lt;?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-\u0026gt;connect(\u0026#39;127.0.0.1\u0026#39;, 6379); echo \u0026#34;Connection to server sucessfully\u0026#34;; //set the data in redis string $redis-\u0026gt;set(\u0026#34;tutorial-name\u0026#34;, \u0026#34;Redis tutorial\u0026#34;); // Get the stored data and print it echo \u0026#34;Stored string in redis:: \u0026#34; .$redis→get(\u0026#34;tutorial-name\u0026#34;); ?\u0026gt; // List 操作 \u0026lt;?php //Connecting to Redis server on localhost $redis = new Redis(); $redis-\u0026gt;connect(\u0026#39;127.0.0.1\u0026#39;, 6379); echo \u0026#34;Connection to server sucessfully\u0026#34;; //store data in redis list $redis-\u0026gt;lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Redis\u0026#34;); $redis-\u0026gt;lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Mongodb\u0026#34;); $redis-\u0026gt;lpush(\u0026#34;tutorial-list\u0026#34;, \u0026#34;Mysql\u0026#34;); // Get the stored data and print it $arList = $redis-\u0026gt;lrange(\u0026#34;tutorial-list\u0026#34;, 0 ,5); echo \u0026#34;Stored string in redis:: \u0026#34;; print_r($arList); ?\u0026gt; "},{"id":79,"href":"/posts/java/java-exception/","title":"Java Exception \u0026 Error","section":"Java","content":"你没有看错，这篇文章的tags中有人生。又一次开始思考人生，总有Bug想害朕。\n今天碰到了一个，算是一个BUG，跑出来是个ERROR，抛出了个Exception。讲道理，这些都是正常的，但是很不讲道理，这个错误报的我望而却步，这个异常更是一头雾水。Just A Fuck For You.\n当我拿到这个集群巡检程序的时候，我认为应该是很简单的部署上服务器就可以了，因为这是一个已经在线上运行的包，我只要改改参数在日常环境跑起来就可以了。然而，真正的魔术开始了。日常环境与线上环境居然差异很大，包括巡检的目标集群、结果数据库机器等都要改。这个还算好，虽然我不知道，但是有师兄在搞搞还是比较简单的，然后就上线，运行。\n第一个问题就是找不到主类。我懵逼，居然连启动都起不起来。好在还有进一步的报错信息，原来是找不到log的包。但是我在本地可以启动，我一直以为打jar包的时候会打依赖进去，结果是并不会打依赖包。这个是学艺不精，经验不足。于是把本地所有依赖包怼进服务器。这次顺利的启动起来了。\n然后就开始报错，几乎所有集群都拒绝访问。这尼玛就很尴尬了，我对整个项目一无所知啊。那就去问一下呗： “师兄，这个巡检被拒绝访问了，所有集群都访问不到。” \u0026ndash;“有点忙，你自己先看看。” “我看不懂啊，先给我讲讲这个整体逻辑啊” \u0026ndash;“没空” \u0026hellip;\n然后就开始了一下午的生不如死。哼，回家睡觉！不干了！ 第二天来到，我决定再深入看一下代码，应该能从代码中找到问题。作为ACM选手，从来就没有机器DEBUG的习惯，眼爆bug在C++100多行的代码里还是很快的，但是在Java里就有点懵逼了。Java的代码你说长，其实也不长。但就是会让你抓狂，自己看自己写的Java项目那是怎么看怎么喜欢。去看看其他人的Java项目，呵呵。写一个大工程当然就是要功能块分拆，功能隔离，减少代码内耦合，利于修改调整，兼具灵活性与健壮性。所以Java代码的特点就是不断的继承，类间调用，流程拆分……有的时候一个很简单的功能可能要涉及7、8个类和接口，所以看代码，就要有个够大的脑内栈空间。但是，就算难看，也不机器DEBUG，手动DEBUG的基本功还是有的。\n但凡报错靠谱点，都没有那么难，痛苦就在于，他报的错误与真正引起错误的地方相差太远，异常却又报的模模糊糊。首先是拒绝连接错误，现在代码里找到所有要访问的集群IP，打出来。然后找师兄去确认，集群是否在用，就这一个工作就前前后后搞了两个多小时，都在忙的不亦乐乎。集群有问题就好办多了，因为这锅就可以甩出去啦，偏偏机器没有问题。既然机器本身没有问题，那就只有代码的问题了。\n坑就坑在这次抛出的异常居然没有抛出一场的地点信息。或者说异常信息说明的地点距离异常真正发生的位置也有一段距离。主异常是有连接器客户端抛出的，抛出信息就是链接失败啦。然而依靠其抛出的异常栈只能找到发出链接请求的这个类，再往下就没有栈内信息了。然后就去看调用的函数，结果一进去发现这个类没有抛出异常，而是自己处理掉了。这本应该是非常值得表扬的，因为捕获了异常意味着这个异常是可以被预料并处理的，所以优秀的程序员都会在能处理的情况下都处理掉，如果是一些不好处理的，或需要根据使用者的需求来处理就继续向上抛，抛给函数使用者去处理。很多初级的Java程序员最常见的做法就是捕获这个异常，然后打印出来，交给运维去发现异常再回来改代码。我手里的这个类并没有抛出异常，而是把一场catch下来自己处理掉了。但是他只处理了其中的IO异常，还有一个可抛出异常也被他catch下来了，并且仅仅是打印到了log里，所以我就只能从日志中追踪到这里了。然而由于没有抛出，所以也就没有信息表明这个一场出现在上面的哪个位置，只能手动二分位置查错了。这个的原理很简单，就是发生异常位置以后的代码都不会被执行，所以只要在其中夹杂一些输出语句，就可以定位到出错的那句了。接下来定位到一个新的类中，至于这个类是干什么的我也不清楚，但是可以找bug。而这个函数就完全没有抛出异常也没有捕获异常，所以这个就要对函数里所有代码都做二分定位，而不是像刚才一样只定位try代码块中的代码就可以了。几个过大概5轮定位，又定位到了一个新的类里，通过对新的这个类的定位，可以基本确定异常就来源于这个函数中的某一句。异常信息中有一个是数字格式错误，通过上面的分析，我也基本上确定在这里发生的就是这个格式错误的异常，由于函数参数中只有一个double的参数，就重点找他的问题。先输出了他的值，发现没有问题。然后发现代码中他与另外一个变量做了比较，而定位异常位置也就发生在这个比较代码块中，参与比较的另外一个是从配置文件中提取的数据。经过往回找这个配置文件的参数选项，发现问题竟然是因为拼写错误导致找不到这个配置选项，所以这条语句的值变成了if( double \u0026gt; null ) 然后就有了这个数字格式错误的异常了。\n草泥马我的心好累。代码中写的是max_master_clients，然而配置文件中是master_max_clients，真不知道线上的那个代码是怎么跑的，害怕。\n异常 Exception # 通过上面的故事，你应该已经了解了Exception的一些特性了。下面具体的介绍一下，以及正确用法！\n"},{"id":80,"href":"/posts/web/tomcat/","title":"tomcat","section":"Web","content":" 日志 # Tomcat的日志系统还算很完善的。来看一下，当你的应用出现问题的时候要去哪里找原因吧。\napache-tomcat/logs/ |_ catalina.2017-07-12.log |_ catalina.out |_ host-manager.2017-07-12.log |_ localhost.2017-07-12.log |_ localhost_access_log.2017-07-12.txt |_ manager.2017-07-10.log |_ 对应的App应用的log文件夹，取决与你项目用的日志工具。 catalina.out 这里的数据都是代码输出到标准输出流的重定向，所以你的SOUT都在这里。 localhost.DATE.log 是你的应用抛出的错误，如页面运行错误，servlet错误等，常用查错工具。 其实目前我也就用过以上两种日志，可能用法还是不太对，入门的时候查日志感觉日志乱的要死。其实这个也不影响使用就是很影响心情，找错误一般可以直接搜索字符串定位就好了。但是我自己感觉还是要在项目开发之前就做好日志的规划工作，什么时候要打log什么时候不打，log的格式是怎样的。心情必须照顾！\ntomcat 安装到发布应用 # 这一部分非常简单。\n安装 # 下载tomcat-core代码包,并解压。 到其bin/目录下，linux执行./startup.sh, windows执行startup.bat脚本。 前提是需要配置JDK到环境变量。 打开http://IP:8080 查看效果。 发布应用 # 将你的应用编译打包成一个war包，然后copy到其webapps文件夹下，通过http://IP:8080/NameOfWar访问。 如何开发Java Web？你需要了解：servlet、SpringMVC、maven、javaBean等。\ntomcat 源码梳理 # 打算看一下源码是怎么玩的，也有可能看不下去，坑先挖上\u0026hellip;\n"},{"id":81,"href":"/posts/linux/curl/","title":"curl","section":"Linux","content":"linux下面自带的一个命令行工具，很常用，关键是很强大。\nsupports # DICT, FILE, FTP, FTPS, Gopher, HTTP, HTTPS, IMAP, IMAPS, LDAP, LDAPS, POP3, POP3S, RTMP, RTSP, SCP, SFTP, SMB, SMBS, SMTP, SMTPS, Telnet and TFTP.\nsupports SSL certificates, HTTP POST, HTTP PUT, FTP uploading, HTTP form based upload, proxies, HTTP/2, cookies, user+password authentication (Basic, Plain, Digest, CRAM-MD5, NTLM, Negotiate and Kerberos)\nfile transfer resume, proxy tunneling and more.\n基本上无所不能了。。。 这里是cURL的PDF版本说明文档，不是很难看懂，里面介绍了这个项目的起源发展、网络协议、如何使用等等。作者还有个很帅的名字：丹尼尔·斯坦伯格。\n作者写了这样一段话：\nRunning curl from the command line was natural and Daniel never considered anything else than that it would output data on stdout, to the terminal, by default. The \u0026quot;everything is a pipe\u0026quot; mantra of standard Unix philosophy was something Daniel believed in. curl is like 'cat' or one of the other Unix tools; it sends data to stdout to make it easy to chain together with other tools to do what you want. That's also why virtually all curl options that allow reading from a file or writing to a file, also have the ability to select doing it to stdout or from stdin. 这是我喜欢Linux的其中一个原因，称之为优雅。\n使用curl来测试http的接口十分方便，下面简单的介绍下如何发起get和post请求。\nGET Request # $ curl -v \u0026#34;http://www.baidu.com\u0026#34; # 显示get请求全过程解析 $ curl \u0026#34;http://www.baidu.com\u0026#34; # 如果这里的URL指向的是一个文件或者一幅图都可以直接下载到本地 $ curl -i \u0026#34;http://www.baidu.com\u0026#34; # 显示全部信息 $ curl -l \u0026#34;http://www.baidu.com\u0026#34; # 只显示头部信息 $ curl \u0026#34;http://www.baidu.com?param=xx\u0026amp;id=xx\u0026#34; POST Request # $ curl -d \u0026#34;param1=value1\u0026amp;param2=value2\u0026#34; \u0026#34;http://www.baidu.com\u0026#34; # general form $ curl -l -H \u0026#34;Content-type: application/json\u0026#34; -X POST -d \u0026#39;{\u0026#34;phone\u0026#34;:\u0026#34;13521389587\u0026#34;,\u0026#34;password\u0026#34;:\u0026#34;test\u0026#34;}\u0026#39; http://domain/apis/users.json # json form "},{"id":82,"href":"/posts/web/http/","title":"你所不知道的http协议之优秀","section":"Web","content":" 协议 # 协议就是数据格式+确认策略。 你所需要知道的就是协议是如何分类的，一般我们按照其工作的层次来分类，分成：通信层协议、应用层协议、物理层协议等七个层次的协议。整个计算机网络体系是由这么多层次组成，但是发展到今天我们主要关心的其实就是两个层次上的协议：通信层、应用层。TCP/IP协议属于通信层，Http属于应用层，也有人认为http属于通信层。关于http属于什么层次，可以是两个架构之间的区别，一种就是RESTful模式的，也是我们常用的；还有一种就是SOA（面向服务的体系结构)他是将http当作通信层协议来使用的。这个关于什么是RESTful和SOA就可以写一篇，这里你只需要知道现在正在向RESTful模式迁移就可以了。\n(成熟的架构大局观+敏锐的技术嗅觉，这是一个CTO必备的能力。)\nhttp协议 # http协议（超文本传输协议）是现代计算机网络最最重要的组成部分。其协议简洁、高效、灵活、强大，也是计算机应用下一步进化的方向。\n除了上面讲的几个你体会不到的特点以外，下面几个特点你要清楚：\n无连接： 不需要保持连接，一个请求干一件事，干完就过。 无状态： 换句话说就是没有记忆，这一点有利有弊。 内容 # http1.1的RFC文档在此，有兴趣的可以去看看。内容比你想的多得多，比我知道的也多得多。本文就简单的介绍一下http报文结构啊什么的，那些网上到处都是，没必要说太多。\nRequest # 由于是应用层，所以我们就只关心数据而不关心其他的东西。 报文结构如下：\nGET /562f25980001b1b106000338.jpg HTTP/1.1 Host img.mukewang.com User-Agent Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.106 Safari/537.36 Accept image/webp,image/*,*/*;q=0.8 Referer http://www.imooc.com/ Accept-Encoding gzip, deflate, sdch Accept-Language zh-CN,zh;q=0.8 xxx 报文由四个部分组成，请求行、请求头、空行、请求数据。\n第一行是请求行，包含三个数据，空格分隔：请求方法、请求资源(URL)、协议版本。 下面紧跟的是请求头，是n个键值对，空格分隔，包含其他的数据：请求的目的地、什么浏览器、该请求接受什么返回格式、什么编码\u0026hellip; 空一行 请求数据。 Response # 返回报文一样四部分：状态行、消息报头、空行和响应正文。\nHTTP/1.1 200 OK Date: Fri, 22 May 2009 06:07:21 GMT Content-Type: text/html; charset=UTF-8 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt;\u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!--body goes here--\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 状态行：协议版本、状态码、状态消息 消息报头： Date:生成响应的日期和时间； Content-Type:指定了MIME类型的HTML(text/html),编码类型是UTF-8 空行 正文 状态码 # 1xx：指示信息\u0026ndash;表示请求已接收，继续处理 2xx：成功\u0026ndash;表示请求已被成功接收、理解、接受 3xx：重定向\u0026ndash;要完成请求必须进行更进一步的操作 4xx：客户端错误\u0026ndash;请求有语法错误或请求无法实现 5xx：服务器端错误\u0026ndash;服务器未能实现合法的请求 常用的：\n200 OK //客户端请求成功 400 Bad Request //客户端请求有语法错误，不能被服务器所理解 401 Unauthorized //请求未经授权，这个状态代码必须和WWW-Authenticate报头域一起使用 403 Forbidden //服务器收到请求，但是拒绝提供服务 404 Not Found //请求资源不存在，eg：输入了错误的URL 500 Internal Server Error //服务器发生不可预期的错误 503 Server Unavailable //服务器当前不能处理客户端的请求，一段时间后可能恢复正常 请求方法 # GET 请求获取Request-URI所标识的资源 POST 在Request-URI所标识的资源后附加新的数据 HEAD 请求获取由Request-URI所标识的资源的响应消息报头 PUT 请求服务器存储一个资源，并用Request-URI作为其标识 DELETE 请求服务器删除Request-URI所标识的资源 TRACE 请求服务器回送收到的请求信息，主要用于测试或诊断 CONNECT 保留将来使用 OPTIONS 请求查询服务器的性能，或者查询与资源相关的选项和需求 GET \u0026amp; POST # 老生长谈的问题，从来没有写下来过，写一次： This is GET:\nGET /books/?sex=man\u0026amp;name=Professional HTTP/1.1 Host: www.wrox.com User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6) Gecko/20050225 Firefox/1.0.1 Connection: Keep-Alive And this is POST:\nPOST / HTTP/1.1 Host: www.wrox.com User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.7.6) Gecko/20050225 Firefox/1.0.1 Content-Type: application/x-www-form-urlencoded Content-Length: 40 Connection: Keep-Alive name=Professional%20Ajax\u0026amp;publisher=Wiley That\u0026rsquo;s all.\nGET 不安全，长度受到浏览器的限制。POST安全，不受限。\nPOST还有一个加强版叫：soap，POST是无结构数据，就是简单的K-V数据。soap是个专用的POST版本，用于传输xml格式的数据。\nPUT \u0026amp; POST # 这两个的区别牵出了一个新的东西\u0026ndash;幂等，而幂等又牵出了另外一个著名的问题\u0026ndash;分布式服务的重复问题。\n幂等是个数学概念，后来是个计算机概念，意思就是s*s=s。\n其问题场景是这样的，在一个分布式系统中我们第一次发送的请求已经被正确执行，但是由于网络抖动请求返回报文客户端没有收到，客户端刷新了一下，于是就又发送了这个请求，这个请求又被做了一次，加入这个动作是付款的话。\n这就要求我们的操作要具有幂等性，也就是说相同的操作，对整个系统产生的副作用是相同的。幂等是个语义范畴的东西，无法被协议检测出来，但是http本身又是一个分布式的协议，所以这个幂等在http中具有举足轻重的地位。 那么这个问题怎么解决？目前有两种方式，一种是引入分布式中间件。把复杂的验证问题交给中间件来解决，（据其他人说）中间件往往会架构笨重，事物容易被绑定在中间件上，不利于系统异构集成。另外就是性能上也很是问题。另一种就是利用幂等设计，很神奇。\n这个幂等就是PUT特有的，而POST不具备幂等的特性。 所谓幂等设计就是说我对于一个请求，由服务端生成一个唯一的处理id，这个id用于为后续操作保证幂等，对于同一个id只做一次操作，但是每次都返回第一次操作的结果。这种设计相比中间件必然很轻量级。\n不过这个问题，我也没有深究，所以理解起来也不深刻。大家纠结最多的是POST和PUT什么时候该用哪个的问题，我也没有答案。哈。\n协议分析利器 # 下面透露点真正的干货。 不管是搞开发还是搞点乱七八糟的小研究，抓包都是程序员最喜欢玩的喽。介绍三个抓包的玩具。\ntcpdump # 如你所见，tcp为基础的包都能抓，最长用来抓http的包。可以定点抓，定端口抓，输出到很多目标。 其特点就是\u0026ndash;多。信息流多到人力看不过来，所以一般都是配合提取工具比如grep 来获取想要的信息。 这个是linux自带工具，不需要安装。 怎么用，暂时可以看这里\nhttpry # sudo apt install httpry 转为http搞的，用起来感觉信息不太够，可能是我不会用。\n扩展阅读\ncharles # MAC上的工具，还是个付费的。不过也有免费版，去官网下载\n怎么用还没玩过呢。待补充。\n"},{"id":83,"href":"/posts/self/howtolearn/","title":"关于计算机科学的学习","section":"Self","content":"这篇文章的标题写了很久都没有开始动笔去写，因为随着学习的宽度和深度不断的扩大，越来越不敢贸然的去写这么大的题目。\n首先这个文章是我自己的经验和思考，要适合个人的情况。\n如何学习新事物 # 抓住概念，触类旁通。\n上面这个两个词是一个高度的概括。扩展出来分成两个方面，一个是如何抓住概念，一个是什么是触类旁通。\n抓住概念 # 在传统的学科中，概念是十分清晰的，尤其是数学、物理学的表述。这样经过总结下来的概念是什么呢？ 就是描述这个事物的特点的严谨表述。 归根结底，现在科学发展的再高，也只是一种归纳，谁也无法确保数学的基础就是无法动摇的，物理学的基础还存在很多不同维度上的争议。所以现在的概念就是一种归纳。\n这种归纳将这个事物独有的特征组合进行描述。符合了这个描述的东西我们就可以认为是这个东西。\n所以当我们在分析事物的时候，除了我们本能主管可以判断的事物以外，我们就是利用这样的特征比对来进行分类判别。\n为什么我们要进行分类判断，给这个东西一个定义呢？\n为了应用前人的理论研究。举个例子，你知道一个直角三角形的两条直角边的长度，你想知道第三条边的长度，如果你不上升到理论的层次上去，你就只能去量。但是一旦你将这三个点上升到了直角三角形的理论分类中，接下来的思考就是理论上继续延伸出去，可以用三角函数、勾股定理等，在没有上升到理论层面的时候是直观的问题，上升到了理论上就是抽象的问题。\n所谓科学与经验的区别，我认为某种程度上是直观与抽象的区别。\n上面说的实际上是抓住概念的重要性。那么如何抓住概念。\n很简单就是去找概念，总有别人定下的概念。 但是！计算机科学有其特殊之处，而且非常的独特的地方，就是，这个领域的很多概念是个体的思维抽象，其他的理论基础非常少。会出现什么问题呢，就是同样的事情，第一个发明出这个概念的人有很清晰的概念。当别人看到了这个东西或是理论以后，他会有自己的理解。这个理解就让人很头疼。有的时候，有些人的理解很形象，相比于最初的概念来说，很容易被人们普遍直观理解。但是，如果这个时候这个人对于原概念或是事物本身并没有理解的非常深刻，没有完全抓住这个事物的特点，那就会产生信息的缺失。\n概念中的信息缺失是十分可怕的。\n就比如你学习牛顿第一定律：一切物体再不受外力作用时,总保持匀速直线运动状态或静止状态。这是原生的概念，如果我说在一个光滑的平面上，放一个小球，不推他，他就静止在那里，推他一下他就一直保持匀速往前滚。这就是牛顿第一定律。\n上面的这个表述对于一个初中生来说，确实很好理解啊。但是这个表示事实上出现了信息缺失，我说的是光滑的平面上，这并不是牛顿第一定律的特征，或者说只是符合条件的一个特殊情况。相比较原版的不受任何外力，对于这个定律的理解就会产生非常大的偏差，你可能会以为只有在平滑的平面上才是这样。\n就是这样，很多时候我们想去快速的了解一个东西或概念是什么意思，于是就去问别人，或是看别人的转述，别人的理解。但是很多情况下，写下这些东西的人本身可能理解了，但是在表述上又讲不完全，导致你的理解会有问题。\n所以你要去抓住概念本身，总结概念本身表述出来的特征，才能让你真正准确的理解这个问题。真正的概念和定理都是非常的简短且优美的，形式上的简单，思维上的复杂，所以需要花时间好好领悟出来。\n在以前学习计算机相关的知识的时候，我会经常去看别人的博客，也能学到很多东西，但是有些时候就无法掌握一个技术点的精髓，尤其是一些算法的精髓。好在在学习算法并实现算法的过程中自己根据实践的经验也能够弥补这些不解，在实践中总结规律和特征。\n在别人的博客中，学习的其实是经验，而概念，要找到源头去理解，好在那些发明了这些概念的人都还大部分建在。\n触类旁通 # 任何事物和理论都不是孤立的。 计算机的很多理论都是相通的，一切的发展也都是有原因的。\n当你知道了计算机的基本物理结构以后，你就应该能够想到一个程序的运行方式。计算机由运算器、控制器、存储器、输入、输出设备组成。那么代码一定是在运算器中运算，数据一定存在存储器中，程序如果要用数据一定也要从存储器中取到运算器中，从存储器到运算器之间的数据传输一定是需要时间的。所以你就知道为什么计算机要有内存和硬盘，因为要加速这个数据传输的过程。。。。\n计算机的很多硬件的设计，其根源就在计算机的基本结构中。这也算是要抓住概念，抓住计算机的物理结构。 同样的很多程序在做优化的时候要优化那些东西，也都是源于硬件的差异，什么部件速度慢，什么部件速度快。\n基本上从计算机的基本结构中我们可以触类旁通的拎出一串很长的技术线。\n这是硬件层，我们的注意点再换个层面，从程序语言这个角度来思考。\n低级的程序语言就是要操纵硬件和逻辑门，用什么来操作呢，用电压。高级的语言能不能被计算机理解，很明显不能，那为什么要有高级语言，因为要方便人的编写。那么高级语言势必要被某个东西转换成底层语言，这就是编译器的工作。怎么能让高级语言变成低级语言，这就要求高级语言一定不能太复杂，要有准确的规则，使得每句高级语言都能准确的翻译成一句底层语言而不能有二意性。\n很多高级语言会有很多高级特性，比如什么动态绑定啦、继承、多态，你去想一下这些是否具有二异性，很明显没有。所以才能实现这样的高级特性。但是在我们直观来看多态本身就是要做到根据运行时的情况的不同去执行不同的代码呀，代码一经编译就是死的了，怎么实现的呢？肯定是在编译的时候加了一些控制代码，程序不可能活的。，肯定是死的。这个代码就是编译器去加的了。所以不同的语言有不同的特性，因为他们用不同的编译器嘛。\n在此基础上在去理解什么设计模式，开发框架，就会简单很多。\n计算机还有一个重要的分支，就是计算机网络。\n从底层来说就是电信号或者是光信号转换成数字信号。所以每个设备都要具备一个转换器，有了转换器，我们就可以不去探讨物理上的问题了。回到计算机的问题。网络如何来认识目的地，肯定不能是单拉线，那么共用一个网络就要确认一下是不是到了目的地，就有了IP地址、Mac地址、路由、转发、协议等等。到了目的地怎么知道是发给哪个程序的呢？于是就有了端口，端口要实体的口嘛？当然不需要，因为你的电脑上没有那么多口嘛。\n。。。\n当你遇到一个上层的问题的时候，把这个问题往底层推，找到它的技术依赖点，然后你就可以懂了。\n如果你看其他人的博客或是什么，他们一般会基于自己的知识，没有必要往下推问题才能理解，以为其本身很熟悉这个层次的问题，只是在这个层次去讨论，所以也不适合你去学习。\n我觉得博客一定是要同一层次或者是略高一点层次的东西才有价值，过高的层次没有好的效果。\n计算机科学本身 # 计算机是一门实践的科学。\n在计算机中，一些工程上的设计思想其实非常简单。很多人只要逻辑思维清晰就很容易理解。这也是计算机行业的某些方面门槛很低的原因，也是很多培训机构看到的商机。\n但是计算机的很多科学理论也是非常难理解的，计算机是数学、物理学、离散数学的应用。其伟大的基础并不是那么简单的逻辑就能理解的，就比如设计一门语言，并不是我们想想这样设计就能保证正确了。我们的逻辑思维虽然很智能，但是不完备，我们无法用逻辑去思考到所有的情况，为了避免逻辑上的遗漏，语言这样的设计工作都要上升到理论层面，从闭包的理论上去证明语言的正确性，也就是保证编译出来的底层语言是准确的，无二意的。举C语言的例子，语法就那么一点点，但是却几乎构建了整个计算机世界。无数人写出的千变万化的C语言代码中，没有一句话会有问题，这不是几个设计者用脑子去想出来怎么设计的，而是用理论去证明出来的。\n计算机的理论可以很坚深，但是其应用也可以很简单。无论是哪一部分，都可以作出优秀的作品出来。\n同时我认为计算机业界的规范还非常混乱，这样很难将经验抽象成理论，没有理论化的基础，这个科学的发展很快就会到瓶颈，因为人脑的能力有限，靠人去搞清楚这些并在记住这些东西的基础上再去发明新的东西是很浪费的。\n学习计算机，关键还是要热爱，如果学着不快乐，活着有什么意义。\n"},{"id":84,"href":"/posts/others/sql/","title":"SQL进阶","section":"Others","content":"本文不介绍最简单的增删改查，而是对于SQL的进阶语句的介绍，顺便研究一下其内部实现。\nJoin # 由浅入深，从使用到优化。\n概述 # Join一般会有人称为级联查询，我表示这个名称还算直观。其应用场景有那么几种：\n某个表中的某些字段需要另一个表来做精细描述。比如职工表中职工等级需要等级表来进一步详细描述该等级的权限、福利等。当我们需要某个人的信息的时候一定是从职工表拉取记录并且需要再从等级表中拉取具体信息合并呈现。 某个人的全方位信息存放在不同的表中，要想得到完整信息就要多表查询合并结果。 上面两种场景都是涉及了两个及以上的表，这就是join的使用场景特点。\nSQL语句 # select col_a, col_b, ... from tb_1 join tb_2 on tb_1.col_a = tb_2.col_a where ... ; 其最主要的特点就是from的来源发生了变化，所以我们可以理解为这个sql语句生成了一个新的表，并从这个新表中获取了符合where条件的记录。所以这个join我们看作是对表的一种运算，运算的结果是一张新的表。 这个join运算有一个on的条件，也就是在这个on的基础上进行运算。\nJoin 运算一共有四种：\ninner join （内连接） outer join （外连接） left outer join （左外连接） right outer join （右外连接） 在讲这四种运算之前先要有一个笛卡尔积的概念。 笛卡尔积来源于离散数学中的集合操作，对于两个集合做笛卡尔积就是将两个集合中元素两两组合，生成一个新的集合，新集合中的每一项都是一个二元组(可以理解为一个数据包， 并且这个数据包是有序的，总是某一个集合的元素在前，另一个在后)。所以，如果两个集合的size分别是n,m， 那么笛卡尔积生成的集合size=n*m; 对于表做笛卡尔积，同理就是将两个表的记录两两组合生成一个巨大的新表，每条记录都是由两个表的记录拼接而成。 该概念仅用于理解运算结果的组成，并不是其实现方式。以下的操作可以理解为是在此基础上进行条件筛选，但事实上SQL使用的是循环的方式去查找结果。\ninner join # 其结果为：笛卡尔积中，符合on 条件的记录。\nouter join # 对于一条A表的记录，如果没有找到符合on条件的对应的B表记录，那么A表的此记录依然出现在结果集中，其对应的B表部分为NULL。 The same to B.\nleft outer join # 根据outer join 的意思，可想而知，对于A找不到B的情况，保留A的记录，而对于B则滤掉相应记录。\nright outer join # 同理。\nTips # 如果对于A的一条记录，有多条B记录对应，那么会以多条记录的形式出现。这一点跟高级语言的思维方式不太一样。高级语言用OOP的思维来想，就是在这个对象的对应成员上挂个链表，有多少条记录就都挂在下面，但是A的这条记录的实例只有一个。\n问题 # join 的内部实现是啥?\n分页 # 这个事实上是非常常用的技巧，也非常简单。\nselect * from TableName limit cnt, pagesize; 其中主要就是这个limit的用法，其支持两个参数，cnt-[偏移量], pagesize-[记录数量]。 很简单的计算机思维，起点加长度，当然起点是0。这个地方我还绕了一下，看了一个博客，结果这个博主很奇葩，人家都下标从0开始了，自己却还让记录从1开始记，害我吃了三秒钟的屎。就是你把记录下标从0开始记就好了。\nexample # 下面这个就是从下标为5的记录开始，查询10条记录。使用的时候只要定一下pagesize，然后接受个page的参数，计算一下偏移量就Over啦。（曾经我还手动撸过，Too Young）\nselect * from TableName limit 5, 10; 索引 # 索引就是目录。但不仅仅是目录，还是整本书。 有几点需要知道：\n数据库中的数据是持久化的。 索引就是文件，也是持久化的。 索引比数据本身更大。 震惊吧，我看到1G的数据有2G的索引的时候我也很震惊，然后就有了这篇文章。\n索引是干嘛的，为什么有索引，索引的好处。。。这些你都想的到，所以不说了。但是有几个数据你需要知道：\n内存速度比硬盘IO快十万倍，1e5。 一次硬盘IO的时间差不多在9ms左右，一台500MIPS的机器可以跑40万条指令。 一个三层B+树索引可以优化百万条的数据查询到3次IO。 索引有哪些？（高频面试问题） # 关于这个问题，如果你回答的是：唯一索引、聚集索引、非聚集索引、主键索引等，一般的开发岗就算答对了。如果是技术实力强的团队，尤其是数据库相关的团队，such as 我所在的阿里中间件存储事业部，这个就算是个菜鸡回答了。如果你眼中的索引是：B+树索引、B-树索引、B树索引、位图索引、Hash索引，你就很有可能要被发offer了。这里就挑个B+树索引来说吧。\n不了解的人一定更关心B树和B-树和这个B+树的区别，那就瞎说一下吧。\nB树 # B树就是二叉搜索树啦，一般要用平衡二叉树，不平衡的还有人用? (B树的原名为B-tree，是多路二叉树，被直译为了B-树。乱糟糟的，你懂就好，不必纠结那些东东)\nB-树 # 是个多路搜索树，也就是非二叉。其最大设定为M叉，在每个结点中，数据有序排列，且子树之间有序，所以可以直接节点上二分查找。 其数据分布在整个树中，也就是说不一定走到叶子就找到数据就返回了。\nB+树 # 基本结构与B-树一样，不一样的就是所有的数据都分布在叶子节点上，中间结点只是做索引的功能不保存数据。\n其实还有B*树，哈哈，是不是很绝望。这种树在非根和非叶节点还放了一个指向兄弟的指针，在数据膨胀的时候空间利用那个率更高。 什么是数据膨胀呢，就是你数据库在变大嘛，你就要不断往索引树里面塞新的数据。这个时候你不断往某个结点里放，结果放满了，但是还有数据要分在这个叉里啊。所以你要把这个结点分裂出子节点，这个结点里把数据放下去，留个指针就好了。对于B+树来说，要求每个节点要至少放满1/2的数据的时候才能分裂;那么对于B*树来说，如果他的节点满了，可以把数据往兄弟节点里放，将分裂水位升到了2/3，所以空间利用率更高。\n但是这并不是我真正想说的。。。 我们还是来看这个B+树好了。\n首先普及一下操作系统数据加载的一个知识：由于我们可以想像，当硬盘上某条数据被加载到内存即将被使用的时候，那么其周围存储的数据有十分有可能就是下一个被用的数据，所以在加载数据的时候都是直接把整个数据页加载到内存里，数据页大小由操作系统决定，一般是4-8K。 这个设计之优美就在于利用了这个特性。每个东西被使用都是有原因的！基于这个特性，我们就可以尽可能的减小我们的磁盘IO次数，How to？我们让B+树的一个结点去记录一个磁盘页的信息，这样我们在树上访问一个节点的时候只做一次IO就将节点中的数据提取出来了，然后我们在内存中做二分，定出下一个节点，然后去访问这个结点，同样只要一次IO。这样索引的查找效率就提升到logM(N)了。\n但是这只是索引的优美，下面是索引的神奇。\n索引查询优化 # 这部分的内容很有生产力，当我还在学校的时候，某个不认识的学长曾经跟我说数据库优化多么重要，一条SQL语句优化就省了好几台服务器的钱。当然他也没能举出例子，说理有些苍白无力啊，那么例子就来了。\nselect * from TableName where a=1 and b\u0026gt;1 and c=2; vs select * from TableName where a=1 and c=2 and b\u0026gt;1; 这是个非常简单的例子，但是很能说明问题。 需要补充几点知识，B+树在节点内做匹配的时候很多时候都是多个字段都有索引的，他是按照最左前缀匹配原则来二分的，通俗点讲就是，贪心匹配，当当前条件满足他就往下走，例如当碰到这个b\u0026gt;1, 那就不管你后面c=2的限制了，先去把所有的b\u0026gt;1的结点访问一遍，去那里再搞你这个c=2。所以肯定是下面一个更快啦。\n会快多少呢？就看你数据库多大了，越大差的越多。这个简单的优化很容易学啊，也是最基础的必须做的优化。 一般=、in之间是可以乱序的，索引会自己调整。\n第二个优化就是：尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条记录。\n关于慢查询的部分，再补充吧。。。\n"},{"id":85,"href":"/posts/java/jdbc/","title":"JDBC","section":"Java","content":"JDBC(Java DataBase Connectivity) 这是JDK中集成的一个数据库API，可以访问任何类型表列数据，特别是存储在关系数据库中的数据。 本文以mysql为例。\n所谓数据库交互，无非就是那么几个部分：建立连接，执行SQL，取回数据。JDBC的设计思路被Php借鉴过去后就产生了PDO，跟JDBC一曲同工，加之轻量级，然后就感觉很好的样子\u0026hellip; 与数据库交互体现在程序上，也无非就是那么几个部分：引入包，实例化对象，调用函数。\n那么学习JDBC学他的什么？学会了怎么用然后呢？可以学习其设计思路，有的时候，从设计思路来学习怎么用会比直接学怎么用要容易，Let me show you.\n架构 # 现在把自己当成设计者，从设计的角度出发来看JDBC。 你要做的事情是将市面上诸多数据库整合到一起，给Java程序提供一个格式统一的工具。用更学术的语言来表达就是将底层差异屏蔽掉，抽象出一个数据库抽象层，使得数据库对于Java程序透明（学术其实也是将事物统一整理成一个较高的层次，忽略底层实现差异，用思想指导实践。例如当你碰到一个新的问题，整体十分复杂，你不可能直接就想到一个实践方法将其实现，这个时候就需要知识来抽象这个问题，当问题抽象到了某个知识领域内，这个问题就可以再从抽象顺着这个知识往下拆解，最后落实到具体实践跟抽象知识已经没什么关系了）。\n要实现统一接口，我们借鉴操作系统与硬件之间的做法，就是每个数据库按照我给的一个标准来写你自己的驱动程序，这个标准就是初步将数据库之间的差异屏蔽，例如我规定所有的select语句由什么函数执行，返回什么格式的数据等。这就是底层的Driver。\n再往上，我们需要一个统一的入口。在Java中，不同数据库实现的Driver肯定是不同的类，这样的话难道我们要用什么数据库就用什么类吗？当然能透明就透明，最好是我在参数中体现我要用什么数据库，灵活性更大。所以这个时候我们在几个类上面在做一个抽象，抽出来一个Manager，这个Manage负责数据库的选择，动态实例化，连接等等乱七八糟的事情，然后这个manage在整理封装成JDBC API提供给Java程序使用。\nOver.\n但是你知道了怎么设计，还是没有卵用，哈哈哈呵呵！上面已经说过了，当你具体实践的时候已经跟上层知识没有什么关系了，但是你会很快理解具体该怎么做。\n实例 # jdbc简单的使用差不多在下面的代码中都有体现，另外我对于这个资源关闭的问题还有点迷惑，因为在jdbc的代码中实现了一个Autocloseable的接口，对于当前版本的JDBC要不要显示关闭资源的问题，有可能是不需要的。有待深入了解这个AutoCloseAble接口。\n//STEP 1. Import required packages import java.sql.*; public class FirstExample { // JDBC driver name and database URL static final String JDBC_DRIVER = \u0026#34;com.mysql.jdbc.Driver\u0026#34;; static final String DB_URL = \u0026#34;jdbc:mysql://localhost/emp\u0026#34;; // URL 格式(mysql)： jdbc:mysql://host:port/databaseName // Database credentials static final String USER = \u0026#34;root\u0026#34;; static final String PASS = \u0026#34;123456\u0026#34;; public static void main(String[] args) { Connection conn = null; PreparedStatement stmt = null; try{ //STEP 2: Register JDBC driver // JDBC要求要显式注册你要用的驱动类 // 这个代码就是让JVM加载对应的类，并执行其中的静态代码。 Class.forName(\u0026#34;com.mysql.jdbc.Driver\u0026#34;); //STEP 3: Open a connection System.out.println(\u0026#34;Connecting to database...\u0026#34;); conn = DriverManager.getConnection(DB_URL,USER,PASS); //STEP 4: Execute a query System.out.println(\u0026#34;Creating statement...\u0026#34;); String sql; sql = \u0026#34;SELECT id, first, last, age FROM Employees\u0026#34;; stmt = conn.prepareStatement(sql); ResultSet rs = stmt.executeQuery(); //STEP 5: Extract data from result set while(rs.next()){ //Retrieve by column name int id = rs.getInt(\u0026#34;id\u0026#34;); int age = rs.getInt(\u0026#34;age\u0026#34;); String first = rs.getString(\u0026#34;first\u0026#34;); String last = rs.getString(\u0026#34;last\u0026#34;); //Display values System.out.print(\u0026#34;ID: \u0026#34; + id); System.out.print(\u0026#34;, Age: \u0026#34; + age); System.out.print(\u0026#34;, First: \u0026#34; + first); System.out.println(\u0026#34;, Last: \u0026#34; + last); } //STEP 6: Clean-up environment rs.close(); stmt.close(); conn.close(); }catch(SQLException se){ //Handle errors for JDBC se.printStackTrace(); }catch(Exception e){ //Handle errors for Class.forName e.printStackTrace(); }finally{ //finally block used to close resources try{ if(stmt!=null) stmt.close(); }catch(SQLException se2){ }// nothing we can do try{ if(conn!=null) conn.close(); }catch(SQLException se){ se.printStackTrace(); }//end finally try }//end try System.out.println(\u0026#34;There are so thing wrong!\u0026#34;); }//end main }//end FirstExample Java 的文档已经非常的详细了，除了是英文版，其他的都非常棒。你可以只了解上面的部分内容，当你需要使用其他的功能的时候都可以方便的在函数列表中找到你要的函数，估计你要实现的功能都有。 例如在获取字段的时候，你可以用下标来获取，而不是只能用字段名称获取。\n如何学习Java的使用? 去看源代码。所谓看源代码并不是代码的细节去看，而是去看这个代码都做了写什么，这个类是个什么类? 其内部是Array还是Map还是List？这些东西清楚了，足以让你知道如何使用它了。当然很多情况下，其内部不是简单的一中数据结构，可能是多种并行。所以你只需要对基础的数据结构很了解，在用这些东西的时候只要看函数名称就能理解其用法。可能在如何学习计算机科学这篇文章中还会提及这方面的技巧。\nStatement # 上面有个地方你可能会不太理解，就是为什么我建立连接后不能直接执行SQL而是要搞一个statement呢？这个就是设计模式与直观思路的差异问题。直观想法就是我建立了连接就可以去执行SQL了呀，但是JDBC要实现更多的功能，所以又进行了流程分拆，这个Statement就是用来执行SQL的那个部分，既然用一个类来执行，必然对这个SQL做了一些什么骚操作。事实上JDBC对于这个Statement有三种设计。\n三种Statement类： # Statement：由createStatement创建，用于发送简单的SQL语句（不带参数）。 PreparedStatement ：继承自Statement接口，由preparedStatement创建，用于发送含有一个或多个参数的SQL语句。PreparedStatement对象比Statement对象的效率更高，并且可以防止SQL注入，所以我们一般都使用PreparedStatement。 CallableStatement：继承自PreparedStatement接口，由方法prepareCall创建，用于调用存储过程。 常用Statement方法： # execute(String sql):运行语句，返回是否有结果集 executeQuery(String sql)：运行select语句，返回ResultSet结果集。 executeUpdate(String sql)：运行insert/update/delete操作，返回更新的行数。 addBatch(String sql) ：把多条sql语句放到一个批处理中。 executeBatch()：向数据库发送一批sql语句执行。 其他 # 以上只是简单的基础使用和一些基本概念的理解，以后会补充JDBC事务的概念，以及JDBC与SQL之间的数据类型转换等。\n会了这个你就基本懂php 中PDO的使用了。\n常用代码实例 # 有一些常用的代码，就直接写在这里，用的到的时候直接Copy上就好了。\n获取insert后自增字段值 # 用于在资源创建后获取资源ID， 要求具有原子性。\nprivate String insertSQL(String sql) { //Connection 参考上面的代码 ... // ResultSet rs; Connection conn = null; PreparedStatement ps = null; long ret = 0; try { conn = ds.getConnection(); // important \u0026amp; ps = conn.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS); int rows = ps.executeUpdate(); rs = ps.getGeneratedKeys(); if( rs.next() ) { ret = rs.getLong(1); } conn.close(); ps.close(); rs.close(); } catch (SQLException e) { e.printStackTrace(); } return Long.toString(ret); } "},{"id":86,"href":"/posts/web/rest-framework/","title":"rest_framework","section":"Web","content":"这是一款Django下的API开发框架，对于业务逻辑较简单的API来说非常方便，开发速度非常快。\n此坑待填\u0026hellip;\n"},{"id":87,"href":"/posts/self/baiji/","title":"百技","section":"Self","content":"百技给我的另一个很大的冲击就是，让我再一次思考自己的人生在追求什么。这可能是要思考一生的问题，但问题的答案在你开始思考的那一秒，潜意识里就已经有了。 我的答案依旧是坦然的面对自己，不为可笑的虚名浪费时间。\n为什么会再一次思考这个问题。其实这个问题在过去的一段时间里一直在思考，因为要做选择了嘛。选择当然就是在现实与自己之间做个平衡。参加培训的我所在的组有10个人，其中9个是研究生，我有点紧张，然后我粗略看一下现场120多人的样貌，我判断的本科生应该不超过10个。这个数据我是没有预料到的，很震惊，同时更加慌张。我想到的第一个问题是：我不会成为下一个《伤仲永》吧。不过很快我就不这么想了，因为我特么根本就不是什么天赋异禀，怎么能跟仲永做比较。然后我就更慌了，没有仲永的本事还在这玩，不太妙啊。然后通过跟大家的几天相处，我终于近距离了解了一下研究生是个什么样子的一群人？然后我又意识到，这群研究生都是很厉害的研究生啊，害怕。\n学术圈的事情，本科生普遍就算了，算是全民普及教育的一部分了，研究生也搞成这样，很大程度稀释了国内学术水平，都是交易，学术民工。(或许这个时候我没有想到后来我也会去读研究生，做起了学术民工)\n为什么会问这样的问题。什么样的问题呢，就是这种问题。。。如何才能平衡工作跟生活？如何成为厉害的人？有没有什么好的方法XXXXX。。。问出这样的问题的人如果自己在0.001秒内没有给自己答案的都可以回家了。如果自己0.001秒就可以的出答案的还问出来，也可以回家了。\n研究生问出这样的问题，我觉得是很不应该的，所以我加了学术上。这就想讲到我对研究生这个学历的看法，不是对研究生们哦。首先一点要说的就是研究生什么年龄都是可以去读的，这在制度上是正确的，给赞。其次我认为其知识水平与思想素质水平不对等是不应该的。换句话说，一个人如果能够参透高深的知识内容，其必定也参透了一些哲学思想，或是自然之道，中国话讲大道至简。如果其强行掌握知识，也未必能在此基础上生发新生命。这貌似是国内学术圈的现状。\n所以有的时候，一纸虚荣未必值得我浪费青春去求证，我也未必需要世界对我的一纸认证。但倘若我真的去了，我会践行一个学者应有的付出。 归根结底，当我面对自己的时候，不要后悔。\n后记： # 2022年6月，重新来读这一篇感想。已经读完研究生，并重新入职原部门，工作8个月。\n在疫情中度过了研究生生活，由于研究的方向是NLP，遇到大规模预训练模型的诞生和发展，研究工作推进的还算顺利，但是没有什么实质的成果。\n"},{"id":88,"href":"/posts/web/django/","title":"Django","section":"Web","content":"(注：本文写在N天之中，随着对其的深入学习，很多的看法会发生变化。我也尽量把东西放在这一篇中解决掉，文章思路会有些跳跃，可能先上了细节后面再归档等等。另外，本文会屏蔽一些技术细节，用一些术语来表达，这些术语均是较容易学习的知识块。)\n这段时间神奇的技术走位，Java与Python的爱恨交织。\n所以既然写到了肯定就是用到了呗，拿到了一个Django的项目，改写成Java的，玩的就是这么欢脱，做为一个写C++出身的入门级Java工程师生活已经如此艰难，然后发现现实是还要兼职Python工程师。\nDjango也算是工程师玩的玩意儿？封装成了这个样子还有什么好玩的，估计随随便便学2个小时语法加一点Django的框架设计就可以玩起来的，我只能说写这项目的哥们太会偷懒了，服气，骗完钱就离职，更是任性的不行。\n言归正传！框架这种东西嘛，就是为了简化开发，提高速度效率，降低合作成本用的，所以django的设计也算是符合了这个目的。但是他并不是简单的照搬了JavaWeb框架的MVC设计思路，而是他妈的又提出了一个神奇的MTC，不用想也知道，就在人家的基础上变来变去还自以为参透了宇宙的奥秘。所谓的MTV就是把几个分工重新分了一下，对，就是要跟人家不一样，日你哥！\n不过话回来，就算是对于MVC这个业界都普遍遵循的设计模式，也有很多不同的理解，比如业务逻辑到底该Controller来做还是Model来做，甚至还有人要把这个交给view来做的。之前貌似还看到了个文章讲什么官方设定，话说都发展到这个地步了谁还管你官方设定。不过呢，这都是个设计思路，不同的程序员当然有自己的理解，自己写项目的时候怎么搞都行，但是现在这框架数量真的有点爆炸了，所以大家还是在设计的时候多用点心吧，实现框架的技术不难，但是设计是艺术。\n所谓的MTV分别就是： Model、Templete、View。熟悉就对了，你肯定一眼就看懂了，我也是一瞬间就明白了。但是很抱歉，仔细想一下这个Templete如果是前端模板的话，view是啥？如果view用来组装前端模板的话，要model来做业务逻辑吗？那controller岂不是没有了？……就是这么神奇，人家把业务逻辑交给了view来做，我特么也是佩服的吐血。Model就纯纯的数据库操作，就像是一个sql的python版。至于Templete，我已经没有耐心再跟他浪费时间了，老子一个写接口的要什么前端！\n对于理解一个框架来说什么最重要？我在很久以前初学框架的时候一脸懵比。我草，这么多代码我得看到什么年？怎么连个主函数都没有，日了狗。。。好在我当时看了一会php，这个比较简单，不用编译一下就能懂，后来我从别人的文章中看到了学习框架的几个步骤等，才知道，看懂路由，就懂了这个框架的一半。\n路由 # 提到这个路由，Python这个框架还是让我吃了一惊的。因为这玩意儿不需要容器，厉害啊。写过其他Web的都知道，我们的Web程序是要在一个Web服务程序的组织下做应答的。但是Django抛弃了这个服务程序，严格来说是Python的Web Server抛弃了其他的服务程序，自己写了一个简单的网关程序\u0026ndash;wsgi。其实作用就是做个协议转换，链接机器与python程序，替代了apache2的一些基础功能。不过据说性能欠佳，做做测试还行，上线还是要靠Nginx的帮助，搞个uwsgi。\n底层的东西，可以不懂，但是懂一定没有坏处，但是我还没时间搞懂。下面讲一下上层路由。\n一个Django的项目特点就是目录比较清晰，比如这个urls.py就是存放路由信息的文件。django在自动化这个地方并没有做太多东西，对于路由信息要显示的写在这里。for一个zample.\nfrom django.conf.urls import url, include from django.contrib import admin import views urlpatterns = [ url(r\u0026#39;^admin/\u0026#39;, admin.site.urls), url(r\u0026#39;^docs/\u0026#39;, include(\u0026#39;rest_framework_docs.urls\u0026#39;)), url(r\u0026#39;^er/\u0026#39;, views.ERView), # ui view url(r\u0026#39;^ui/Node\u0026#39;, ui_views.node_view), url(r\u0026#39;^ui/Cluster\u0026#39;, ui_views.cluster_view), url(r\u0026#39;^ui/InstanceGroup\u0026#39;, ui_views.instance_group_view), url(r\u0026#39;^ui/Chart\u0026#39;, ui_views.chart_view), url(r\u0026#39;^ui.*\u0026#39;, ui_views.home_view), # API url(r\u0026#39;^v1/\u0026#39;, include(\u0026#39;rest_api.urls\u0026#39;)), url(r\u0026#39;^v2/\u0026#39;, include(\u0026#39;rest_api.urls_v2\u0026#39;)), #url(r\u0026#39;^report/\u0026#39;, include(\u0026#39;report.urls\u0026#39;)), url(r\u0026#39;^.*\u0026#39;, include(\u0026#39;rest_framework_docs.urls\u0026#39;)), ] 路由中可以预留参数位置，可以写正则表达式，论灵活性也还行。看到有些东西后买你跟的不是一个类，而是一个import语句，这是将路由转移到这个新的应用中去了，所以要去这个应用下再找对应的文件去继续路由，直到找到某个类为止。上面这个程序中其实是用到了一个叫rest_framwork的东西，这个玩意貌似是用来写网页文档用的东西，不过这个不是重点。\n既然找到了这个类，那么有个经典的问题又来了。去调用那个函数啊？这就涉及到了django路由的两种方式，一种是定义到函数，另一种是调用到类。一把小项目就自己定义到函数就好了。但是当项目比较大的时候就需要将路由定义到类的身上，注意这里我们说的都是在views.py 中的类。\n对于基类View，其暴露了一个as_view()的函数，该函数会对请求进一步做分发。下面两个就是这种方式路由的。\nurl(r\u0026#39;^Unit/(?P\u0026lt;pk\u0026gt;\\w+)\u0026#39;, UnitDetailView.as_view(), name=\u0026#39;UnitDetail\u0026#39;), url(r\u0026#39;^Unit\u0026#39;, UnitView.as_view(), name=\u0026#39;Unit\u0026#39;), as_view() 是如何做分发的呢？它会调用一个dispatch函数对请求方式做个路由出去再调用到你真正的处理函数。总是很麻烦，还没来得及看代码。 不过这里有一个简化的另外一个类，继承的时候继承Generic.View， 这是一个系列类， 有很多。用的时候就在处理类中写固定的函数就好了。在View的部分再细说。\n从安装到Hello World # 安装python 安装pip 安装django 找到一个目录来存放你的站点，然后执行命令创建目录：\ndjango-admin startproject mysite 在目录中出现站点的目录，进入发现有一个manage.py的文件和一个目录。 目录结构如下：\nmysite/ manage.py mysite/ __init__.py settings.py urls.py wsgi.py manage.py 是这个项目的命令行工具，与django-admin相似。 mysite/ 这个文件夹的名字是不能随便更改的，因为这就是包的名字。 settings.py 就是这个项目的所有设置 urls.py 就是你自己设计的路由 wsgi.py 这是事实上的Server入口 然后命令启动这个Web Server就可以了：\npython3 manage.py runserver 一般我会给个manage.py运行权限，将首行的python改成python3, 这样看你的django装在了那个版本下面。 运行起来去看8000端口就可以了。这个页面写的还是挺好的，内容不多，但是有一些提示很有人性化。\n至此一个项目就算是建成了，但是这里的项目跟其他我们说的项目不太一样，就是个空壳子，往里面塞的事实上我们称之为app。\n添加一个app：(在manage.py 同级的目录下执行下列命令，以使app作为独立模块使用而不是子模块)\npython3 manage.py startapp polls # 建立一个名为polls的app 然后还是来看目录结构：\npolls/ __init__.py admin.py apps.py migrations/ __init__.py models.py tests.py views.py models.py 数据库相关 views.py 业务逻辑相关 现在我们写一个简单的view，并组装好路由信息，让网站跑起来。\n编写views.py 如下： from django.shortcuts import render from django.http import HttpResponse # Create your views here. def index(request): return HttpResponse(\u0026#34;Hello World. This is polls app.\u0026#34;) 新增一个urls.py 文件在polls文件夹下，并添加路由信息如下： #!/usr/bin/env python3 # coding=utf-8 from django.conf.urls import url from . import views urlpatterns =[ url(r\u0026#39;^$\u0026#39;, views.index, name=\u0026#34;index\u0026#34;), ] 在mysite目录的urls.py 新增polls的路由信息： from django.conf.urls import include, url from django.contrib import admin urlpatterns = [ url(r\u0026#39;^polls/\u0026#39;, include(\u0026#39;polls.urls\u0026#39;)), url(r\u0026#39;^admin/\u0026#39;, admin.site.urls), ] runserver tips # 在mysite的路由中，我们没有加正则结束符$,且使用include可以将polls内部独立成一个模块，无论polls在哪里都没关系。\n在url中可以添加参数进行访问，在使用到的时候补充这部分例子。\nModel # python在这个方面简直方便的没有人性。我倾向于理解其是用python对象对数据表加以描述，并且！自动生成一个管理中心。可以直接使用python进行数据库交互。更方便的是，如果你对数据库操作很生疏，sql语句使用的不熟练，python自己集成了sqlLite这个玩意，你可以单纯使用python进行数据处理而不需要担心数据持久化的事情。当然你也可以自己搭建好数据库，并在配置中配置你所使用的数据库。\n下面就来建立model。编辑polls/models.py代码：\nfrom django.db import models # Create your models here. class Question(models.Model): queston_text = models.CharField(max_length=200) pub_date = models.DateTimeField(\u0026#39;date published\u0026#39;) def __str__(self): return self.question_text class Choice(models.Model): question = models.ForeignKey(Question, on_delete=models.CASCADE) choice_text = models.CharField(max_length=200) votes = models.IntegerField(default=0) def __str__(self): return self.choice_text 官方是这样解释的：The code is straightforward. 代码已经很直观了。除了基本的字段，还有一个函数，这个函数一看就是默认的函数，用来字符串化这个model的。也就是说，当你输出这个类的实例的时候，输出什么东西，就是这个函数来决定的。\n现在我们只是写了两个类，当然一个类就对应着一个数据表。我们需要手动建立这些表并生成交互接口。下面我们要将polls这个app，install到这个项目中，在mysite的settings.py中添加install项：\nINSTALLED_APPS = [ \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, \u0026#39;polls.apps.PollsConfig\u0026#39;, ] 然后我们执行下面的命令：\npython3 manage.py makemigrations polls 这个时候就完成了建表的任务。这个命令就是专用model操作的。然后使用下面这个命令可以显示出被执行的sql语句：(后面的0001根据执行返回值确定)\npython manage.py sqlmigrate polls 0001 然后我们执行以下命令来使我们的变更生效：\npython3 manage.py migrate 以上都不是关键，关键是其自动化数据库交互的部分, 在官方文档称之为database API。\n其主要思想就是面向对象的概念，将数据表抽象成为一个对象，对这个对象提供了一些增删改查的函数。直接show you the code\nfrom django.utils import timezone from polls.models import Question, Choice # 查询Question表中数据 Question.objects.all() # 创建一条数据并存入数据表， 注意q是一个记录对象，只是一条记录。 q = Question(question_text=\u0026#34;What\u0026#39;s new?\u0026#34;, pub_date=timezone.now()) q.save() # 获取字段值 q.id q.question_text # 更改字段值并保存 q.question_text = \u0026#34;what\u0026#39;s your name?\u0026#34; q.save() # 获取记录 q = Question.objects.filter(id=1) q = Question.objects.get(id=1) # 这两个之间的区别还是有的，暂时没有深究 更多操作待补充，继续往下走\u0026hellip;\n(Django 自动生成了一个admin的操作页面， 使用下列命令生成用户就可以使用了)：\npython3 manage.py createsuperuser 然后在url后加/admin/就可以进去了。\nsettings # 待续\u0026hellip;\n"},{"id":89,"href":"/posts/java/java-3/","title":"Java-反射","section":"Java","content":"Java某些特性决定了他今天的地位，反射就是其中之一。\n反射是一种在运行过程中使用的，对于任意一个对象都可以获得他所属的类，进而都能够获取他的任意的方法和属性。我对反射的理解就是可以实现动态调用。 最常见的应用场景就是在Java的Web框架中，就是根据一些路由信息来定位到某个类的某个函数，定位到这个函数后就要启动这个函数。不可能写N多个if-else来匹配是否是当前类，是否是这个函数，我们希望的就是我传个参数，然后就能动态调用这个函数。至于类的实例化，函数的调用，交给JVM来做，这就是反射的意义。也是一种语言特性，很多解释型语言都具备这一特性，例如php等，其实java究其本质也算是一个解释型语言，只是有一个预编译的过程，编译出来的字节码也还是要用java虚拟机来解释执行。\n实例化对象并调用对应函数 # 使用反射可以根据类名称来实例化对象，调用函数，传递参数。 这一部分涉及到的内容还是很多的，比如可变长参数，反射的机制，函数的重载问题等。\n首先要获取我们要调用的函数，所以第一步先Class.forName()。这个函数是让JVM去加载这个类，然后获取其对应的函数getMethod()。在获取函数的时候会涉及重载的问题，多个函数名称一样的函数会被随机获取，我们可以通过制定参数类型的方式来确定我们要获取的函数具体是哪一个，下面的例子中就有这个问题的体现。后面还会有一个函数的重载的问题，有待求证。\n获得了函数，接下来就可以做调用了， invoke函数参数列表也是可变的，第一个参数是执行函数的实例，如果是静态函数第一个参数就是null。这里我是先new了一个实例，然后传进去的，一般也可以在第一个参数的位置上写class1.newInstance()，然后就是参数列表了，按照与原函数参数顺序一致的顺序填进去就可以了。我在例子中用的是另外一种方式，也是由于目标函数的参数列表并不是普通的参数导致的，这也是一个坑点。\n如果你要调用的函数有一个可变长的参数，你就得绕个弯。一般我们调用可变长参数的函数的时候就是传一个数组进去就可以了，但是这里并不可以，如果参数位置是一个数组的话就会报IllegalArgumentException: wrong number of arguments。然后就发现这个invoke本身就是一个参数可变长的函数，所以当我们把参数传进去之后被JVM拆成了单项，这样再往我们要调用的函数里传的时候就会参数数量不一致。这个是由于JVM会做拆分导致的，为了避免这个问题就把参数搞成JVM不会拆分的数据结构，这样做个整体传进去就可以了。下面的代码里就是使用Object来解决这个问题，可能也有其他的方式。\npackage com.paladnix /** * Created by paladnix on 17-7-17. */ public class TestReflect { public static void main(String[] args) throws Exception { String className = \u0026#34;com.paladnix.TestReflect\u0026#34;; String methodName = \u0026#34;exec\u0026#34;; Class\u0026lt;?\u0026gt; class1 = Class.forName(className); TestReflect testInstance = new TestReflect(); Method method = class1.getMethod(methodName, String.class); // 调用exec(String args) // Method method = class1.getMethod(methodName, String[].class); // 调用exec(String... args) String[] params = new String[3]; params[0] = \u0026#34;123\u0026#34;; params[1] = \u0026#34;234\u0026#34;; params[2] = \u0026#34;345\u0026#34;; Object[] p = new Object[]{params}; System.out.println(method.invoke(testInstance, \u0026#34;2\u0026#34;)); // 调用exec(String args) // System.out.println(method.invoke(testInstance, p)); // 调用exec(String... args) } public String exec(String... args) { StringBuilder ret = new StringBuilder(); for(String param : args){ ret.append(param+\u0026#34;*\u0026#34;); } return ret.toString(); } public int exec(String args) { return 1; } } 上面提到的函数重载的问题，如下的两个函数：\n/* Method - 1 */ public String exec(String a, String... args) { StringBuilder ret = new StringBuilder(); for(String param : args){ ret.append(param+\u0026#34;*\u0026#34;); } ret.append(a); return ret.toString(); } /* Method - 2 */ public int exec(String args) { return 1; } /* Method - 3 */ public String exec(String... args) { return \u0026#34;s\u0026#34;; } 其理由很简单，当调用语句是exec(\u0026quot;aa\u0026quot;) 的时候应该去调用哪一个？其实，这个问题只存在于方法3和方法1中，他们与方法2之间区分是很明确的，在调用的时候是遵循了正则表达式中*和+的原理，如果只有一个参数就调用一个参数的那个，如果两个就去调用多的那个。但是在方法1和3之间，就无法区别了，两个参数列表都符合，这就无法调用，虽然函数本身没有编译错误，但是一旦使用，就会有编译错误。\n"},{"id":90,"href":"/posts/java/java-2/","title":"Java 基础数据结构","section":"Java","content":"最近在高频率的开新坑，所以博客也就高频率的开新东西，但是由于精力有限而且需求不是很大，所以在很多问题上暂时是不求深解的。浅尝辄止，还要去快攻下一个堡垒。但是以后都是要补回来的。。\n但是这个应该不是浅尝，因为会经常用到。\nString # 其构造方法比较特殊，可以直接等于赋值，也可以用严格的Java面向对象的写法。\n构造 # String s = \u0026#34;abc\u0026#34;; s = \u0026#34;abc\u0026#34; String s = new String(\u0026#34;abc\u0026#34;); char[] data = {\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;}; String s = new String(data); String str = s.subString(1,2); //start from 1, length=2 方法 # charAt(int ); length(); replace(char old, char new); // 常见的对象转换成字符串与转换回去的问题。 // 待补充 String对象是不可改变的。每次使用 System.String类中的方法之一时，都要在内存中创建一个新的字符串对象，这就需要为该新对象分配新的空间。在需要对字符串执行重复修改的情况下，与创建新的 String对象相关的系统开销可能会非常昂贵。如果要修改字符串而不创建新的对象，则可以使用System.Text.StringBuilder类。例如，当在一个循环中将许多字符串连接在一起时，使用 StringBuilder类可以提升性能。\nStringBuilder # 其一般使用方式很简单。\nStringBuilder sb = new StringBuilder(); sb.append(\u0026#34;abc\u0026#34;+\u0026#34;bbc\u0026#34;); sb.append(1.0); System.out.println(sb.toString()); 至于StringBuffer，可以理解为线程安全的StringBuilder。Builder的是非线程安全的，Buffer是安全的。所以在单线程的时候就可以使用StringBuilder。在速度上是 Builder \u0026gt; Buffer \u0026gt; String 。\nMap # 在Java中Map是一个接口，实现这个接口的类有那么几个常用的，分别是：EnumMap, HashMap, HashTable, IdentityHashMap, LinkedHashMap, WeakHashMap, TreeMap, SortedMap and more.\n常用方法 # public interface Map\u0026lt;K, V\u0026gt; Map\u0026lt;String, List\u0026lt;String\u0026gt;\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); clear(); put(K, V); get(K); HashMap和Hashtable的区别 # HashMap和Hashtable都实现了Map接口，但决定用哪一个之前先要弄清楚它们之间的分别。主要的区别有：线程安全性，同步(synchronization)，以及速度。\nHashMap几乎可以等价于Hashtable，除了HashMap是非synchronized的，并可以接受null(HashMap可以接受为null的键值(key)和值(value)，而Hashtable则不行)。 HashMap是非synchronized，而Hashtable是synchronized，这意味着Hashtable是线程安全的，多个线程可以共享一个Hashtable；而如果没有正确的同步的话，多个线程是不能共享HashMap的。Java 5提供了ConcurrentHashMap，它是HashTable的替代，比HashTable的扩展性更好。 另一个区别是HashMap的迭代器(Iterator)是fail-fast迭代器，而Hashtable的enumerator迭代器不是fail-fast的。所以当有其它线程改变了HashMap的结构（增加或者移除元素），将会抛出ConcurrentModificationException，但迭代器本身的remove()方法移除元素则不会抛出ConcurrentModificationException异常。但这并不是一个一定发生的行为，要看JVM。这条同样也是Enumeration和Iterator的区别。 由于Hashtable是线程安全的也是synchronized，所以在单线程环境下它比HashMap要慢。如果你不需要同步，只需要单一线程，那么使用HashMap性能要好过Hashtable。 HashMap不能保证随着时间的推移Map中的元素次序是不变的。\nList # 这个是有一个类一个接口，类是awt中的东西我们就不看了。就只看作为接口，那些东西实现了这些接口，常用的用法就好了。这个接口集成了Collection和Iterable的接口，所以总的来说。 常用的类有：ArrayList， LinkedList。\nList:元素是有序的(怎么存的就怎么取出来，顺序不会乱)，元素可以重复（角标1上有个3，角标2上也可以有个3）因为该集合体系有索引， ArrayList：底层的数据结构使用的是数组结构（数组长度是可变的百分之五十延长）（特点是查询很快，但增删较慢）线程不同步 LinkedList：底层的数据结构是链表结构（特点是查询较慢，增删较快） Vector：底层是数组数据结构 线程同步（数组长度是可变的百分之百延长）（无论查询还是增删都很慢，被ArrayList替代了） 方法 # List\u0026lt;String\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); add(index, Value); addAll(index, Collection); remove(index); set(index, Value); get(index); subList(from, to); // [from, to) 有一些LinkedList的东西暂时用不上就先不写了。\n以上的几个东西都有迭代器的使用，可能会单开一篇来写迭代器的内容(还有C++的那部分)。\n"},{"id":91,"href":"/posts/java/maven-1/","title":"Maven","section":"Java","content":"使用maven已经是不可避免的事情了，如果你是个java工程师的话。并且，使用maven基本上是你最好的选择。但是我并不喜欢用IDE来集成maven，这算是强迫症，命令行强迫症。\nMaven 是什么？ # 传说他的功能十分强大，目前我感受到的是如下几个功能：\n自动构建项目结构，根据不同的框架需求 自动包依赖管理 自动编译工程 自动启动测试 总而言之就是恰到好处的做了你觉得很麻烦又没有必要自己做的事情。 安装 # 跟JDK是一个思路的，在环境变量中添加M2_HOME即可。\n使用 # # 创建Java Web 项目 mvn archetype:generate -DgroupId=com.hello -DartifactId=hello -DarchetypeArtifactId=maven-archetype-webapp # 生成项目 mvn install # 发布到tomcat # 复制生成的./target/xxx.war到tomcat目录下的webapps中去，如果不能访问就重启一下tomcat。 上述是将项目自带的helloworld页面显示出来，我们自己使用会用到一个更核心的方法\u0026ndash;配置文件。\npom.xml # 这个配置文件是maven的核心。\n在创建好的文件夹中有一个pom.xml 这里的内容分成两部分，一部分是你的项目基本信心，叫啥，啥版本的等等；还有一部分是我们要配置的部分。这一部分又分成好几部分，有依赖关系(dependencies)、生成(build)等等。\n下面是一个Maven的基本结构\n\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;!-- The Basics --\u0026gt; \u0026lt;groupId\u0026gt;...\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;...\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;...\u0026lt;/version\u0026gt; \u0026lt;packaging\u0026gt;...\u0026lt;/packaging\u0026gt; \u0026lt;dependencies\u0026gt;...\u0026lt;/dependencies\u0026gt; \u0026lt;parent\u0026gt;...\u0026lt;/parent\u0026gt; \u0026lt;dependencyManagement\u0026gt;...\u0026lt;/dependencyManagement\u0026gt; \u0026lt;modules\u0026gt;...\u0026lt;/modules\u0026gt; \u0026lt;properties\u0026gt;...\u0026lt;/properties\u0026gt; \u0026lt;!-- Build Settings --\u0026gt; \u0026lt;build\u0026gt;...\u0026lt;/build\u0026gt; \u0026lt;reporting\u0026gt;...\u0026lt;/reporting\u0026gt; \u0026lt;!-- More Project Information --\u0026gt; \u0026lt;name\u0026gt;...\u0026lt;/name\u0026gt; \u0026lt;description\u0026gt;...\u0026lt;/description\u0026gt; \u0026lt;url\u0026gt;...\u0026lt;/url\u0026gt; \u0026lt;inceptionYear\u0026gt;...\u0026lt;/inceptionYear\u0026gt; \u0026lt;licenses\u0026gt;...\u0026lt;/licenses\u0026gt; \u0026lt;organization\u0026gt;...\u0026lt;/organization\u0026gt; \u0026lt;developers\u0026gt;...\u0026lt;/developers\u0026gt; \u0026lt;contributors\u0026gt;...\u0026lt;/contributors\u0026gt; \u0026lt;!-- Environment Settings --\u0026gt; \u0026lt;issueManagement\u0026gt;...\u0026lt;/issueManagement\u0026gt; \u0026lt;ciManagement\u0026gt;...\u0026lt;/ciManagement\u0026gt; \u0026lt;mailingLists\u0026gt;...\u0026lt;/mailingLists\u0026gt; \u0026lt;scm\u0026gt;...\u0026lt;/scm\u0026gt; \u0026lt;prerequisites\u0026gt;...\u0026lt;/prerequisites\u0026gt; \u0026lt;repositories\u0026gt;...\u0026lt;/repositories\u0026gt; \u0026lt;pluginRepositories\u0026gt;...\u0026lt;/pluginRepositories\u0026gt; \u0026lt;distributionManagement\u0026gt;...\u0026lt;/distributionManagement\u0026gt; \u0026lt;profiles\u0026gt;...\u0026lt;/profiles\u0026gt; \u0026lt;/project\u0026gt; Maven Coordinates 坐标 # groupId:artifactId:version这三个字段值是定位一个包不可缺少的坐标构成：组织名：项目名：版本号。\npackaging # 打包方式，主要是jar、war。\n##依赖\u0026ndash;dependencies 基本上主流的包都有maven的库，所以基本上在官方的文档中也都能找的到，只要将其对应的部分配置进来就可以了，举个例子。\n\u0026lt;!-- spring boot --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- jersey --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-container-servlet\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; exclusion # 排除包依赖，有些包不希望使用某些包作为依赖，就加到其对应的exclusion中。这是因为有写包之间是冲突的，某个包使用的一个包，这个包是与另一个冲突的，所以在引入这个包的时候就得屏蔽其冲突包。\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-embedder\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt; \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-core\u0026lt;/artifactId\u0026gt; \u0026lt;!-- \u0026lt;groupId\u0026gt;*\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;*\u0026lt;/artifactId\u0026gt; --\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt; ... \u0026lt;/dependencies\u0026gt; 当你需要使用某些包的时候，就可以去这里搜索，获得其对应的maven配置代码，粘贴进来就可以了。\n下一次补充maven自动构建过程。\n"},{"id":92,"href":"/posts/java/jersey/","title":"jersey","section":"Java","content":"jersy是一个Web Service的框架，据说是符合RESTful架构的一种框架，这是一种新的思路，而不是新的技术，是对于前端的各种技术而言，所设计的后台实现方式，力图以一种统一的方便的方式组织为前端提供数据。 jersey的官网.\n此次接触这个框架是业务需要了，但是，觉得这个框架比较简单，正好也有时间，所以就做一个学习实验，探索一下在资源短缺的情况下如何学习一个新的东西。事实上资源也确实不是很多，这一次主要依靠官方文档学习使用。\n原本打算直接上代码的，但是在官网上看了一会后就发现有好多名词解释的问题。那就先来看几个名词。\n首先第一个就是JAX-RS，这是JAVA EE6引进的新技术，全称Java api for RESTful Web Service. 主要是使用了注解的形式来简化Web开发和部署。然后跟Jersey的关系是Jersey实现了JAX-RS的框架接口，并且扩展了更多的东西，提供了自己的API。\n然后学习Jersey的第一步就是搞懂他的路由方式，在这里就是注解了。\n在讲注解之前还有一个不是很重要的名词：POJO(Plain Old Java Object), 称之为简单一般Java对象，这个概念是与JavaBean做区分的。其实没有什么必要，引用Martin Fowler的一句话：\n“我们疑惑为什么人们不喜欢在他们的系统中使用普通的对象，我们得到的结论是——普通的对象缺少一个响亮的名字，因此我们给它们起了一个，并且取得了很好的效果。” ——Martin Fowler\n所以事实上也就是个名词，所谓简单Java对象就是不包含业务逻辑的对象，一般用于描述数据实体。具体的区别等到写JavaBean的时候就看出来了，这里不讲了。\n在我手中的项目使用了其中的两个包，maven代码如下：\n\u0026lt;!-- jersey --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.containers\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-container-servlet\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jersey-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 可以看到一个是servlet的Container，另外一个是client客户端。具体的用法，等到用到再说。\n注解路由 # 这里用的路由就是JAX-RS的规范。（一次写不完，慢慢补充）。\n@Path # 这个注解的原文解释非常好，所以有时间的还是去看一下原文是怎么写的吧，下面我就结合自己理解写一下。\n这个@Path注解的内容是一个相对的URI路径，由其注解的类会被相应的路径访问到。\n在下面这个例子中可以看到，这个类被一个@Path注解为\u0026quot;printers\u0026quot;，当URL路径为/printers的时候就会路由到这个类中，那么这个类有那么多函数，调用那个函数呢？下面还有子路径以及路径的通信方式。\n首先HTTP-Methods都是被支持的，常用的有：\n@POST @GET @PUT @DELETE 并且对于每个函数都可以进行@Path的进一步注解，有过Web开发经验的人都知道是怎么玩的。如果你的URL路径是/printers/list， 就会定位到getListOfPrinters()函数。同理可知其他的用法。 需要说的可能是如果一个函数没有注解而其他的函数有注解，在路径为printers的时候就会定位那个没有注解的，因为其他的都是精确匹配的，按照精确匹配无法匹配到其他的函数，这个是不精确匹配的，所以就过来了。 对于/，开始和结尾的位置可以加可以不加，都能够被解析。除此以外，这里还有些内容你可能看不太懂，下面会讲。\n@Path(\u0026#34;/printers\u0026#34;) public class PrintersResource { @GET @Produces({\u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34;}) public WebResourceList getMyResources() { ... } @GET @Path(\u0026#34;/list\u0026#34;) @Produces({\u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34;}) public WebResourceList getListOfPrinters() { ... } @GET @Path(\u0026#34;/jMakiTable\u0026#34;) @Produces(\u0026#34;application/json\u0026#34;) public PrinterTableModel getTable() { ... } @GET @Path(\u0026#34;/jMakiTree\u0026#34;) @Produces(\u0026#34;application/json\u0026#34;) public TreeModel getTree() { ... } @GET @Path(\u0026#34;/ids/{printerid}\u0026#34;) @Produces({\u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34;}) public Printer getPrinter(@PathParam(\u0026#34;printerid\u0026#34;) String printerId) { ... } @PUT @Path(\u0026#34;/ids/{printerid}\u0026#34;) @Consumes({\u0026#34;application/json\u0026#34;, \u0026#34;application/xml\u0026#34;}) public void putPrinter(@PathParam(\u0026#34;printerid\u0026#34;) String printerId, Printer printer) { ... } @DELETE @Path(\u0026#34;/ids/{printerid}\u0026#34;) public void deletePrinter(@PathParam(\u0026#34;printerid\u0026#34;) String printerId) { ... } } 注解除了简单的字符串以外，按照JAX-RS的规范，在路径中可以设定变量。也就是上面看到的@Path(\u0026quot;{printerid}\u0026quot;)的用法，这里的话花括号中的部分就是变量，是用URL的方式传参过来的。对应的在其函数的定义中，参数列表中就对这个参数做了声明：@PathParam(\u0026quot;printerid\u0026quot;)，就作为参数传进来了。对于参数，还可以进行正则匹配，格式如下：@Path(\u0026quot;{name: [a-zA-Z]*}\u0026quot;)，则如果参数符合大小写字母的限制就能够正确匹配，否则就是404了。\n@Produce # 很明显这个注解是描述了这个方法或是类可以生产什么东西，什么类型的东西，也就是返回给Client什么类型的内容，如果是text/html，则返回的就是一个页面。这个东西在HTTP请求的accept字段会有限制，如果accept注明了接受什么类型的数据，那么就会选择对应的生产者去调用，在其他注解方式相同的情况下。\n可以选择多个MIME媒体类型。\n@Consumes # 消费者，就是这个类或方法可以接受什么媒体类型的数据，例如:@Consumes(MediaType.APPLICATION_JSON)就说明该函数可以接受Json类型的数据。具体的用法还没有用过，暂时不写。\n@POST # 如果我们用jersey来做API的话，一般就是将POST的报文转换成JSON字符串整个传过来。这个时候参数直接就传做函数的参数，不需要做什么说明。事实上不做注解说明的函数就是被默认塞进来的参数。\n还有一种是表单参数。这个目前没有做过，不过我猜也是一样的。\nJersey Client # 做API最常用的就是Client了，一个以http协议为基础的请求发送端。\nClient client = ClientBuilder.newClient(); WebTarget target = client.target(url); // put Response response = target.request().accept(MediaType.APPLICATION_JSON_TYPE).put( Entity.entity(obj.toJSONString(), MediaType.APPLICATION_JSON_TYPE)); // post Response response = target.request().accept(MediaType.APPLICATION_JSON_TYPE).post( Entity.entity(inputJson, MediaType.APPLICATION_JSON)); // get (参数放在url中) Response response = target.request().get(); if(response == null || response.getStatus() != 200 ) // 请求失败 String detail = response.readEntity(String.class); JSONObject object = JSON.parseObject(objString); client.close(); 基本用法就是这样了，可以用来对自己的API进行测试，也可以去调其他的API。\njesey的几种参数注解 # 在写接口的时候接受的参数有这么几种，上面已经介绍过了@PathParam， 下面就系统的介绍一下几种参数。\n@PathParam() # 可以认为是定义在路径中的一个变量。程序提取对应路径位置的字符串作为对应的参数。使用方式在上面有所以不详细介绍了。\n@QueryParam() # 该参数用于获取Get请求中的查询参数，他和上一个的区别是它是通过URI中的？符号来实现的。\n@GET @Path(\u0026#34;/user\u0026#34;) @Produces(\u0026#34;text/plain\u0026#34;) public User getUser(@QueryParam(\u0026#34;name\u0026#34;) String name, @QueryParam(\u0026#34;age\u0026#34;) int age) { ...} 当请求是：http://localhost:8080/user?name=cesar\u0026amp;age=21时会被这个方法捕获。\n@FormParam() # 顾名思义就是表单中的数据\n@POST @Consumes(\u0026#34;application/x-www-form-urlencoded\u0026#34;) publicvoid post(@FormParam(\u0026#34;name\u0026#34;) String name) { // Store the message } 默认参数值@DefaultValue # 当你希望在函数获取参数时参数有一个默认值，那么就可以使用该注释，它的使用方法如下\n@GET @Path(\u0026#34;/user\u0026#34;) @Produces(\u0026#34;text/plain\u0026#34;) public User getUser(@QueryParam(\u0026#34;name\u0026#34;) String name, @DefaultValue(\u0026#34;26\u0026#34;) @QueryParam(\u0026#34;age\u0026#34;) int age) { ...} 使用Map的参数@Context # 在一个大型的server中，由于参数的多变，参数结构的调整很容易遇到问题，这时候就可以考虑使用@Context来进行注释了。例子如下：\n@GET public String get(@Context UriInfo ui) { MultivaluedMap\u0026lt;String, String\u0026gt; queryParams = ui.getQueryParameters(); MultivaluedMap\u0026lt;String, String\u0026gt; pathParams = ui.getPathParameters(); } 接下来你会用到遍历map和删除map元素的操作来做一些处理。\n"},{"id":93,"href":"/posts/idea/ideakey/","title":"IDEA常用快捷键","section":"ID Ea","content":" \u0026lt;Ctrl\u0026gt;+ \u0026lt;click\u0026gt; 定位到变量声明处\n\u0026lt;Ctrl\u0026gt; + \u0026lt;\\B\u0026gt; 返回上一次浏览的位置\n\u0026lt;Ctrl\u0026gt; + \u0026lt;Alt\u0026gt; + \u0026lt;L\u0026gt; 自动对齐\n\u0026lt;Ctrl\u0026gt; + \u0026lt;F12\u0026gt; 显示类成员\n\u0026lt;Alt\u0026gt; + Left\\Right 切换标签页\n\u0026lt;Alt\u0026gt; + \u0026lt;Enter\u0026gt; 光标在错误上调出自动错误处理列表\n\u0026lt;Ctrl\u0026gt; + \u0026lt;-\u0026gt; 折叠光标所在的方法\n\u0026lt;Ctrl\u0026gt; + \u0026lt;Shift\u0026gt; + \u0026lt;-\u0026gt; 折叠所有方法\n\u0026lt;Ctrl\u0026gt; + \u0026lt;=\u0026gt; 展开光标所在的方法\n\u0026lt;Ctrl\u0026gt; + \u0026lt;Shift\u0026gt; + \u0026lt;=\u0026gt; 展开所有方法\n"},{"id":94,"href":"/posts/c++/c-oop-3/","title":"C++ OOP--const、引用、指针","section":"C","content":"继续梳理C++中的问题， 今天梳理的是最基础的几个概念，也是比较麻烦的概念。\n引用 # 引用是一个变量的别名，声明时必须初始化，而且之能在初始化的时候绑定一个变量对象。\n引用不能绑定在引用上，因为引用本身不是对象。 普通引用不能绑定到立即数上，因为立即数不是对象，但是常量引用是可以的。 普通引用不能引用类型不同的对象。 以上的普通引用是相对于常量引用来说的，下面会介绍到。\n指针 # 这个概念最简单，他不是是一种数据类型，他的数值是个地址，可以用解地址符*来直接操作指向的地址内的变量。\n指针有下面四种状态:\n指向一个对象; 指向紧邻对象的下一个位置； 空指针(nullptr, 避免使用NULL，nullptr可以被转为任意类型的指针); 其他指针装态(无意义的状态)； const 常量 # const 修饰的常量，默认是文件内有效，如果想在多文件内可用，就加extern修饰。\n这个和其他的东西一结合就比较烦。\n首先const是声明常量的作用，用其修饰的变量值必须初始化且不可更改。这就是普通常量了，很好理解。\nconst 引用 # 如果你声明了一个引用，并且这个引用是const修饰的，那么，你要知道两个事情：第一，引用不能绑定到其他变量了；第二，用这个引用不能改变做引用的对象的值了，但是不影响那个变量通过其他途径改变，改变后的值一样会在引用中表现出来。\n如果你引用的对象是个常量，那么这个引用也必须是常量。反过来没有这个限制。\nconst 指针 # 指针这块又有两种，因为指针是可以改变其指向的对象的，并且其指向的对象也是可以更改的。就出现了指针常量(pointer to const) 和 常量指针(const pointer)。汉字理解起来没有英文来的准确，所以下面不用常量指针和指针常量来表述。\npointer to const 很明显是指向的对象是个常量，而指针不能够修改这个对象的值。\nconst pointer 很明显就是这个指针是个常量，只能指向这个固定的内存，但是可以通过其修改对象的值。\n在定义上如下：\nint a; // pointer to const const int *p1 = \u0026amp;a; // 等同于 int const *p = \u0026amp;a; // const pointer int *const p2 = \u0026amp;a; 所以可以看出来，const修饰的就是紧跟其后的内容，在pointer to const的定义中可以认为*p 指代指向的对象；而const pointer中const修饰的是p；\nconst 函数 # 以上是const的基础知识，在下面的讨论中依然有效。\nconst参数 # const的参数无非就是希望函数不要改变这个参数的值，在传值的时候没有什么意义，但是如果传过来的是个引用或是指针就很有必要考虑是否允许函数修改值的问题。\n函数在使用实参初始化形参列表的时候，会忽略顶层const（顶层const指等号左边对象不可更改的const修饰符，底层const指等号右边的对象不更改的const修饰符即pointer to const）。也就是说在传递参数的时候我们可以使用非常量传递给常量参数。\n在传常量引用的时候自然就是不希望通过这个引用修改值。尤其是当一个参数是引用的时候，如果要传立即数就必须是const修饰的，否则编译不会通过。 一般建议尽量使用常量引用，只要能确定函数不会改变该参数的值就可以声明为常量引用。\n顺带提一下数组传参的注意事项。首先就是肯定是传指针或引用，数组不允许拷贝传参。指针就不说了，如果不能改变值就用const修饰，否则就声明成正常的类型。要说一下的就是引用。 对于数组的引用传参来说，维度也是参数的一部分，正确的声明方式如下：\nvoid func(int (\u0026amp;a)[100]){...} 注意括号，一定是这样声明，因为你引用的是a这一个数组，而不是一个引用数组a[100]。\n传递二维数组，数组本质上没有维度之分，二维数组就是第一维存放指针，第二维是正常的数组。所以在声明参数的时候第一维不必管，但是第二维及以后的维度要注明长度。\nvoid func(int (*a)[][10]){...} const 修饰成员函数 # 在成员函数的参数列表的后面使用const修饰符说明该函数不会更改成员变量。\nconst 修饰函数返回值 # 这个今天不想讨论了，之后写一个函数的整理，在其中讨论这个问题比较好。\n最后，要多用const。\n关于C++修饰符的规则 # 整理了几天，整理来整理去，发现学习的过程中反反复复的就在纠结几个修饰符。然后有一些自己的思考。\n修饰符并不都是一样的，有那么几种类型，比如有修饰类型的、有修饰权限的等。但是无论是哪种修饰符，其要修饰的主体是一样的，就是我们定义的变量、函数、类。 说白了，C++的关键字，其自己没有异议，是什么就是什么。但是我们自己定义的变量就不一样了，我们要赋予他们不同的身份、功能、作用、权限，而这一切都要靠修饰符来明确。\n举个例子： const int *p = \u0026amp;a;，这个中有两个或者说有三个修饰符，两个运算符。三个修饰符分别是：const、int、*，并且其作用对象都是p。 但是不能单纯的拆开来分别修饰，因为修饰符的顺序会影响其修饰的结果，总的来说，每个修饰符都是在修饰其以后的代码。 上面这句代码我们其实倒着来读就是他的正确意义：这是一个变量，名字叫p，而且这是一个指针变量，这个指针是指向int类型变量的，且通过其指向的int类型变量是不可变的。\n换个例子也是一样的: int * const p = \u0026amp;a;: 这是一个变量，名字叫p，而且这个p的值是不可变的，这个p是一个指针，指向int型变量。\n为什么会这样呢？因为编译器需要按照固定的规则来解析这个3个修饰，甚至来说，绝大多数的修饰符都是按照一个规则来解释的，所以在设计修饰符的时候就按这样的规则设计，这个规则就是每个修饰符修饰其后的代码，且修饰的最终对象是我们设的变量名。\n上面还有几点其实有意思的。就是这个指针是不是个类型的问题，当然不是了。 *本身就是一个修饰符，也可以是个操作符，但是绝对没有int*这个类型，所以写声明代码的时候就将其当成修饰符来写就好了。同样的还有一个问题，就是引用是不是个类型呢? 当然也不是啦。一样都是修饰符。\n"},{"id":95,"href":"/posts/c++/c-oop-2/","title":"C++ OOP--函数解析过程","section":"C","content":" 类的作用域 # 名称查找优先，对于编译器来说，优先寻找名称一致的函数，再关心类型的问题。\n编译器在进行名称查找的顺序: 直接类定义 -\u0026gt; 父类定义 -\u0026gt; 祖宗类定义。但是，搜索顺序是按照静态类型开始的，结合上面的动态绑定，如果你的指针类型是父类，那么即使实体是个子类也不会在子类域中搜索，直接从父类开始搜索，因为编译阶段无法做动态绑定。\n隐藏\u0026amp;重载\u0026amp;覆盖 # 这个概念刚开始学C++的人可能会比较迷。\n隐藏 # 隐藏是在继承中出现的概念。基类与派生类有一个同名函数，则无论是否参数类型一致，基类的函数都会被隐藏掉。这个隐藏的意思，与Java中的override是否一致，我觉得不一致，但是效果一致。因为编译器在搜索名字的时候首先搜索派生类的函数，然后看参数，如果参数类型对的上就调用，对不上就报错。所以根本调用不到基类的函数，实现了隐藏。但是，C++中基类的函数还是存在的，Java中是直接将父类的函数段重写，父类的函数完全从代码段消失了。 既然还存在，就意味着可以访问。使用using关键字调用函数可以直接调用基类被隐藏的函数，可以说using改变了编译器名字查找的顺序。\n对于虚函数，我们要求参数类型必须一致，就是这个原因。要实现动态绑定就必须使得当查找到函数名时，此函数可以被调用，而不是报个错说参数不一致。\n这个规则是可以类推出来的，从命名上我们就可以窥探出这个东西有什么特质。\n比如作为成员函数，就是可以被隐藏，无论是虚函数还是普通函数都是可以的。虚函数可以被普通函数隐藏，普通函数也可以被虚函数隐藏，其他一些概念一样可以用命名来推导出来。\n重载 # 重载是对于函数来说的，与类间继承没有关系。对于一个普通函数，即不存在任何的类中的独立函数，重载的概念很清晰，就是相同的函数名，不同的参数列表；\n对于成员函数来说，在同一个类中，可以重载，重载的概念也是一样的。\n覆盖 # 覆盖与上面的东西又不一样，但是这个不是C++中的重点概念。覆盖是对于基类的虚函数来说的，派生类写一个名称、参数类型完全相同的函数，可以实现覆盖，其实就是虚函数的那一套东西。\n只要分清楚，隐藏和覆盖是在父子间作用的，重载是同级内作用的就可以了。\n那么有一个问题，很恶心，哈。 就是基类的虚函数被重载了，有很多个版本，子类在覆盖的时候，可以选择覆盖哪个版本。一样是使用using修饰符来将基类的函数作用域同步到当前作用域上来，这样只有对需要覆盖的版本进行覆盖就行了，其他的就使用基类的实现。\n"},{"id":96,"href":"/posts/c++/c-oop-1/","title":"C++ OOP基础--动态绑定","section":"C","content":"面向对象其实就是那样，都差不多，不一样就是关键字还有一些奇怪的机制问题，总的来说实现的东西都是一样的。\n虚函数 # 对应Java的抽象函数。但是略有区别。 虚函数在定义的时候使用关键字virtual来修饰声明，但是不一定是没有实现的，可以指定一个已经是实现的函数为虚函数。虚函数最主要的定义是使得每个继承他的子类都实现自己的版本。并且虚函数是实现C++动态绑定的关键。 虚函数只能声明在类的内部。\n动态绑定 # 所谓动态绑定就是，有些函数并不是在编译的时候就知道要去调用那个函数的，而是在真正运行的时候才能根据变量的类型去调用对应的函数。这个实现就是对于基类的虚函数，子类也实现一个版本（子类在实现的时候不需要指定函数为虚函数，因为继承过来的函数就是虚函数，是可以传递的），这样对于同一个函数就有两个版本，当我在调用的时候使用指针调用或引用调用（注意必须是这两种调用之一的方式才会有动态绑定的效果，其他都是在编译阶段就能够确定下来。）就可以实现动态绑定。\n由于虚函数是在执行的时候才调用，所以在编译阶段就有些错误报不出来，比如如果我们没有实现某个子类的虚函数，在调用的时候就没有函数去执行，所以所有的虚函数都必须被定义，而不仅仅是声明，普通的函数只要我们永不到就可以不进行定义。\n引用和指针调用 # 所谓引用和指针调用，是指函数中关于虚函数的调用对象是作为引用参数或者是指针参数传进去的，这样就需要根据参数的类型来调用不同版本的虚函数。这里就要说一下基类与派生类之间的类型转化问题，正是因为其二者可以进行类型转化，所以在参数列表中的类型并不能唯一限定参数的类型，才有了虚函数调用时的动态绑定。\n类间类型转换 # 子类中有一部分是来自与基类的，这一部分可以被单独利用。也就是说，一个子类，我们也可以把他当作他的某个基类来使用，使用的时候只用到基类的部分。也就是说，我有一个基类的指针，我就可以指向这个子类，此时，指针就操作子类的基类部分。这就是从派生类到基类的类型转换。\n反过来就是不行的，可想而知，多的东西可以不要，少了东西就会有问题，所以不存在从基类到派生类的转化。同时我们也就明白了，如果你要对于一个虚函数动态绑定，在调用函数的对象的类型声明的时候就要声明为基类的类型，这样当你传入一个子类的引用的时候，该引用就会转换为子类，进而去调用子类的虚函数实现；如果你写声明的时候声明为了子类的类型，就没有办法动态绑定了，因为反向没有办法转换。\n虚函数覆盖 # 子类要实现自己的虚函数版本就要对基类的虚函数进行覆盖，override，又是这个熟悉的东西。覆盖当然就要参数类型完全一样，参数不一样的那是重载，是不同的函数。书上说，一般我们都是要进行覆盖而不是重载，但是有的时候我们会搞错参数列表的顺序等细节，所以，你可以在函数声明的参数列表后加override说明符来告诉编译器，你是要覆盖虚函数的，如果有细节错误就告诉我！\n如果你在后面加上了final修饰符，就意味着，这个虚函数不希望再被覆盖了。\n关于虚函数的默认参数，不同版本可能会有不同的默认参数值，但是在默认参数的选取上，是依据静态类型决定的，也就是说不能做到动态绑定，调用函数的对象定义成什么类型就用什么默认值。如你调用函数的对象是基类的引用，那么即使你最后执行的是子类的函数，默认值也是基类的默认值，所以这个就会出现隐蔽的问题。所以安全起见，默认参数一致最好。\n猜想 # 同时从这里我们也可以窥探出编译器的原理。对于一个函数覆盖来说，函数的默认值必须是在编译阶段就写进机器码中的，尽管你有两个版本的函数，编译器会对两个函数分别编译，但是默认值存储的实现是与函数编译分开的。这里只是猜测，对于函数的默认值，其实编译器可以将其存储在对应的栈位置上，也可以将其转成一个赋值命令存储在函数代码段中，这两种理论上都可以实现默认参数的功能，但是从编译器的定义角度，参数是单独存放在数据段的，而不在代码段，那么在编译的时候就会根据你参数的字面类型进行设定，而无法进行动态绑定。这个应该是C++的一个设计缺陷，最初设计函数编译的时候没有动态一说，就直接写进数据段了，等到出现动态绑定的时候沿用之前的函数处理的方式，就无法实现绑定。（不知道这个思路对不对，以后有时间考证下）。\n回避动态绑定 # 除了动态绑定，也可以用作用域操作符来强制执行某一类的虚函数版本。\ndouble ans = C-\u0026gt;Base::Update(); 为什么要回避动态绑定，这与类间设计有关。如果基类与派生类关于虚函数功能设定是：基类虚函数处理通用处理，派生类处理剩余子类相关内容，那么对于真的要完整实现功能的时候就要在派生类的虚函数中先调用一下基类的虚函数，再实现派生类的函数剩余部分，所以这时候就要回避动态绑定。\n纯虚函数 # 你的直觉会告诉你这个纯虚函数应该是个只有声明没有定义的函数。没错，这就是纯虚函数，在格式上有一个特点，就是函数声明最后有一个=0标志。这个声明必须在类的内部，并且类内不能对这个函数进行定义，在类外部定义是可以的。\n纯虚函数是在一些设计上必要的。比如我们有一个操作，有4个版本，每个版本根据不同的参数值有不同的动作，那么我们会设计一个基类，并在基类中声明这个函数，但是这个函数明显什么都不能做，而是要等到不同的子类根据自己的方案实现这个函数。所以这时候就声明一个纯虚函数就好了。\n子类只要正常的覆盖这个函数就可以，如果不覆盖就继续往下传递。\n抽象类 # 很熟悉，Java中含有抽象函数的类是抽象类，在这里有纯虚函数的类就是抽象类。并没有什么修饰符，就是个类。\n继承中的友元 # 友元不可继承、不可传递。 派生类的友元不可访问基类中的非公有成员。 "},{"id":97,"href":"/posts/java/java-1/","title":"Java 抽象与接口","section":"Java","content":"在使用Java的过程中最主要的就是接口、继承这些东西。其实概念十分的简单，只是名字特殊了点，设计的技巧性较强。\n之前听到有人在思考抽象类和接口的区别，以及为什么要两个都存在。但是，可能是我的见识太短，并没有这样的疑问。\n抽象 # 面向对象编程抽象是避不开的内容，最经典的动物类，没有任何一种生物你可以说他就是动物，但是就是有动物这个概念，所以动物就是思维的抽象。良好的设计就要这样从抽象一步一步实例化最后具象为实体。 那么对于抽象的类来说，有一些东西就没有办法确定，比如动物的行走是用腿还是用腹？这个在动物类中无法确定，所以就需要先抽象着。\n抽象类用修饰符abstract 修饰，并且抽象类不可以实例化，所以就不能用final来叠加修饰。抽象类可以没有抽象函数，但是有抽象函数的类必须定义为抽象类。\n抽象函数 # 就是只有声明没有定义的函数，声明如下：\npublic abstract boolean Update(); 抽象类 # public abstract class A{ ... } 接口 # 与抽象类最大的不同就是，这并不是个类。接口不是类。所以这两个东西在本质上就不一样，所以我不认为二者有什么好冲突的。\n而且最重要的就是，在Java中类是单一继承的，也就是说一个类只有一个父亲。那么对于从动物类派生出来的陆地动物、水生动物来说是没有什么问题，但是对于一个两栖动物就很尴尬，他没办法从上面的两个类中做继承，你要单独分出一个两栖动物也不是不可以，但是如果在一个系统中这样的复杂类型非常多就非常的麻烦了，然而在C++中是可以多继承的，于是就出现了接口这个东西。\n接口是一种特殊的、完全没有实现的类。其中所有的方法都是没有实现的，且其中的域全都是常量。\n接口的定义 # public interface interfaceName [extends superInterface1, superInterface2, ...]{ // 常量定义(类型已经默认，可以省略不写) [public] [static] [final] type Name = constValue; // 方法定义 [public] [abstract] returnType functionName(params)[throws exceptionList]{ ... } } 在子接口中对父接口的函数可以进行覆盖。\n接口的实现 # public class A implements Interface1, Interface2, ...{ // 必须实现所有的接口函数 } public abstract class A implements Interface1, Interface2, ...{ // 可以不实现，交给自己的子类实现。 } 所以Java使用抽象类和接口的形式来实现了多继承。\n"},{"id":98,"href":"/posts/others/hexo/","title":"Hexo","section":"Others","content":"这是一个经济又快速又好看的博客搭建教程。\n你的博客将会有一个后缀为github.io的域名，并且在该域名下有300M的存储空间。但是，本教程只写给Linux用户，其他用户参考自行摸索，原理一致，操作类似。\n你看到的我的这篇博客就是最后的效果，当然你也可以自行修改样式。\n博客使用Hexo博客生成系统，其优点如下：\n简单快速，无需服务器端架设环境。 可选样式众多，易于修改。 扩展插件众多，且使用方便。 使用markdown语法编写博客，易于上手。 生成博客为纯静态代码，无需运行环境可直接移植，不依赖数据库。 本机环境的准备 # 你需要以下几个软件的环境：\nNode.js Git Hexo 安装node.js # 在安装这个的时候卡了很久，然后才知道自己装的是Node.js, 然而需要的是Node！正确的结果是在命令行输入node -v 如果可以看到版本号就可以了。 正确的安装命令是：sudo apt install nodejs-legacy，害怕。。。就是有这样的操作，当你install nodejs的时候，对不起，这个并不是你要的node.js， 哈，我也很绝望啊！\n然后要安装一下这个npm工具：\n$ sudo apt install npm $ npm -v #看npm版本，如果结果显示版本号则安装成功 安装git # $ sudo apt install git 有的时候在安装完git后依旧在项目中无法使用，后面发布博客到github上面的时候会使用到git，如果报错：Deploy not found git 之类的，就需要再搞一下这个玩意儿！这就是软件版本混乱的锅，想说爱你不容易！\n$ npm install hexo-deployer-git 安装Hexo # $ npm install hexo-cli -g 当然这个在安装的时候也有坑出现各种问题，那就只好去百度了，我是因为前面的东西出问题后来修好后就好了。一般也不会有啥问题了。\n使用 # 其使用逻辑非常简单而且封装很好，命令操作也十分简洁，重点在于配置文件的修改。这是个强配置的框架，事实上好的框架就应该这样，甚至可以将软件由不懂程序设计的人来使用，但是前提得有一个个很清晰的配置文件设计思路以及详细的说明书……\n建立工作区 # $ hexo init Blog $ cd Blog 新建一篇博文 # 在Blog文件夹内执行：\n$ hexo new 文件名(不加后缀) $ hexo new Hello 此时新建了一个文件在source/_posts/Hello.md， 打开文件即可编写内容，内容使用markdown语法。 事实上在第一次初始化博客的时候其中带有一篇示例博文，与你新建的这个文件在同一目录下。你可以先不着急编写文章，先来看一下默认文章的效果。\n本地启动服务 # $ hexo server 随后你在本地浏览器输入localhost:4000 应该就可以看到你的博客。如果你的4000端口被占，请参照命令给出的提示信息操作。\n部署到Github.io # 在讲这个之前必须要说一下，配置文件的使用和Github Page的用法。\nGithub Page # Github提供了这样一个服务，可以做项目的说明博客等，也可以用来做个人主页。\n首先你要在Github上有一个帐号，然后新建一个repository，项目名称必须为YourUserName.github.io。然后你需要在此项目下上传纯静态网页代码。之后可以使用https://YourUserName.github.io来访问这个站点。\n上传代码这件事当然是Hexo一个命令搞定，生成代码也是一个命令搞定，所以不用担心，先来看如何配置Hexo\n配置 # 配置文件路径：Blog/_comfig.yml 打开并修改其中如下几个必要的信息：\ntitle ： 更改为你博客的标题，就是你风骚的昵称。 author： 更改为你喜欢的你的代号。 url： 未来你博客的地址。 root: 这个十分重要，就是你项目所在的文件夹的名称（如果你选择使用github page做站点，就写YourUserName.github.io， 如果你选择使用自己的服务器来做站点，就写你服务器上存放代码的文件夹名称，你会用YourIP/YourRoot的方式来访问，所以你应该知道填写什么了吧）。 #Directory：块下的几行你可以全部打开，但是其中的某些东西需要进一步配置。 theme： 你可以选择你喜欢的主题，更多主题，每个主题都有其自己的详细说明，不再赘述。 deploy： type: git, repo: git@github.com:YourUserName/YourUserName.github.io.git, branch: master。这个配置的就是上传部署的目标地址。也就是你的Github Page 的项目地址。 好了，以上配置做好后就可以尝试第一次上传了。\n上传部署 # $ hexo clean # 清除之前生成的文件 $ hexo g # 生成博客文件 $ hexo d # 部署到`deploy`的目的地址。 然后你可以尝试使用https://YourUserName.github.io 来访问你的博客了。\n你也可以选择在本地测试，使用上面提到的 本地启动服务 即可。\n主题 # 主题非常多，你可以选择你喜欢的主题，并到其详细说明中寻找安装、使用和修改的方法。 每个主题都有自己的配置文件，且配置文件的格式是统一的，所以很方便。\n本博客使用的主题为Next。\n一些人气颇高的主题会有自己的官方网站，上面有更多插件的使用。如果有时间，我会补充该部分内容到该文章中。如果你对此做了整理，我也很乐意讲你的成果添加到本文的附录中。\nThanks.\n多机同步 # 换了公司的电脑再带着自己的电脑写博客有点太low了，最好的方式当然是无牵无挂，有网就能玩的状态，所以就需要多机同步。很自然就想到了github嘛，之前发布的时候是将生成的静态网页发布了github上，但是你的工程源文件并没有同步上去，所以要做的就是将工程文件也搞上去。然后就有两个思路：1. 在io那个仓库新建一个分支，然后把源代码搞到新分支上去。2. 搞个新的仓库，单独放工程源文件。\n由于我的github操作水平有限，在尝试新分支的时候总是出错，所以我就选择了另一种简单粗暴的方式。\n首先在本地初始化建仓库, 在github上建一个仓库，关联起来\n$ git init $ git add . $ git commit -m \u0026#39;init\u0026#39; $ git push origin master 其实就是跟普通建仓库一样的。。。有些东西没有写，其实默认应该是会的，就是添加新机器的ssh_key到github上，ssh-keygen -t rsa -C \u0026quot;你的邮箱地址\u0026quot;，然后复制~/.ssh/id_rsa.pub 到github上就可以了。 不过我在网桑看到了有人将文件夹下的.gitignore文件追加了两行：/deploy_git 和 /public 。如果你直接建仓失败了就这样搞试试。\n然后就是在另一台机器上，现在本地建起hexo的工作区，然后同步数据过来就好了。\n$ git init $ git remote add origin \u0026lt;url\u0026gt; $ git fetch --all $ git reset --hard origin/master 这样就同步好了，接下来每次更新博客流程如下:\n$ git pull $ hexo new XXX $ hexo g $ hexo d $ git add . $ git commit -m \u0026#39;xx\u0026#39; $ git push origin master 搞起来感觉有点麻烦，因为用的是Node这个体系，不熟悉。\n"},{"id":99,"href":"/posts/acm/acmroad/","title":"ACMRoad","section":"Acm","content":"作为ACM的老队员，最经常被问的不是XXX算法的问题，而是“学长我要玩ACM，我该从哪开始？”。这个问题嘛，有超过3个人问就有必要写成文字来回答，正如但凡一个操作需要两条以上命令就可以写成脚本来做一样。\n就不回首往事了，尽管一路走来感慨良多啊。\n新人，也有区别。你是没有程序编写基础的还是有一定代码基础的？有Py基础还是C的基础？有没有算法基础？\n如果你是一个大一新生，且没有学过程序设计，或正在学，那么我建议你花最多2周，把C语言关于文件操作之前的部分学完(文件操作非必要)。不要说2周太短了，如果你打算在ACM竞赛中获得不凡的成绩，就2周。你可能天赋异秉可以花很少的时间学会C语言，这很好，说明你有个好脑子，且可以在搞好ACM的同时兼顾上课。如果你的脑子不是很棒，但是也喜欢，2周时间就必要的做些调整，课该怎么上就要考虑一下了（事实上就算是脑子很好，也要考虑一下）。\n然后你可能要检测一下自己的C语言水平，尤其是在做ACM题目上的水平。此时我建议你去用2周的时间刷掉HDU平台上的第11页的题目，这上面的题目涉及到的算法比较简单，算法对应的C语言程序也比较简单，只是使用到了字符串的处理、数组的使用、结构体的使用等基本语法知识，但是会让你对这些基本知识有翻天覆地的改观，他们很简单，但是可以做出很神奇的动作。这些题目可以让你对C语言的语法更加熟练，甚至到了4岁小朋友说母语的水平一样自然而流畅，同时，当然你因为不会使用高级语法来加快代码编写速度和质量，就像4岁小朋友不会写作文一样。但是仅仅语法熟练只是一方面，同时你会学习到一些更加快速方便的函数，如使用sort()函数来排序而不是自己编写冒泡排序等傻逼的排序函数；你还会接触到强类型语言中变量的数值边界问题、数值精度问题；字符串处理的常见bug；如何编写递归代码等。你还会知道你的电脑一秒钟只能运行大约1e8次的简单数学运算，你会慢慢的学会用计算机的思维方式思考问题的解决办法。同时你还会接触到一些算法，如动态规划等。（此页中有很少的几个题目非常困难，没关系，不要管他们，但你需要完成至少90道题目）\n然后你可以小声的对自己说：“我已经看到了ACM-ICPC的影子了！”。\n然后你需要入门一下。这个阶段你可能会比较痛苦，因为你要做的就是不断的离开你熟悉的几行代码，转而去学习新的算法，写新的代码。而这一切，应该都没有人会仔细的教你。\n到现在为止，你可能都没有学过一个完整的算法。之前做的那些水题都只是思维的开胃菜而已。那么现在你要清楚你必须去认真的、系统的学习一些算法。要能清晰的理出算法的逻辑，快速的编写出高质量且准确的代码，要能眼动查找BUG。不用担心，有人的地方都有路，已经有无数人做过这件事，所以你有章可循。\n在介绍下一站之前，我必须告诉你，ACM比赛使用Linux操作系统编写代码。所以，按照我们的一致希望，我们希望你能从现在开始使用Linux并逐步使用Linux来工作，windows只是个好东西，但不是程序员的玩具，你的玩具是Linux操作系统，比赛统一使用Ubuntu操作系统作为平台，如果你对Linux一无所知，你需要去百度一下了。\n至于如何安装Ubuntu操作系统和如何使用，请见其他博文或直接来实验室寻找学长的帮助（文章目前还没有整合）。\n你需要去Vjudge申请一个帐号，并且开始学习[简单搜索专题]传送门。我们一致建议从这个算法专题开始，因为这里要用到的技能你学习起来会比较快速，因为你的前期技术铺垫已经做好了。其次这里的内容将会在其他的算法中使用到，所以你要从这里开始。这里的学习并没有学习资料，一切资料都在网络上，这里有的只是十几道检验你学习成果的题目，但是，这些题目与你今后比赛中遇到的题目在外形上长的已经很相似了。你大概需要一周多一点的时间来攻克这个专题。当你结束这个专题的时候你应该具备以下几条但不限于此的能力：\n快速编写递归程序。 看到搜索类问题可以快速反应出解决方式并编写代码解决。 快速估算自己方案的时间空间复杂度并决定是否可行。 尝试使用高级一些的语法来编写代码，如C++中的部分内容，包括重载运算符等。 手动调试代码修改BUG而不需要依靠调试工具。 初步熟练使用Vim编写代码，并初步熟悉Linux-Ubuntu操作系统，使用简单命令来操作计算机。 熟练的从网络上寻找资源解决自己的疑问，同时可以快速的看懂别人的相关代码。 了解一些题库。 接下来你或许就不再需要这篇文章的指导了，但是，你离入门还差的远。\n之后的一段时间内，算法还是要继续学习，依旧用这样的专题的形式。同时你也要去接触一下真正的比赛是什么样子，以及，真的强是什么样子。\n以下平台会不定期有比赛，可视个人情况参加： # Codeforces(cf) HihoCoder\n以下算法方向需要你在未来两年内有所涉及，但是掌握这些算法并不是保障： # 搜索 图论(最短路、生成树、二分图、连通图、网络流\u0026hellip;) 动态规划(树形DP、数位DP、区间DP、斜率DP、概率DP\u0026hellip;) 数论 数据结构(线段树、搜索树、平衡二叉树、KD树、树堆\u0026hellip;) 字符串(KMP、Hash、AC自动机、后缀数组、字典树) 等\u0026hellip; 推荐的书： 刘汝佳竞赛入门经典两本：紫书、大白书，链接不放了。 # 有些问题，可以先尝试自己回答一下，自己实在回答不了或无法找到答案回答，再提出来。\n"},{"id":100,"href":"/posts/c++/accessmodifier/","title":"OOP中的-控制修饰符","section":"C","content":"面向对象编程(Object-Oriented Programming)中,最初开始接触到的就是访问控制修饰符。访问控制修饰是几乎所有的OOP语言都会涉及到的，下面就整理三个我熟悉的语言。\nC/C++ # 更详细的内容可以参考《C++ primer》-类 这一章。\n概述 # 有三种修饰符，分别：private、public、protected。其中最后一个protected是在继承出现以后才有效的。对于无论是成员变量还是成员函数，这些修饰符都具有相同的作用，即访问控制。其设计的主要作用是为了防止封装的类内成员被类的使用者无意更改或误操作，同时，对访问权限的限制可以实现代码间的松耦合。在类内算法做调整的过程中保持使用者可调用的代码接口，只更改私有函数等。 在详述各个控制符之前要讲一下struct 和class的区别。二者都可以用来定义类，唯一的不同就是默认的访问权限不同。struct的第一个修饰符之前定义的成员默认是public的，但是class是默认private的。\nprivate 与 public # 这两个要一起来说，因为二相相生。private就是将控制权限制在类内，只能是类内的函数访问。public完全没有限制。这两个是最容易理解的，也没有什么好说的。\nprotected # 比上面两个略复杂一点点。在没有继承的情况下，protected与private是一样的，所以protect之所以与private不同在于派生类的访问。其修饰的成员可以被派生类直接访问，但是不被派生类对象访问。这个有些博客写的不太严谨，protected无论什么时候都不能与public一样，也就是类的使用者不能直接访问。 换句话说，派生类可以将其修饰的成员当成自己的亲成员来访问，派生类内部可以用对象实例来访问，但是类外不行。\n举个例子：\nclass Base{ protected: int m; ... } class A : public Base{ public: // Note-1 void Add(A \u0026amp; tmp){ tmp.m += 1; } ... } int main(){ A tmp; // Note-2 int x = tmp.m; return 0; } /* * 其中，Note-1的写法没有问题，但是Note-2的写法就是非法的。 */ friend # 有的时候我们的类成员不能被使用者直接访问，但是我需要让其他的一些非类内成员函数来访问，如重载运算符的时候需要被模板函数访问，所以又有了一个新的控制访问修饰符，这个修饰符只用来修饰一些函数或类的声明，也就是说可以让一些类或函数成为该类的友元，使得其可以访问类内的成员变量和成员函数，不受其他修饰符的限制。\n只能修饰非成员函数的声明，或其他类。 只能在类内修饰。 其声明不受其他几个修饰符影响。 友元关系不能传递, 也不可继承。 友元声明，只是声明了访问权限，并没有实际声明，如要使用该函数，仍然需要显示用普通声明再声明一次。 用作继承权限修饰符 # 除了用于成员权限声明，此三个修饰符海可以用来修饰类的继承方式，不同的继承方式使得基类成员在派生类中的权限不同。\n基本用法如下：\nclass CLASSNAME : [修饰符] BASECLASS {...} class A : public Base{...} 修饰符默认为private private # 基类中的所有protected、public 成员在该派生类中是private成员。 基类中的所有private成员在派生类中不可用。 protected # 基类中的所有protected、public 成员在该派生类中是protected成员。 基类中的所有private成员在派生类中不可用。 public # 基类中的所有public 成员在该派生类中是public成员。 基类中的所有protected 成员在该派生类中是protected成员。 基类中的所有private成员在派生类中不可用。 using 改变权限 # 如果在子类中使用using关键字则可以更改继承过来的变量的权限。例如：\nclass Base{ private: int m; } class A : public Base{ public: using Base::m; // 则此类中m为public变量，同样可以更改为其他类型。 } Java # 在Java中有四种访问修饰符，分别是：private、protected、public、默认修饰符。其中类只能由public或默认修饰符修饰（这里指访问权限的修饰，下面有final修饰符的用法）。且程序中有多个类的时候，程序文件名要命名为public修饰的那个类的名称。Java解释器运行的时候运行main函数所在的类。表现在命令行即：\npublic class A { ... } class B { public static void main(Stringp[] args){ ... } } // 文件名为 A.java 编译：\njavac A.java 运行：\njava B public # 可以被任意访问。\nprivate # 其修饰的成员只能由类内函数访问、修改。与C++无较大区别。\nprotected # 其修饰的成员可由一下几个访问：\n类内其他成员。 同一个包中的其他类 该类的子类。 默认修饰符 # 一般只能被同一个程序、同一个包中的其他类访问。\n继承中的区别 # Java的继承没有修饰符，派生类可以继承基类的所有非私有成员（这里的继承是指可以操作，私有成员依然存在只是不能操作，不能访问，在C++中也是一样的），并且，继承具有传递性。\n例如B继承了A， C继承了B，则C可以直接访问A的非私有成员。\n基类成员隐藏 # 派生类中如果有同名变量（类型可不同），则实现了对积累成员的隐藏。在函数中，基类定义的函数处理的是积累的变量，子类实现的函数处理的是子类的变量。\n可以使用super来调用被隐藏的变量。super是该类的直接父亲。\n方法的覆盖 # 同名\u0026amp;同类型\u0026amp;同参数列表，的方法会对基类方法进行覆盖(override)。这样会完全清除基类的对应方法，所以是override.\n其他控制符 # 下面这两个控制符事实上不是本文章的重点，但是顺带提一下就过了。下面与上面的东西不是一回事，所修饰的东西也不是一个类型，所以不要搞混了。\nstatic # 静态的，可修饰变量、方法、符合语句。是属于类的，而不属于对象。 静态函数只能处理静态变量，不能处理类内的非静态变量。 静态变量初始化是由static修饰的符合语句来完成。可以直接声明并赋值也可以用下面的方式。 static int a,b; static{ a = 1; b = 2; } final # 常量修饰符，可修饰变量、方法、类。 final修饰的方法不能被重写覆盖。final修饰的类不能派生子类。\nPHP # 有了上面的内容就可以类推到这个上面也是一样的，只是会更简单一些。\n类和方法默认public。 特殊的就是，同一个类的不同实例之间可以无限制直接互相访问。 "},{"id":101,"href":"/posts/self/thinking-1/","title":"随想-1","section":"Self","content":"最近听民谣，都是比较低沉的，各种无奈、不得志等等。。。但是这个阶段的我听了却是一脸的轻蔑。\n第一首歌，听到“趁我们还年轻，还可以倔强”，我的第一反应是为什么不年轻就不可以倔强？然后想到了我的父亲，这应该是十分真实而贴切的例子了。\n我真切的感受到我父亲的无奈与痛苦，所以曾经思考良久，一个男人自己与家庭是什么关系的存在？是财富收入的来源？是家庭的一份子？是家庭具有主宰地位的人？…… 我自己心中当然有我的答案。得出自己的答案永远只需要1秒钟，剩下的就是你的内心能否强大的做到这个答案。我的答案跟真理同路，跟大众心理相悖。我不认为男人跟女人之间有什么家庭分工上的区别，不存在男人就要做什么而女人就不需要做什么。有人可能会问你为什么不说不存在男人就不做什么而女人就要做什么？你这大男子主义！呵呵，现实中大家都知道，女人一旦不高兴了，还有什么做不做，男人不都特么得做吗？男人不高兴了能怎么样？排解一下、发泄一下、调整一下，回来继续该干嘛干嘛。那么，为什么？为什么会有这样的情况出现？有人说不这样的男人都被淘汰了。当然这只是一部分的人，并不是所有的男人女人都是这样，总有一批人大家都认知很清楚明了，不会做这样无聊又损人不利己的事情。\n男人跟女人没什么差别，人格上没有、性别上没有、能力上也没有。有人说女人青春就那么短暂，过了那段时间就人老珠黄，而男人呢？四十还是一样反而越老越有魅力。其实这个观点就足够写一篇文章的了，今天就慢慢来扯一下。首先第一个就是为什么男人年龄大反而有魅力？为什么女人没有？这个问题我的第一反应很清晰，因为男人在社会上什么都干，生活了那么久，各个方面的能力经验财富都积累的很多，所以由内而外的散发着成熟的力量，这是真正的魅力，当然有一些各个方面都不怎么样的男人就没有这样的魅力了。然而女人嘛，如果你选择了在20多岁依靠自己的美貌获得了生活资料，那么必然就缺少了这些经验、阅历、能力等，自然当你年老色衰的时候就没办法散发这样的力量。如果你没有依靠女性特质来生活，你的人格魅力应该也是非常大的。所以在这个角度来看，大家都是一样的，你有能力，有经验，就会有魅力，而不是人种天生带有区别。一个男人年轻的时候依靠家里的财富而腹内空空，等到40岁一样是个没有魅力的中年人。当然要说一下的就是，有优势就要用，但是别依赖。最可怕的不就是别人比你聪明还比你努力吗？同样可怕的就是别人比你先天优势强，还比你更清楚自己要做什么。\n另一个角度就是，女人的青春短暂，那么，男人的青春就不短暂了吗？男人也是这个年纪身体素质很强，体型最好看，精力最旺盛，过了这个阶段一样就是个中年人，他的内在可能很强，但是外在一样衰老。但是男人在这段时间做了什么，一些女人又做了什么？我认识两个女人，大我10岁，此刻都是30多的年纪了，现状截然不同，而这样的现状我曾预料到，但是当时不敢相信，后来现实印证了。一个是很骄傲、很独立、有想法有能力的女人，长的也好看；另一个就是最最一般的女人，该上学的时候没有好好上，当然另外一个也没有好好上，俩人同学。然后这个女人在生活稍微好一点的时候，就会享受生活，说享受其实不太恳切，就是对后面的事情抱着极其乐观的心态，因为挣钱的是他的男人，当经济不紧张的时候就吃吃喝喝玩玩乐乐，等到经济紧张的时候就满面愁容。另一个女人，在青春中，学习茶道，卖茶叶，谈了恋爱，分了手，但是始终经济独立，有自己的事业。此时的二人，在两个层次甚至差了两个层次。等到两个人都30多了，都开始容颜凋谢，该有魅力的人依旧碾压另一个，当然你要跟20岁的小姑娘比，颜值自然没法比，但是思想更胜一筹。从这个角度来说，男人女人一样，放在自己的同类中做对比，很现实，很多人就是自己没有自律这个东西，今天好了就天真的想象每天都好，思维目光具浅。自己付出了多少就会得到多少，别的都没用。其实这个故事中还有另外一个角色，就是这个普通女人的男人，他是个很有头脑也有能力的人，但是这个男人大这女人10岁，就是我的父亲。由于各种原因，男人要在这样的情况下工作，又没有固定的工作，工程风险很大，所以，在这种风险很大的情况下身边还有一个这样的人存在当然就特别容易出问题，这里疏漏一点那里浪费一点。所以多这个男人来说，他被拖累了。更严重的是，他们有一个小女儿，又是一个无法摆脱的负担，还有一个上大学的儿子，怎么办？还能怎么办？对这个男人来说就被加持死了，没有办法动，没有足够的资金支持他做出变动，即使所在的行业出现问题，也必须坚持到儿子大学以后才行吧。\n这就是无法倔强！\n他曾经有什么样的眼光、什么样的魄力和勇气，孤身进入一个新的行业，依靠自己的社交能力和头脑，自己解决机会问题，解决技术问题。我十分清楚，并且十分敬佩。但是现在的他，就是这样的无奈。心中纵使万分不服气，没办法，倔强不了。儿子要生活、女人要生活、女儿要生活，不能让他们都暂停啊，说给我一年时间我去自由打拼挣钱去。曾经我还小的时候，无所谓，我放在我奶奶家，也离婚了，自己一个人，就特么天不怕地不怕。什么是倔强，就是当我有一天想做什么事情的时候我就能去做而不是被现实加持的死死的在心里挣扎。\n这需要什么？很清晰，一定的资本储备，一个人或有个贤内，一个清晰的头脑。千万不要因为一时的寂寞、一时的人性弱点就贸然做不成熟的动作，最大的表现就是不要因为寂寞就找个不适合自己的女人，这是最最最重要的。你要倔强，要自由，就得承受这些不好过，这就是代价，但是对我来说，我可以忍受寂寞，但是我无法忍受自己怂，我自己怎么失败我都认，但是如果让我因为某个人而没有尽全力而败，我会恨这个人，但是这个人是我自己选择的，怎么能恨她呢？最后还是恨自己，相当于自己做了不成熟的选择，所以不存在这样的人就不存在这样的风险。当我一个人的时候我什么时候都能吼一句：从头再来！然后哪怕几天吃不上饭又如何，我不怕。我不能低下我的倔强的头，那是我活到现在的一大支柱。\n当你一个人的时候，一切都变简单了，毫无压力就往前走。生活费？不存在的，能吃饱就行，吃的自在一点也没多少钱。房子？无所谓，有个洗澡睡觉的地方就够了，大了还得打扫。人际？都是自己好兄弟，挺开心的。父母？自己的，有困难说话，没困难我要有自己的生活了。我有喜欢的东西，车、狗。攒钱去买，没钱了车可以不开，狗可以跟我一起吃我剩的。\n这世界上唯一不存在的就是规则。我为什么非得用别人的做法来要求自己？那是别人的做法，那是大家认为的规则，什么没有房子就很难结婚，什么各方压力很大。那都是庸人被裹携，我为什么还要自己走进去？当然不，没有谁规定，就算有人规定没房子不能结婚，那我干嘛要结婚？也没人规定必须结婚啊。所以，没有规则。\n这社会有规则，但是你有选择规则的权力。你可以选择进入一个体系，然后要与其中的规则博弈。你要看清楚你适合什么样的规则，甚至有很多规则是潜在的，隐藏的，但是你可以看出了它真实存在，你就像一个异类生活在一个体系内却用着另外一套规则跟他们博弈。这依靠的是你对社会规律的把握。你没有必要遵循大家的规则，因为大家要的东西不一样怎么能用同样的规则呢？\n行业最害怕的就是践踏规则的人，因为这样的人一定成功更快而且当你意识到的时候已经无力回天，只能望尘莫及。很典型的就是当初瑞星杀毒和某杀毒软件价格竞争的如火朝天，360突然冒出来说，我不要钱，免费了。其他人还玩个屁，然后所有人都只好玩免费。有些规则可以践踏，有些可以，当你看到一条规则可以践踏的时候，就别犹豫，干了再说。\nGood Luck.\n"},{"id":102,"href":"/posts/self/before/","title":"学习更深C/C++语言之前的思想准备","section":"Self","content":"从开发这个Online Judge开始到现在，我自己收获颇多。有的时候是为了这个项目去学了很多东西，有的时候是学了其他的东西刚好就用在了这个项目上。一个良性的过程就是这样，有的是目的去做，有的是无心为之，但总会带来新的峰回路转，柳暗花明。从最开始的稚嫩，连MVC的概念都不清晰，就开始写，一点点实现，写的很丑，然后就写不下去了；后来学习了Java 的MVC， 然后又偶然看到了Php的MVC，然后就开始写自己的框架，有了Husky，然后就把OJ用框架进行重构。写了一段时间后，写到了后台的判题核心，一部分是自己闭门造车，一部分借鉴了网上的思路，但是实现起来总是那么别扭，说不上的不放心。刚好在这样的情况下，又看到了一些实现的细节，有了新的思路。意识到自己的技术实力贸然开发是很不成熟的，但是，没有关系，本来就是这样，它成功了是我的成功，他不成功也不会失败，是我增长经验最重要的一次经历，我借此机会学习到了很多知识和经验。但是我一定是对此有很大的信心和决心，要做好，并且要做的更优秀，虽然可能会花费比较长的时间。\n写这篇博客的时候，此时我坐在理工楼三楼的悬空阳台上吹着风，听着手机的歌，塞着耳机，桌子是暗红色，很沉稳；一字排开手机、电脑、鼠标。很少会动鼠标，更少动手机，很简洁也很舒服，优美又惬意的工作环境。\n下午的时候，突然大脑进入了很奇怪的状态，突然想不起来刚刚要做什么，跑出去打了一个多小时的球，然后回来去洗澡，车忘了骑回来，裤子也被打出一条口子，整个人的状态就不对。可能最近一直都是满载运行，所以需要休息一下，然后就过来写博客了。\n写这篇博客干什么呢？ 为了更好的出发。\n意识到自己在C++的操作系统部分的薄弱，所以下一步就是要开始学习，以OJ的判题核心为基础，一个一个的学习下来。学习的过程与开发过程是完全不一样的，因为学习是很卡顿的过程，总是不懂，然后查，然后想，记下来。所以带着开发的节奏来学习就不行，开发的时候要一气呵成，行云流水的代码一行一行的开始码，思路很清晰，然后单元测试，几个修改，结束。就像是一切都准备好后开始做菜，一步一步几分钟就出锅了。学习的过程就不一样了，要看，要记下来，更主要的是，要实践，甚至是各种情况都要试验一下，才能熟练的掌握用法，处变不惊。\n所以这篇博客就是自己跟自己谈谈心，调整一下装态和心态。同时也规划一下学习的路线。\n路线： # C++中的系统进程、内存、CPU时间相关的函数用法。 C++编译器的参数使用。 C++头文件使用。 C++机器相关的常量与不同机器之间的区别。 以上是第一部分，另外就是关于如何在服务器上开设一个独立服务，监听端口。还有消息队列怎么在PHP和OJCore之间传递。 一点一点来，应该会需要1周左右的时间。\n明天是5.20，此时的我毫无想法。其实大家都差不多，看谁能得偿所愿吧。或许再过一段时间，都明白了是怎么一回事，就再也不会这么傻了，那个时候就挺可笑的了。\n有些事情，只有一次机会，错过了，就变成了另一种，虽然表面一样，但是实质已经不同。\nGlade to see you.\n"},{"id":103,"href":"/about/","title":"关于我","section":"Introduction","content":"参加过ACM-ICPC 算法竞赛，成绩还可以。喜欢算法，喜欢简洁的东西，至少用起来要简洁， Linux死忠粉。 觉得趁年轻，该努力就努力，趁还喜欢学习，就多学一些。希望如果某一天突然想干点别的就能去干点别的。但是，写程序，是一辈子的爱好了。\n计算机科学与技术学院 ( CS ) 苏州大学计算机科学与技术学院ACM集训队 ( 队长 ) 苏州大学微软学生俱乐部SUMSC ( 主席 ) 2017.01 MCM/ICM Meritirious Winner 2016.12 ACM/ICPC Asia Regional Contest China-Final 2016 Bronze Medal ( Shanghai ) 2016.11 ACM/ICPC Asia Regional Contest Beijing Site Sliver Medal 2016.10 CCPC Hangzhou Site Sliver Medal 2016.10 ACM/ICPC Asia Regional Contest Dalian Site Gold Medal 2017.10 ACM/ICPC Asia Regional Contest Shenyang Site Gold Medal 2017.11 ACM/ICPC Asia Regional Contest Qingdao Site Gold Medal 2017.12 ACM/ICPC Asia Regional Contest EC-Final 2017 Sliver Medal ( Shanghai ) 2018.06 ACM/ICPC Asia Regional Contest Xuzhou Site Gold Medal 苏州大学 - 2018.9 ~ 2021.6 # 计算机科学与技术 - NLP方向 联系方式 # GitHub: https://github.com/Paladnix E-mail: Paladnix@outlook.com "},{"id":104,"href":"/posts/web/husky/","title":"Husky - A Light Web MVC Framework","section":"Web","content":"这篇文章是对我自己编写的PHP MVC 框架：Husky 的详细说明， 算作是官方说明文档。\n项目的GitHub地址\nHusky是什么？ # Husky 是一个使用PHP语言编写的Web MVC微框架，此项目最初是作者偶然看到的一篇博客中的教学项目。我对项目的代码进行了一些修改和整理，删除了一些不必要的内容，添加了部分设计，目前框架处于第一个版本(Husky-0.9)，框架将会长期维护更新。目前只在Linux开发环境下测试可用。\n如果你是一个初出茅庐的Web开发者，那么本框架就十分适合你来使用了。相比较很多成熟的PHP框架来说，Husky的体积小，逻辑简单，还没有加入很多集成的自动化功能。整个框架按照一个既定的数据格式实现了MVC开发的需求，更主要的是，在一定程度上说，这个框架还处于比较原始的状态， 这对新手深入了解框架的体系结构十分有利，你可以按照自己的想法对框架进行修改，甚至可能在此基础上改写出更出色的框架。\n本框架的开发初衷是为作者所在的学生社团开发网站，多人合作模式下编写网站没有一个框架实在太乱了。但是衡量工作内容，于是决定自己开发一个微框架来辅助网站的开发，就有了这个项目。\n你需要掌握什么？ # 此框架需要一定的php网站开发经验才能熟练的使用。所以在使用之前，你需要具备以下的知识或能力:\n配置apache2 的Rewrite功能 数据库SQL语句 php基本语法 面向对象编程的基本知识 简要了解http协议与请求url链接 清楚的了解软件 MVC 架构的组成 在进一步开发框架之前，你需要进一步具备以下的知识或能力:\napache2 的更多配置选项 熟练掌握http协议 深入理解 MVC 框架结构 熟练使用php语言进行面向对象编程 熟练使用PDO数据库操作库 良好的编程习惯 Husky 做了什么？ # Husky 实现了下面几个功能：\n唯一的网站入口，url地址重定向 自动化加载MVC控制类，自动化解决类间依赖 过滤SQL注入攻击的安全问题， 使用PDO进行数据库操作 Controller、Model、View模块分离 定义数据参数等的格式 配置环境 # 框架需要软件环境：\nLinux apache2 php(\u0026gt;=5.4) mysql 开启apache2 rewrite 功能 # 默认的Ubuntu apache2是没有开启这个功能的，要先去看一下 /etc/apache2/mods-enabled/ 文件夹下是否存在rewrite.load 模块的链接，如果没有，要去看一下 /etc/apache2/mods-available/ 中是否存在对应的文件，如果有，则使用下面的命令建立一个链接到 ../mods-enabled/ 文件夹下：\n$ ln -s /etc/apache2/mods-available/rewrite.load /etc/apache2/mods-enabled/rewrite.load 旧版本的apache2需要修改httpd.conf 文件中的AllowOverride None 修改为 AllowOverride All\n如果是新版本的apache2需要修改/etc/apache2/apache2.conf 中的 AllowOverride None 修改为 AllowOverride All, 同时看一下 AccessFileName 为 .htaccess ;\ndownload code # 准备好环境以后，下载该项目的代码包到你本地的文件夹 eg: project/ 中。注意请将代码包中所有的文件放置在 project/ 文件夹下，并检查隐藏文件.htaccess是否存在，如不存在请到Github上下载下来并放置在 project/ 目录下。\n此时项目中默认会存在一个本教程的某个版本，直接在浏览器的地址栏输入:localhost/project/(如果你的project/文件夹不在localhost的目录下请移至localhost/)。此时如果你看到了本教程的某个版本的网页，则除数据库部分的环境配置成功，否则请检查软件是否安装，apache2的Rewrite功能是否已经打开。\n开始编写代码 # 下载下来的框架带有一个项目的目录结构，我们不需要变动。但是需要说明一下目录的结构和用途：\nproject/ \\__ application/ \\__ controllers/ \\__ models/ \\__ views/ \\__ config/ \\__ config.php \\__ PHP_MVC/ \\__ phpmvc.php \\__ Core.class.php \\__ Model.class.php \\__ Sql.class.php \\__ View.class.php \\__ Controller.class.php \\__ Model.class.php \\__ runtime/ \\__ sql/ \\__ css/ \\__ js/ \\__ fonts/ \\__ images/ \\__ index.php \\__ .htaccess application/文件夹内放置的就是整个网站即将开发的MVC部分的代码，基本上整个网站代码都会在这里。 config/放置整个网站的配置信息，包括数据库的密码、用户名等。 PHP_MVC是整个框架的核心代码，也包含了框架的基类，其余的代码都继承自这里的基类。 runtime/存放网站运行过程中的log日志文件和错误记录。 sql/做为开发过程中存放网站的数据库文件。 index.php是整个网站的唯一入口，已经重定向过来，在其中有两个宏定义：APP_DEBUG和APP_DEBUG_FRA分别用于网站开发时错误检测和框架开发时的错误检测。网站发布时需要将两个宏全部关闭。 .htaccess是网站url重定向文件 代码风格 # 框架的整体采用Java代码风格，命名规则上也大部分借鉴Java命名规则。\nMySQL表名， 小驼峰命名法 testTable 类名(Class)， 大驼峰命名法：Sql 方法名(Actions)， 小驼峰命名法：index, indexPost 模块名(Models)， 大驼峰命名法， 后缀Model： TestModel 控制器(Controllers)， 大驼峰命名法，后缀Controller： TestController 视图(Views)， 控制器名/行为名： TestView Controller # /* * php 代码： /application/controllers/TestController.class.php * */ class TestController extends Controller{ /* * 当 url 为：localhost/project/test/ 或 localhost/project/text/index/ 时调用该函数 * * index 可以做为默认打开页面时的处理函数， * 不写则默认调用父类的index函数，直接渲染页面。 * 该函数接受一个字符串数组参数 如：$params , 该字符串是url中的参数，数组中每个元素形如： id=2 ； * 每组参数使用 \u0026#39;name=value\u0026#39; 的形式存储。 * assign() 函数可以将键值对存储进视图模块中，交由视图模块进一步处理。 * render() 函数渲染视图，调用视图模块的函数进行渲染。 可以写一个参数用来标志：action */ public function index( $params ){ $content = (new TestModel)-\u0026gt;selectAll(); $this-\u0026gt;assign(\u0026#39;title\u0026#39;, \u0026#39;全部条目\u0026#39;); $this-\u0026gt;assign(\u0026#39;content\u0026#39;, $content); $this-\u0026gt;_view-\u0026gt;render(\u0026#34;index\u0026#34;); } /* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 当 url 为：localhost/project/test/add/ 时调用该函数 * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 同样也可以带参数 */ public function add( $params ){ $data[\u0026#39;name\u0026#39;] = $_POST[\u0026#39;value\u0026#39;]; $count = (new TestModel)-\u0026gt;add($data); $this-\u0026gt;assign(\u0026#39;title\u0026#39;, \u0026#39;添加成功\u0026#39;); $this-\u0026gt;assign(\u0026#39;count\u0026#39;, $count); $this-\u0026gt;_view-\u0026gt;render(\u0026#34;add\u0026#34;); } } View # /* *\tphp 代码： /application/views/TestView.class.php */ class TestView extends View{ /* * 对于不同的函数可以编写不同的前端组件，重写render函数按需加载组件 * * 此类对应上面的 TestController\t* */ public function render( $action=\u0026#34;index\u0026#34; ){ if($action == \u0026#34;index\u0026#34;){ $this-\u0026gt;index(); return ; } else if($action == \u0026#34;add\u0026#34;){ $this-\u0026gt;add(); return ; } } public function index( ){ $pages[] = APP_PATH.\u0026#34;/application/views/Index/header.php\u0026#34;; $pages[] = APP_PATH.\u0026#34;/application/views/Index/body.php\u0026#34;; $pages[] = APP_PATH.\u0026#34;/application/views/Index/footer.php\u0026#34;; foreach( $pages as $page) $this-\u0026gt;page($page); } public function add( ){ $pages[] = APP_PATH.\u0026#34;/application/views/Index/header.php\u0026#34;; $pages[] = APP_PATH.\u0026#34;/application/views/Index/add.php\u0026#34;; $pages[] = APP_PATH.\u0026#34;/application/views/Index/footer.php\u0026#34;; foreach( $pages as $page) $this-\u0026gt;page($page); } } Model # /* * php 代码： /application/models/TestModel.class.php */ /* $this-\u0026gt;formatInsert($data) : 接受一个键值对数组，将其格式化为：键=\u0026#39;值\u0026#39; ， 键=\u0026#39;值\u0026#39; 的字符串， 如果对应字段为整形数，则没有引号 $this-\u0026gt;formatWhere($data) : 键值对 -\u0026gt; 字符串， $this-\u0026gt;formatUpdate($data) : 键值对 -\u0026gt; 字符串， $this-\u0026gt;selectSQL($sql) : 执行$sql 语句，并返回二维数组做为结果。 $this-\u0026gt;querySQL($sql) : 执行$sql 语句，返回被影响的行数。 */ class TestModel extends Model{ /* 例如需要将数据库中所有的记录都提取出来并返回一个二维数组记录所有的数据 * */ public function selectAll(){ $sql = sprintf(\u0026#34;select * from `%s` \u0026#34;, $this-\u0026gt;_table); return $this-\u0026gt;selectSQL($sql); } /* 如果要插入记录到数据库中，则将键值对存在 $data 中 * query函数将返回受影响的行数 */ public function insert( $data ){ $sql = sprintf( \u0026#34;insert into `%s` %s\u0026#34;, $this-\u0026gt;_table, $this-\u0026gt;formatInsert($data) ); return $this-\u0026gt;querySQL($sql); } } "},{"id":105,"href":"/posts/self/begining/","title":"Begining","section":"Self","content":"这里是新的起点。\n其实没有什么特殊的事情发生，只是因为最近的状态发生了一些很微妙的变化，从一个单纯的ACMer逐渐的过渡到一个真正的程序员。开始真正的系统的接触学习计算机体系的其他的更多元的知识，去体系化的思考和学习计算机和软件体系。\n有句话说的好：编程只是一门失传的艺术的再现，这门艺术就是“思考”。我很喜欢去思考或是去观摩别人的思考。每个人的程序和架构都是他思维的体现，优秀的代码总是闪着令人振奋的美感，思维之美。精巧的结构，复杂的算法，灵活的扩展，严谨的安全意识\u0026hellip; 我愿意花费时间去琢磨这些美妙的设计。\n博客我曾经写过一段时间，但是觉得长得太丑，然后就转去了Latex。写了很久的Latex的文档，觉得也有点麻烦，尤其最近在写网站相关的内容， 所以又重新考虑了一下博客，然后选了Hexo这个新物种。觉得还不错。\n我的博客会写些什么 # 在博客长的好看的情况下我会写很多东西，因为一旦颜值高，就会想写东西，毕竟，金玉其外败絮其中的东西总是很可笑。为了匹配这样的颜值就会想方设法的让内容充实起来。\n技术 # 这个是作为程序员的基本素养，学习\u0026ndash;传播，利人利己。我不会在学习的过程中来记录学到的一知半解，因为那样的东西堆积起来没有什么意义，甚至破坏了整体的美感，我会在经过一段时间的学习和思考后来博客中系统的记录下一项技术和事件。但是有的时候我会先编写一个草稿，以免经过的时间过长我会遗漏一些比较基础或是底层的内容，造成技术文章的阅读门槛变高。我本人是不喜欢那些阅读门槛高的文章，尤其不喜欢依靠虚的名词架高理解的门槛。这样做没有什么意义。我在技术的文章中更喜欢做比喻，找一个形象化的例子加以解释。事实上很多技术都是思维的体现，思维总是来源于生活的基本认知，所以都会有形象化的解释方法，便于理解。如果有人能从我的博客中学习到比知识本身更深刻的东西，那才是我的技术文章的真正价值。知识本身只是信息，能传达信息深层的理念和设计，才是文章的作用。\n生活 # 作为我的个人博客，难免会写一些我的个人境况，个人对一些技术、事件、人、物的理解和看法。我相信我是站在自己的角度上，无意对外界作出攻击或诋毁，我只是必要的心理活动的表达，更多的时候是写给自己看。他体现了我的人生观、价值观、世界观。如果有的人看了我的文章，我也很乐意分享我的看法，但是，我无意强加我的观点给任何人，一切只是一种表达，他的本意没有向外辐射的意图。我也相信我的个人博客不具备社会影响力，而是新时期技术加成后的一方思维天地。\n在这一部分，有可能会涉及情感、工作、爱好等。\n新的起点 # 从来没有那么一刻，你说，我就在这一刻长大了，或我就从这一刻从一个男孩变成一个男人。所以也就没有那么一刻就成了新的起点。\n是因为技术方向的变更，使得我从，事实上只是较少范围的使用网络，变换到了现在这个几乎离开互联网和文档就工作不下去的状态。我自己也感受到这种微妙的，给我的心理状态带来的变化。\n计算机技术就像是一个巨大的游戏机。在这其中你可以设计、使用工具去完成很多有趣的工作，自动化的处理，漂亮的界面，便捷的生活。其实每天都在玩游戏，沉迷在这个巨大的游戏机世界。在玩这些游戏的时候，会获得难得的平静，明明就在工作，其实思维已经在另一个世界。这个世界的一切都是有缘由的，有确定的规则，而这个世界产生的东西还可以加成到现实社会，最主要的是可以用来赚钱，何乐而不为。\n我相信在不久的将来，几乎所有人都要具备基础的计算机知识和程序设计能力，因为这是未来社会运行的技术基础。甚至我大胆的认为，当全民都具备程序设计思维的时候，社会的精神状态将发展到一个新的时代。人将具备深刻的规则意识，并深刻认识到自身的渺小，具备合作的意识与能力。换句话说，社会进化的下一个节点，将依靠这样的技术革命进行，而不是靠文化教育。\n最后，Hello World！\n"},{"id":106,"href":"/posts/c++/debug/","title":"Debug","section":"C","content":" 启动后台进程，top -H -p 可以查看所有的线程 systemd, deamon pstree -a // 进程树 wait waitpid, // 父进程管理子进程 hup 和 nohup pstack 打印堆栈, 是GDB的简单封装，可以参考一下GDB的使用。 LLDB 和 GDB # LLDB 是LLVM工具链中的一个DEBUG工具，和GDB非常相似。\nGDB教程：http://c.biancheng.net/view/8191.html 命令差异详情参考：https://lldb.llvm.org/use/map.html LLDB 速查：https://www.jianshu.com/p/4250e4805bb3 o "},{"id":107,"href":"/posts/c++/epoll/","title":"Epoll","section":"C","content":" Linux事件驱动机制 # 在本学人机交互课程的时候，用到过一个渲染库，由于需要监听很多组件的点击和键盘事件，主函数中有一个巨大的轮询机制，并且当时还是写的单线程的处理，这当然是十分鸡肋的一种处理方式。\nLinux中，事件驱动机制，也称为IO多路复用。是内核实现的一种机制，在内核2.6以后的版本中才有。\n在Linux中，一切皆文件，文件即IO。文件、socket通信、进程间通信管道pipe都是IO事件，都使用统一的fd文件描述符(File Descriptor)来表示。\n文件描述符 # 每个文件描述符会与一个打开的文件相对应 不同的文件描述符也可能指向同一个文件 相同的文件可以被不同的进程打开，也可以在同一个进程被多次打开 系统为维护文件描述符，建立了三个表:\n进程级的文件描述符表 系统级的文件描述符表 文件系统的i-node表 每一个进程都会维护一个fd表，一般一个进程允许打开的最大文件数量是1024。\n事件驱动机制 # 应用程序层面的事件通知机制总是绕不过轮询这个天坑，轮询带来的问题至少有三个：\n不加限制的for循环必然导致cpu跑满 加了sleep的轮询必然导致一定的拥挤，不必要的等待。 大IO事件的阻塞，影响了后续的事件处理。 Linux在内核层面提供了epoll的机制来实现事件的通知，在没有事件的时候阻塞应用进程。做到CPU的0浪费。具体的实现方式在应用端只需要三个函数。\nepoll_create， 创建一个fd池 epollctl，向fd池中注册需要监听的事件 epollwait，等待事件唤醒自己 我们先从整体了解一下epoll的内部实现机制。\n内核中epoll的实现机制 # Linux系统的一切皆文件的设计中，为文件对象设计了一个poll回调机制，即当某个fd的读写状态满足的时候，即发生poll回调，将fd相关的数据(epitem)塞入一个队列中，并通知操作系统唤醒应用进程。\n由此我们可以知道，当应用进程使用epollctl函数注册了事件以后，调用epollwait函数即可进入实际的睡眠状态，直到操作系统接到poll回调将其唤醒。应用线程没有任何浪费的操作。\n此处需要注意一点，虽然Linux中一切皆文件，但是并不是所有的文件对象都具有一致的接口，poll接口就不是都支持的，朴素意义（狭义）的文件系统是不支持的。socket是支持的。所以epoll常用于网络IO的处理中。\n代码示例 # 关于socket的知识：\n[1]. C/C++ socket编程教程之六：使用listen(),accept(),write(),read()函数 [2]. linux C++ socket编程 实例 int socket(int domain, int type, int protocol); 函数对应一切皆文件的open操作；\nAF_INET: IPv4 Internet协议\nSOCK_STREAM: TCP字节流\nint bind(int sockfd, const struct sockaddr * addr, socklen_t addrlen); 分配一个具体的地址给sockfd\nlisten() 函数让socket处于监听的状态，此时如果有请求进来，就放入缓冲区，直到缓冲区满；中间调用accept() 函数即可以从缓冲区获取一个请求。listen 非阻塞。\naccept() 函数会阻塞进程，并创建一个新的socket，这个socket记录了客户端的ip等信息，后续与客户端通信都是使用这个新的socket。accept只是建立了这个通信的通道，之后的处理要用read和write来处理消息。在epoll中这是两个事件。需要再监听这个新的socket才能在有数据的时候唤醒应用进程。\n服务端：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #define IPADDRESS \u0026#34;127.0.0.1\u0026#34; #define PORT 8787 #define MAXSIZE 1024 #define LISTENQ 5 #define FDSIZE 1000 #define EPOLLEVENTS 100 //创建套接字并进行绑定 static int socket_bind(const char* ip,int port); //IO多路复用epoll static void do_epoll(int listenfd); //事件处理函数 static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf); //处理接收到的连接 static void handle_accpet(int epollfd,int listenfd); //读处理 static void do_read(int epollfd,int fd,char *buf); //写处理 static void do_write(int epollfd,int fd,char *buf); //添加事件 static void add_event(int epollfd,int fd,int state); //修改事件 static void modify_event(int epollfd,int fd,int state); //删除事件 static void delete_event(int epollfd,int fd,int state); int main(int argc,char *argv[]) { int listenfd; listenfd = socket_bind(IPADDRESS,PORT); listen(listenfd,LISTENQ); do_epoll(listenfd); return 0; } static int socket_bind(const char* ip,int port) { int listenfd; struct sockaddr_in servaddr; listenfd = socket(AF_INET,SOCK_STREAM,0); if (listenfd == -1) { perror(\u0026#34;socket error:\u0026#34;); exit(1); } memset(*servaddr, 0, sizeof(servaddr)); servaddr.sin_family = AF_INET; inet_pton(AF_INET,ip,\u0026amp;servaddr.sin_addr); servaddr.sin_port = htons(port); if (bind(listenfd,(struct sockaddr*)\u0026amp;servaddr,sizeof(servaddr)) == -1) { perror(\u0026#34;bind error: \u0026#34;); exit(1); } return listenfd; } static void do_epoll(int listenfd) { int epollfd; struct epoll_event events[EPOLLEVENTS]; int ret; char buf[MAXSIZE]; memset(buf,0,MAXSIZE); //创建一个描述符 epollfd = epoll_create(FDSIZE); //添加监听描述符事件 add_event(epollfd,listenfd,EPOLLIN); for ( ; ; ) { //获取已经准备好的描述符事件 ret = epoll_wait(epollfd,events,EPOLLEVENTS,-1); handle_events(epollfd,events,ret,listenfd,buf); } close(epollfd); } static void handle_events(int epollfd,struct epoll_event *events,int num,int listenfd,char *buf) { int i; int fd; //进行选好遍历 for (i = 0;i \u0026lt; num;i++) { fd = events[i].data.fd; //根据描述符的类型和事件类型进行处理 if ((fd == listenfd) \u0026amp;\u0026amp;(events[i].events \u0026amp; EPOLLIN)) handle_accpet(epollfd,listenfd); else if (events[i].events \u0026amp; EPOLLIN) do_read(epollfd,fd,buf); else if (events[i].events \u0026amp; EPOLLOUT) do_write(epollfd,fd,buf); } } static void handle_accpet(int epollfd,int listenfd) { int clifd; struct sockaddr_in cliaddr; socklen_t cliaddrlen; clifd = accept(listenfd,(struct sockaddr*)\u0026amp;cliaddr,\u0026amp;cliaddrlen); if (clifd == -1) perror(\u0026#34;accpet error:\u0026#34;); else { printf(\u0026#34;accept a new client: %s:%d\\n\u0026#34;,inet_ntoa(cliaddr.sin_addr),cliaddr.sin_port); //添加一个客户描述符和事件 add_event(epollfd,clifd,EPOLLIN); } } static void do_read(int epollfd,int fd,char *buf) { int nread; nread = read(fd,buf,MAXSIZE); if (nread == -1) { perror(\u0026#34;read error:\u0026#34;); close(fd); delete_event(epollfd,fd,EPOLLIN); } else if (nread == 0) { fprintf(stderr,\u0026#34;client close.\\n\u0026#34;); close(fd); delete_event(epollfd,fd,EPOLLIN); } else { printf(\u0026#34;read message is : %s\u0026#34;,buf); //修改描述符对应的事件，由读改为写 modify_event(epollfd,fd,EPOLLOUT); } } static void do_write(int epollfd,int fd,char *buf) { int nwrite; nwrite = write(fd,buf,strlen(buf)); if (nwrite == -1) { perror(\u0026#34;write error:\u0026#34;); close(fd); delete_event(epollfd,fd,EPOLLOUT); } else modify_event(epollfd,fd,EPOLLIN); memset(buf,0,MAXSIZE); } static void add_event(int epollfd,int fd,int state) { struct epoll_event ev; Site is undergoing maintenance = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_ADD,fd,\u0026amp;ev); } static void delete_event(int epollfd,int fd,int state) { struct epoll_event ev; ev.events = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_DEL,fd,\u0026amp;ev); } static void modify_event(int epollfd,int fd,int state) { struct epoll_event ev; Site is undergoing maintenance = state; ev.data.fd = fd; epoll_ctl(epollfd,EPOLL_CTL_MOD,fd,\u0026amp;ev); } 客户端代码\n"},{"id":108,"href":"/posts/c++/gccclang/","title":"Gcc\u0026 Clang","section":"C","content":"GCC 是 GNU旗下的编译工具集。Clang是基于LLVM的一套C/C++、Object-C/C++ 的一款编译器。LLVM则是一个通用后端，用于优化程序、链接程序、生成代码等。\n常用的编译选项说明 # "},{"id":109,"href":"/posts/c++/rand/","title":"Rand","section":"C","content":" mt19937 # std::mt19937是伪随机数产生器，用于产生高性能的随机数。 C++11引入。返回值为unsigned int。\nmt 是Mersenne Twister算法译为马特赛特旋转演算法，是伪随机数发生器之一，其主要作用是生成伪随机数。发明于1997年。\nMersenne Twister有以下优点：随机性好，在计算机上容易实现，占用内存较少(mt19937的C程式码执行仅需624个字的工作区域)，与其它已使用的伪随机数发生器相比，产生随机数的速度快、周期长，可达到$2^19937-1$，且具有623维均匀分布的性质，对于一般的应用来说，足够大了，序列关联比较小，能通过很多随机性测试。\n随机数生成的用法 # 生成5个随机数\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;random\u0026gt; using namespace std; int main() { std::mt19937 rng(std::random_device{}()); for (int i = 0; i \u0026lt; 5; i++) { cout \u0026lt;\u0026lt; rng() \u0026lt;\u0026lt; endl; } return 0; } 生成均匀分布的随机数\n#include \u0026lt;iostream\u0026gt; #include \u0026lt;random\u0026gt; using namespace std; int main() { std::mt19937 rng(std::random_device{}()); std::uniform_int_distribution\u0026lt;\u0026gt; uni_int(1, 100); for (int i = 0; i \u0026lt; 5; i++) { cout \u0026lt;\u0026lt; uni_int(rng) \u0026lt;\u0026lt; endl; } return 0; } 【参考文献】 # 自研实现 \u0026amp; boost实现：https://blog.csdn.net/caimouse/article/details/55668071 MT算法原理：http://www.cppblog.com/Chipset/archive/2009/01/19/72330.html 用法文档(官)：https://zh.cppreference.com/w/cpp/numeric/random "},{"id":110,"href":"/posts/c++/readme/","title":"Readme","section":"C","content":"虽然简单的C++ 会写了，但是对于一些面向对象的设计依然有较大的漏洞。在这里针对漏洞进行修补。\n函数拦截替换：https://cloud.tencent.com/developer/article/1478460 C++ 异步： https://chlorie.github.io/ChloroBlog/posts/2020-10-07/0-async.html "},{"id":111,"href":"/posts/c++/scopeguard/","title":"Scope Guard","section":"C","content":" C++ 原子事务 # 本文所介绍的ScopeGuard方法来自于Andrei-Alexandrescu 和 Pertu-Marginean在2000年发布的一篇文章。其提出了一种更加安全和优美的原子事物处理机制。\n原子事务是指，一个或一组动作，要么全做，要么全不做。在代码中，体现为操作失败时的回滚操作。\n比较直观的做法是在代码中引入大量的异常处理。这不仅让代码变得更长而且更加不易扩展，当添加一个新的操作将会引入大量的异常处理代码。\n另外一种做法则是遵循“构造时创建资源，析构时清除资源”的原则来实现，需要为每一种操作实现一个单独的操作类，大致如下：\nclass VectorInserter{ public: VectorInserter(std::vector\u0026amp; v, User\u0026amp; u): container_(v), commit_(false) { container_.push_back(\u0026amp;u); } void Commit() throw(){ commit_ = true; } ~VectorInserter() { if (!commit_) container_.pop_back(); } private: std::vector\u0026amp; container_; bool commit_; }; 你可以这样来使用这个操作类：\nvoid User::AddFriend(User\u0026amp; newFriend) { VectorInserter ins(friends_, \u0026amp;newFriend); pDB_-\u0026gt;AddFriend(GetName(), newFriend.GetName()); // Everything went fine, commit the vector insertion ins.Commit(); } 可以看到，在析构函数中，只有当commit没有被调用的时候，才会进行回滚操作。这样做的好处是，避免编写大量的异常处理代码，一旦操作成功就设置commit为true，否则在析构函数中进行回滚操作。\nScope Guard 的实现方法 # 以上的思路缺点在于需要编写大量的操作类。使用Scope Guard可以写出如下简洁的代码。\nvoid User::AddFriend(User\u0026amp; newFriend) { friends_.push_back(\u0026amp;newFriend); ScopeGuard guard = MakeObjGuard( friends_, \u0026amp;UserCont::pop_back); pDB_-\u0026gt;AddFriend(GetName(), newFriend.GetName()); guard.Dismiss(); } 代码中的guard唯一的作用就是在函数结束的时候调用pop_back, 除非已经调用过Dismiss函数。\n对于一组操作，我们可能需要多个guard来针对每个操作进行回滚。\n// 调用某个成员函数 friends_.push_back(\u0026amp;newFriend); ScopeGuard guard = MakeObjGuard(friends_, \u0026amp;UserCont::pop_back); // ScopeGuard也可用于普通函数： void* buffer = std::malloc(1024); ScopeGuard freeIt = MakeGuard(std::free, buffer); FILE* topSecret = std::fopen(\u0026#34;cia.txt\u0026#34;); ScopeGuard closeIt = MakeGuard(std::fclose, topSecret); 实现 Scope Guard # 首先来实现一个基类：\nclass ScopeGuardImplBase { public: void Dismiss() const throw() { dismissed_ = true; } protected: ScopeGuardImplBase() : dismissed_(false) {} ScopeGuardImplBase(const ScopeGuardImplBase\u0026amp; other) : dismissed_(other.dismissed_){ other.Dismiss(); } ~ScopeGuardImplBase() {} // nonvirtual (see below why) mutable bool dismissed_; private: // Disable assignment ScopeGuardImplBase\u0026amp; operator=(const ScopeGuardImplBase\u0026amp;); }; 由于回滚函数的不同，所以我们需要不同的子类来具体的实现如何回滚。具体的包括调用有参函数、无参函数、成员函数等。\n下面以有一个参数的函数为例：\ntemplate \u0026lt;typename Fun, typename Parm\u0026gt; class ScopeGuardImpl1 : public ScopeGuardImplBase { public: ScopeGuardImpl1(const Fun\u0026amp; fun, const Parm\u0026amp; parm): fun_(fun), parm_(parm) {} ~ScopeGuardImpl1() { if (!dismissed_) fun_(parm_); } private: Fun fun_; const Parm parm_; }; 并实现一个工厂方法:\ntemplate \u0026lt;typename Fun, typename Parm\u0026gt; ScopeGuardImpl1\u0026lt;Fun, Parm\u0026gt; MakeGuard(const Fun\u0026amp; fun, const Parm\u0026amp; parm) { return ScopeGuardImpl1\u0026lt;Fun, Parm\u0026gt;(fun, parm); } 有了以上的代码，我们就可以使用这个ScopeGuardImpl1的对象来进行回滚。但是这并不利于我们的代码，对于调用者来说，他需要区分不同类型的回滚操作，并实例化不同的对象。因此我们使用一个typedef来整理一下：\ntypedef const ScopeGuardImplBase\u0026amp; ScopeGuard; 将基类的常量引用重定义为ScopeGuard。\n进一步复制完善 # 接下来我们就可以实现不同类型的对象和重载工厂函数。\n无参函数 template \u0026lt;typename Fun\u0026gt; class ScopeGuardImpl0 : public ScopeGuardImplBase { public: ScopeGuardImpl0(const Fun\u0026amp; fun): fun_(fun) {} ~ScopeGuardImpl0() { if (!dismissed_) fun_(); } private: Fun fun_; }; template \u0026lt;typename Fun\u0026gt; ScopeGuardImpl0\u0026lt;Fun\u0026gt; MakeGuard(const Fun\u0026amp; fun) { return ScopeGuardImpl0\u0026lt;Fun \u0026gt;(fun); } 带参数的成员函数 template \u0026lt;class Obj, typename MemFun\u0026gt; class ObjScopeGuardImpl0 : public ScopeGuardImplBase { public: ObjScopeGuardImpl0(Obj\u0026amp; obj, MemFun memFun): obj_(obj), memFun_(memFun) {} ~ObjScopeGuardImpl0() { if (!dismissed_) (obj_.*fun_)(); } private: Obj\u0026amp; obj_; MemFun memFun_; }; template \u0026lt;class Obj, typename MemFun\u0026gt; ObjScopeGuardImpl0\u0026lt;Obj, MemFun, Parm\u0026gt; MakeObjGuard(Obj\u0026amp; obj, Fun fun) { return ObjScopeGuardImpl0\u0026lt;Obj, MemFun\u0026gt;(obj, fun); } // 创建方法 // ScopeGuard guard = MakeObjGuard(friends_, \u0026amp;UserCont::pop_back); 进一步优化(异常处理) # 以上的实现有一个新的问题，因为我们要在析构函数里调用一个外部传入的函数，而如果在析构函数中抛出异常非常危险，由于有栈展开的机制存在，将会引发程序的崩溃。\n关于栈展开的解释和过程可以参考：https://docs.microsoft.com/zh-cn/cpp/cpp/exceptions-and-stack-unwinding-in-cpp?view=msvc-170\n因此我们坚决防止析构函数抛出异常。在代码中我们需要对外部函数的调用进行异常捕获。并不做任何处理。\n... ~ScopeGuardImp0() { if (!dismissed_) try { (obj_.*fun_)(); } catch(...) {} } 进一步优化(传递引用) # 如果我们希望在回滚函数中传递一个引用值，除了新编写一组新的子类来支持，也可以使用一个工具类来转换引用。\ntemplate \u0026lt;class T\u0026gt; class RefHolder { T\u0026amp; ref_; public: // 通过一个拷贝构造，拷贝出一份新的引用。 RefHolder(T\u0026amp; ref) : ref_(ref) {} operator T\u0026amp; () const { return ref_; } }; template \u0026lt;class T\u0026gt; inline RefHolder\u0026lt;T\u0026gt; ByRef(T\u0026amp; t) { return RefHolder\u0026lt;T\u0026gt;(t); } 使用时对于需要被引用的参数，可以被包装一下。\n// 回滚函数， 修改引用参数 void Decrement(int\u0026amp; x) { --x; } void UseResource(int refCount) { ++refCount; ScopeGuard guard = MakeGuard(Decrement, ByRef(refCount)); ... } 使用上面的方法，可以将传递引用通过拷贝值的方式，实现实际上传递的还是引用。\n并且我们可以对ScopeGuardImpl1中的参数param使用const进行修饰。使用这种方式，可以在编译阶段进行安全检查。\ntemplate \u0026lt;typename Fun, typename Parm\u0026gt; class ScopeGuardImpl1 : public ScopeGuardImplBase { ... private: Fun fun_; const Parm parm_; }; 至此，我们可以方便的编写带有回滚机制的原子事务函数。\n"},{"id":112,"href":"/posts/c++/thread/","title":"Thread","section":"C","content":"C++11 提供了线程开发模块，此前都使用pthread，一种C语言的解决方案。但是pthread的使用极其繁琐，导致初初使用pthread在赛场上搞了几个小时还是传不对参数，结果也拿不出来。thread的出现大大的简化了多线程编程。\nThread 的基本用法 # #include\u0026lt;iostream\u0026gt; #include\u0026lt;thread\u0026gt; using namespace std; void say_hi(string s) { cout \u0026lt;\u0026lt; \u0026#34;Hello: \u0026#34; \u0026lt;\u0026lt; s \u0026lt;\u0026lt; endl; return ; } int main() { string str = \u0026#34;Paladnix\u0026#34;; thread thr(say_hi, str); // 创建线程thr并启动。传入待执行的函数和参数。 cout \u0026lt;\u0026lt; \u0026#34;Others\u0026#34; \u0026lt;\u0026lt; endl; thr.join(); // 阻塞主函数直至thr线程结束退出。 return 0; } 如果主函数没有调用join(), 则主函数可能在thr线程之前结束，会强制结束子线程。输出的结果如下：\nOthers libc++abi: terminating Hello: Paladnix [1] 39257 abort ./a.out 也可以使用detach() 函数，将thr函数放到后台运行，与主函数的进程解绑。缺点就是thr的输出结果不会再出现在主进程的终端上。\n传入成员函数 # 除了可以使用普通函数作为线程的启动函数，也可以用类的成员函数来构造线程。\nclass Person { string name; int age; public: Person() {} Person(string name, int age):name(name), age(age){} void say_hi(string hi) { cout \u0026lt;\u0026lt; hi \u0026lt;\u0026lt; \u0026#39; \u0026#39; \u0026lt;\u0026lt; name \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; __LINE__ \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; this_thread::get_id() \u0026lt;\u0026lt; endl; } }; void test_thread_2() { Person a(\u0026#34;Paladnix\u0026#34;, 18); thread thr(\u0026amp;Person::say_hi, a, \u0026#34;Hi\u0026#34;); thr.join(); cout \u0026lt;\u0026lt; __LINE__ \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; this_thread::get_id() \u0026lt;\u0026lt; endl; } Mutex 锁 # 多个线程共享一个变量时，往往需要对资源进行加锁。Mutex是一种互斥锁。\n#include \u0026lt;iostream\u0026gt; // std::cout #include \u0026lt;thread\u0026gt; // std::thread #include \u0026lt;mutex\u0026gt; // std::mutex volatile int counter(0); // non-atomic counter std::mutex mtx; // locks access to counter void attempt_10k_increases() { for (int i=0; i\u0026lt;10000; ++i) { if (mtx.try_lock()) { // only increase if currently not locked: ++counter; mtx.unlock(); } } } int main (int argc, const char* argv[]) { std::thread threads[10]; for (int i=0; i\u0026lt;10; ++i) threads[i] = std::thread(attempt_10k_increases); for (auto\u0026amp; th : threads) th.join(); std::cout \u0026lt;\u0026lt; counter \u0026lt;\u0026lt; \u0026#34; successful increases of the counter.\\n\u0026#34;; return 0; } 上面的代码展示了Mutex的一个示例用法，最后统计出++counter的操作一共进行了5321次，所以可以知道try_lock()函数是非阻塞的。\ntime_mutex锁 # 与mutex锁不同，提供了一个try_lock_for() 函数可以指定阻塞的时间，如果超时还未获得锁则返回false。 try_lock_until() 函数支持指定一个时间点，在指定时间点之前保持阻塞。\nstd::lock_guard # A lock guard is an object that manages a mutex object by keeping it always locked. On construction, the mutex object is locked by the calling thread, and on destruction, the mutex is unlocked. It is the simplest lock, and is specially useful as an object with automatic duration that lasts until the end of its context. In this way, it guarantees the mutex object is properly unlocked in case an exception is thrown.\n构造函数时加锁，析构/异常捕获时释放锁。这是C++的基础机制RAII的利用。\n// lock_guard example #include \u0026lt;iostream\u0026gt; // std::cout #include \u0026lt;thread\u0026gt; // std::thread #include \u0026lt;mutex\u0026gt; // std::mutex, std::lock_guard #include \u0026lt;stdexcept\u0026gt; // std::logic_error std::mutex mtx; void print_even (int x) { if (x%2==0) std::cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; is even\\n\u0026#34;; else throw (std::logic_error(\u0026#34;not even\u0026#34;)); } void print_thread_id (int id) { try { // using a local lock_guard to lock mtx guarantees unlocking on destruction / exception: std::lock_guard\u0026lt;std::mutex\u0026gt; lck (mtx); print_even(id); } catch (std::logic_error\u0026amp;) { std::cout \u0026lt;\u0026lt; \u0026#34;[exception caught]\\n\u0026#34;; } } int main () { std::thread threads[10]; // spawn 10 threads: for (int i=0; i\u0026lt;10; ++i) threads[i] = std::thread(print_thread_id,i+1); for (auto\u0026amp; th : threads) th.join(); return 0; } std::unique_lock # 一样使用了RAII机制，利用析构函数自动释放锁。\n更方便的是，不需要try_catch 来保证析构函数的调用了。\n#include \u0026lt;iostream\u0026gt; // std::cout #include \u0026lt;thread\u0026gt; // std::thread #include \u0026lt;mutex\u0026gt; // std::mutex, std::unique_lock std::mutex mtx; // mutex for critical section void print_block (int n, char c) { // critical section (exclusive access to std::cout signaled by lifetime of lck): std::unique_lock\u0026lt;std::mutex\u0026gt; lck (mtx); for (int i=0; i\u0026lt;n; ++i) { std::cout \u0026lt;\u0026lt; c; } std::cout \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } int main () { std::thread th1 (print_block,50,\u0026#39;*\u0026#39;); std::thread th2 (print_block,50,\u0026#39;$\u0026#39;); th1.join(); th2.join(); return 0; } 条件变量：condition_variable # 多线程中，线程之间的同步可以借助condition_variable来实现， 在线程A中，使用condition_variable的wait方法将线程阻塞，直到线程B调用notify方法将线程A唤醒，线程A继续进行。\n一个典型的生产-消费模型：\n#include\u0026lt;iostream\u0026gt; #include\u0026lt;thread\u0026gt; #include\u0026lt;mutex\u0026gt; #include\u0026lt;atomic\u0026gt; #include\u0026lt;queue\u0026gt; #include\u0026lt;chrono\u0026gt; #include\u0026lt;condition_variable\u0026gt; int main() { std::queue\u0026lt;int\u0026gt; production; std::mutex mtx; std::condition_variable cv; bool ready = false; // 是否有产品可供消费 bool done = false; // 生产结束 std::thread producer( [\u0026amp;] () -\u0026gt; void { for (int i = 1; i \u0026lt; 10; ++i) { // 模拟实际生产过程 std::this_thread ::sleep_for(std::chrono::milliseconds(10)); std::cout \u0026lt;\u0026lt; \u0026#34;producing \u0026#34; \u0026lt;\u0026lt; i \u0026lt;\u0026lt; std::endl; std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); production.push(i); // 有产品可以消费了 ready = true; cv.notify_one(); } // 生产结束了 done = true; } ); std::thread consumer( [\u0026amp;] () -\u0026gt; void { std::unique_lock\u0026lt;std::mutex\u0026gt; lock(mtx); // 如果生成没有结束或者队列中还有产品没有消费，则继续消费，否则结束消费 while(!done || !production.empty()) { // 防止误唤醒 while(!ready) { cv.wait(lock); } while(!production.empty()) { // 模拟消费过程 std::cout \u0026lt;\u0026lt; \u0026#34;consuming \u0026#34; \u0026lt;\u0026lt; production.front() \u0026lt;\u0026lt; std::endl; production.pop(); } // 没有产品了 ready = false; } } ); producer.join(); consumer.join(); return 0; } 其中在使用的时候尤其要注意wait函数需要配合一个标注变量，并用while循环。这是为了避免线程被虚假唤醒。例如存在线程B和C都在wait， 而线程A唤醒B线程的时候，C线程也被唤醒了，并且以更快的速度消耗了A产生的数据，那么B继续执行则会发现并没有数据。\n"},{"id":113,"href":"/posts/c++/%E5%86%85%E5%AD%98%E6%A3%80%E6%B5%8B/","title":"内存检测","section":"C","content":"由于对指针的深度操作，使得C++程序出现内存问题的风险变得很大。常见的内存问题包括：内存泄漏、重复释放、读写未申请的内存地址、悬挂指针、野指针等。\ngcc 自带编译检查 # google的sanitizers工具集提供了这部分编译检查工具，gcc 4.9以上支持。\n需要安装libasan的库: sudo yum install libasan\n常用的gcc参数如下：\n开启内存泄露检查功能：-fsanitize=leak 开启地址越界检查功能：-fsanitize=address 开启越界详细错误信息：-fno-omit-frame-pointer 只有跑到的代码才能检测出，未被执行的代码无法检测。\nValgrind 教程 # 参考：https://blog.csdn.net/tissar/article/details/87194737\n"},{"id":114,"href":"/posts/c++/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","title":"智能指针","section":"C","content":"C++ 智能指针是对普通指针的一种封装，具体的有四类指针， 而不是一种。按照需求使用指针有助于我们提高代码质量。\n所有的智能指针都在追求一个东西：RAII(Resource acquisition is initialization), 资源获取即初始化。\nscoped_ptr 作用域指针(boost 库) # 正如其名字指出的那样，在作用域结束的时候即自动释放的指针。\nscoped_ptr 指针具有一些特殊的要求。\nscoped_ptr是noncopyable的，也就是无法复制。 不能作为容器中的元素，因为无法复制。 example # #include \u0026lt;boost/scoped_ptr.hpp\u0026gt; #include \u0026lt;iostream\u0026gt; struct Shoe { ~Shoe() { std::cout \u0026lt;\u0026lt; \u0026#34;Buckle my shoe\\n\u0026#34;; } }; class MyClass { boost::scoped_ptr\u0026lt;int\u0026gt; ptr; public: MyClass() : ptr(new int) { *ptr = 0; } int add_one() { return ++*ptr; } }; int main() { boost::scoped_ptr\u0026lt;Shoe\u0026gt; x(new Shoe); MyClass my_instance; std::cout \u0026lt;\u0026lt; my_instance.add_one() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; std::cout \u0026lt;\u0026lt; my_instance.add_one() \u0026lt;\u0026lt; \u0026#39;\\n\u0026#39;; } // output // 1 // 2 // Buckle my shoe 比较特殊的地方是 1. x没有手动调用delete；2. MyClass的析构函数不需要释放ptr；\n【参考文献】 # boost 库实现scoped_ptr： https://www.boost.org/doc/libs/1_50_0/libs/smart_ptr/scoped_ptr.htm shared_ptr # shared_ptr中所实现的本质是引用计数(reference counting)，也就是说shared_ptr是支持复制的，复制一个shared_ptr的本质是对这个智能指针的引用次数加1，而当这个智能指针的引用次数降低到0的时候，该对象自动被析构。\n需要特别指出的是，如果shared_ptr所表征的引用关系中出现一个环，那么环上所述对象的引用次数都肯定不可能减为0那么也就不会被删除，为了解决这个问题引入了weak_ptr。\nexample # #include \u0026lt;memory\u0026gt; using namespace std; class F {}; class G : public F {}; shared_ptr\u0026lt;G\u0026gt; sp0(new G); // okay, template parameter G and argument G* shared_ptr\u0026lt;G\u0026gt; sp1(sp0); // okay, template parameter G and argument shared_ptr\u0026lt;G\u0026gt; shared_ptr\u0026lt;F\u0026gt; sp2(new G); // okay, G* convertible to F* shared_ptr\u0026lt;F\u0026gt; sp3(sp0); // okay, template parameter F and argument shared_ptr\u0026lt;G\u0026gt; shared_ptr\u0026lt;F\u0026gt; sp4(sp2); // okay, template parameter F and argument shared_ptr\u0026lt;F\u0026gt; shared_ptr\u0026lt;int\u0026gt; sp5(new G); // error, G* not convertible to int* shared_ptr\u0026lt;int\u0026gt; sp6(sp2); // error, template parameter int and argument shared_ptr\u0026lt;F\u0026gt; 【参考文献】 # shared_ptr 微软文档：https://docs.microsoft.com/zh-cn/cpp/standard-library/shared-ptr-class?view=msvc-170 weaked_ptr # 对weak_ptr起的作用，很多人有自己不同的理解，我理解的weak_ptr和shared_ptr的最大区别在于weak_ptr在指向一个对象的时候不会增加其引用计数，因此你可以用weak_ptr去指向一个对象并且在weak_ptr仍然指向这个对象的时候析构它，此时你再访问weak_ptr的时候，weak_ptr其实返回的会是一个空的shared_ptr。实际上，通常shared_ptr内部实现的时候维护的就不是一个引用计数，而是两个引用计数，一个表示strong reference，也就是用shared_ptr进行复制的时候进行的计数，一个是weak reference，也就是用weak_ptr进行复制的时候的计数。weak_ptr本身并不会增加strong reference的值，而strong reference降低到0，对象被自动析构。为什么要采取weak_ptr来解决刚才所述的环状引用的问题呢？需要注意的是环状引用的本质矛盾是不能通过任何程序设计语言的方式来打破的，为了解决环状引用，第一步首先得打破环，也就是得告诉C++，这个环上哪一个引用是最弱的，是可以被打破的，因此在一个环上只要把原来的某一个shared_ptr改成weak_ptr，实质上这个环就可以被打破了，原有的环状引用带来的无法析构的问题也就随之得到了解决。\n【参考文献】 # https://www.zhihu.com/question/20368881/answer/14918675 auto_ptr # 这是标准库中的一种简单的智能指针，与shared_ptr 不同在于，指针在复制的时候会转移所有权，也就是一个对象只会由一个智能指针所拥有，在复制和传递参数的时候都会出现所有权转移的问题。\n使用auto_ptr 作为成员函数可以有效的避免内存泄漏，当两个成员A和B在构造函数中申请资源，如果A成功而B失败了，则整个对象的构造函数是失败的，因此不会调用对象的析构函数，而A申请的资源无法得到释放。 如果使用auto_ptr 来封装A和B，则可以保证当auto_ptr被销毁的时候一定连带销毁自己持有的指针。\nunique_ptr # 同一时刻只能又一个unique_ptr 指向同一个对象，不支持拷贝转移。指针析构的时候会一起析构所指向的对象。\n"},{"id":115,"href":"/posts/c++/%E7%81%AB%E7%84%B0%E5%9B%BE/","title":"火焰图","section":"C","content":" 使用dtrace 分析程序性能 # 运行程序并采样， \u0026lt;main\u0026gt; 替换为待分析的程序\n# 采样到程序结束 sudo dtrace -c \u0026#39;./\u0026lt;main\u0026gt;\u0026#39; -o out.stacks -n \u0026#39;profile-997 /execname == \u0026#34;\u0026lt;main\u0026gt;\u0026#34;/ { @[ustack(100)] = count(); }\u0026#39; # 以99Hz的频率, PID是2063的进程为捕获对象, 包括用户态和核心态, 持续60s sudo dtrace -x ustackframes=100 -n \u0026#39;profile-99 /pid == 2063 \u0026amp;\u0026amp; arg1/ { @[ustack()] = count(); } tick-60s { exit(0); }\u0026#39; -o out.user_stacks dtrace 脚本语法参考：https://docs.oracle.com/cd/E24847_01/html/E22192/gbwaz.html#scrolltoc\n生成火焰图 # 1. git clone https://github.com/brendangregg/FlameGraph 2. ./stackcollapse.pl \u0026lt;out.stacks\u0026gt; | ./flamegraph.pl \u0026gt; ~/Desktop/perf.svg perf 性能分析 # 直接参考这个吧：http://linux.51yip.com/search/perf 和这个：https://blog.justforlxz.com/2020/07/21/use-perf-to-analytics-program/\n"},{"id":116,"href":"/posts/cmake/libs/","title":"Libs","section":"Cmake","content":" 列出所有动态连接库 # ldconfig -p nm 命令 # 查看静态库或动态库定义了哪些函数\nnm -n --defined-only xxxx.a nm -g -C --defined-only xxxx.so nm -D xxxx.so 显示hello.a 中的未定义符号，需要和其他对象文件进行链接.\nnm -u hello.o 在 ./ 目录下找出哪个库文件定义了close_socket函数.\nnm -A ./* 2\u0026gt;/dev/null | grep \u0026#34;T close_socket\u0026#34; objdump 命令 # 查看动态库有哪些符号，包括数据段、导出的函数和引用其他库的函数\nobjdump -tT xxx.so objdump -x xxx.a 查看动态库依赖项\nobjdump -x xxx.so | grep \u0026#34;NEEDED\u0026#34; 查看动态符号表\nobjdump -T xxx.so 假如想知道 xxx.so 中是否导出了符号 yyy\nobjdump -T xxx.so | grep \u0026#34;yyy\u0026#34; 。 查看动态符号表\nobjdump -t xxx.so -T 和 -t 选项在于 -T 只能查看动态符号，如库导出的函数和引用其他库的函数，而 -t 可以查看所有的符号，包括数据段的符号。\n"},{"id":117,"href":"/posts/cmake/makefile/","title":"Makefile","section":"Cmake","content":" 赋值 # = 是最基本的赋值 := 是覆盖之前的值 ?= 是如果没有被赋值过就赋予等号后面的值 += 是添加等号后面的值 注意点 1: 赋值语句的处理顺序 # \u0026ldquo;=\u0026rdquo; 赋值是等到最后才会执行的部分。\nx = foo y = $(x) bar x = xyz 在上例中，y的值将会是 xyz bar ，而不是 foo bar 。\n“:=”表示变量的值决定于它在makefile中的位置，而不是整个makefile展开后的最终值。\nx := foo y := $(x) bar x := xyz 在上例中，y的值将会是 foo bar ，而不是 xyz bar 了。\n基本全局变量 # MAKECMDGOALS, make xxx， 配置的目标：xxx。 OPT, make xxx -Dtest_ut, 后面的选项参数：-Dtest_ut CXXFLAGS, CXX编译器的选项参数，与上面的OPT不同的是，OPT是来自于命令行，FLAGS是传递给编译器 判断选择 # 使用逗号隔开ifneq条件的两个变量，空就是空。 常用的if包括：ifeq, ifneq, ifdef, ifndef\nifneq ($(filter dbg, $(MAKECMDGOALS)),) DEBUG_LEVEL=2 else ifneq ($(filter shared_lib install-shared, $(MAKECMDGOALS)),) DEBUG_LEVEL=0 LIB_MODE=shared else ifneq ($(filter static_lib install-static, $(MAKECMDGOALS)),) DEBUG_LEVEL=0 LIB_MODE=static else ifneq ($(filter jtest rocksdbjava%, $(MAKECMDGOALS)),) OBJ_DIR=jl LIB_MODE=shared ifneq ($(findstring rocksdbjavastatic, $(MAKECMDGOALS)),) OBJ_DIR=jls ifneq ($(DEBUG_LEVEL),2) DEBUG_LEVEL=0 endif ifeq ($(MAKECMDGOALS),rocksdbjavastaticpublish) DEBUG_LEVEL=0 endif endif endif include # 引入xxx.mk 文件，一般将src.mk 中配置不同的target所对应的源代码文件列表。\n# These are the sources from which librocksdb.a is built: LIB_SOURCES = \\ cache/cache.cc \\ cache/cache_entry_roles.cc \\ cache/cache_key.cc \\ cache/cache_reservation_manager.cc \\ cache/clock_cache.cc \\ cache/fast_lru_cache.cc \\ cache/lru_cache.cc \\ cache/compressed_secondary_cache.cc \\ cache/sharded_cache.cc \\ db/arena_wrapped_db_iter.cc \\ db/blob/blob_fetcher.cc \\ db/blob/blob_file_addition.cc \\ db/blob/blob_file_builder.cc \\ ... "},{"id":118,"href":"/posts/cmake/project-struct/","title":"Project Struct","section":"Cmake","content":" 一个较好的项目结构 # . ├── CMakeLists.txt # CMake项目文件 ├── bootstrap.sh # 一些常用的脚本，如编译、测试、clean ├── build # CMake的临时文件夹 ├── deps # 第三方依赖库 ├── include # 项目的头文件，lib项目中需要暴露出的interface │ └── union_find.hpp ├── log # 测试时的log文件 ├── src │ ├── main.cpp │ └── union_find.cpp └── test └── test-main.cpp 以上所以一个lib库常用的目录结构\n"},{"id":119,"href":"/posts/cmake/readme/","title":"Readme","section":"Cmake","content":" CMake Tutorial # 由于不同平台的makefile写法不同，因此需要一个集大成者cmake来实现：“Write once, run everywhere”。cmake主要用于生成makefile，实际的编译组织工作还是由make来实现。\n在看了一些C++工程的CMake文件后，结合官网给的文档，对于CMake的设计思想有了一些理解。\n核心思想 # CMake的核心思想是通过对构建对象的描述来组织编译。我们的代码核心的构建对象只有两类: 库(lib)、可执行文件(exe)。\n因此我们需要了解CMake的两个核心函数：add_library, add_executable。分别对应了两类目标。一个常规的用法如下：\n# for lib set(SRC_FILES_LIB xxx.cpp xxx.cpp xxx.cpp ...) addlibrary(\u0026#34;xxx_lib\u0026#34; ${SRC_FILES_LIB}) # for exe set(SRC_FILES_EXEC xxx.cpp xxx.cpp xxx.cpp ...) add_executable(\u0026#34;xxx_exec\u0026#34; ${SRC_FILES_EXEC}) 以上的两个部分，仅仅是简单的描述了目标程序的来源构成\n一个简单完整的CMake项目 # # 设定cmake的最小版本 cmake_minimum_required(VERSION 3.21) # 设定允许指定项目的版本 cmake_policy(SET CMP0048 NEW) # 设定项目的\u0026lt;project_name, VERSION\u0026gt; project(codeshark VERSION 1.0.0) # 设定CXX编译标准 set(CMAKE_CXX_STANDARD 11) # 设定CXX编译器的标志 set(CMAKE_CXX_FLAGS_RELEASE \u0026#34;-g -O2 -DNDEBUG\u0026#34;) set(CMAKE_CXX_FLAGS \u0026#34;${CMAKE_CXX_FLAGS} -fPIC -Werror -Wno-format\u0026#34;) # 收集需要开放的头文件 set(SOURCE_HEADS_LIB include/union_find.hpp) # 收集lib库的源代码 set(SOURCE_FILES_LIB src/union_find.cpp) # 设定编译目标lib， 类型，源代码 add_Library(codeshark-mkdata STATIC ${SOURCE_FILES_LIB}) # 设定可执行文件的源代码 set(SOURCE_FILES_EXEC src/main.cpp) # 设定第三方库 set(libxxx ${PROJECT_SOURCE_DIR}/deps/openssl/lib/libssl.a) # 添加可执行文件目标 add_executable(main ${SOURCE_FILES_EXEC}) # 添加依赖的库，可以是上面指定的lib，或是安装的其他库 target_link_libraries(main codeshark-mkdata libxxx) # 添加target的头文件检索目录 target_include_directories(main PUBLIC include/) # 安装头文件与连接库(make install) install(FILES ${SOURCE_HEADS_LIB} DESTINATION /usr/local/include/codeshark) install(TARGETS codeshark-mkdata DESTINATION /usr/local/lib) [参考文献] # https://zhuanlan.zhihu.com/p/338657327 "},{"id":120,"href":"/posts/docker/build-image/","title":"Build Image","section":"Docker","content":" 如何构建自己的镜像 # 当我们需要对外提供一个配置好的基础环境时，我们需要自己打包构建一个image镜像，并发布出去。\n大致的流程是：拉取基础镜像、进入镜像并安装依赖、退出容器并打包、上传至中央仓库。\n以一个简单的C++调试环境为例 # 选择ubuntu作为基础镜像： docker pull ubuntu 查看是否拉取成功：\ndocker images 以交互的方式启动容器 docker run -it ubuntu /bin/sh 在容器内部安装g++和gdb程序， 并退出 apt update apt install g++ gdb exit 找到容器并打包 docker container ls -a 可以看到有我们刚刚退出的容器，此时容器已经停止运行，但是容器依然存在。\ndocker commit -a paladnix -m \u0026#39;simple gdb\u0026#39; cbf13e09376d simple-gdb:1.0 docker images 可以看到我们已经有了两个image：\nREPOSITORY TAG IMAGE ID CREATED SIZE simple-gdb 1.0 1a46f7f7599e 16 seconds ago 446MB ubuntu latest ba6acccedd29 8 weeks ago 72.8MB 通过dockerfile来创建镜像 # Dockerfile\nFROM ubuntu RUN apt update \u0026amp;\u0026amp; apt install g++ gdb docker build -t simple-gdb:1.0 ./ 上传镜像至docker-hub # 这是一个类似于github的设计，我们可以在https://hub.docker.com/ 中申请一个账号，然后创建自己的镜像仓库。随后在本地机器上使用命令登陆即可上传操作。\ndocker login # 根据提示输入账号和密码 随后需要将我们的镜像重命名，其中REPOSITORY必须是我们注册的“用户名/仓库名”的形式，tag可以自行设定。\ndocker tag [image ID] [UserID]/[repository]:[tag] 随后使用docker push [UerID]/[repository]:[tag] 即可上传至中央仓库。\n"},{"id":121,"href":"/posts/docker/docker-limit/","title":"Docker Limit","section":"Docker","content":"运行Docker的容器时，我们往往需要对其进行资源管控，并且会有一些数据传输的需求。\n运行 # "},{"id":122,"href":"/posts/docker/readme/","title":"Readme","section":"Docker","content":" Docker 的基本理念与设计 # Docker是一种基于cgroup技术的虚拟容器技术，其设计核心思路与Git类似。\n镜像与容器 # 镜像(image)可以简单的理解为一个小型的OS或者APP，其好处是可以直接通过docker启动执行，而不需要配置乱七八糟的依赖环境。而容器(container)则是启动后的镜像，同一个镜像可以被多次启动。\n启动一个容器以后我们可以使用交互模式启动也可以直接启动某个程序，或者在构建镜像的时候就指定默认启动程序。\n"},{"id":123,"href":"/posts/git/git-checkout/","title":"Git Checkout","section":"Git","content":" checkout 主要用于 分支的切换 # 以当前(HEAD)分支为基础新建分支\ngit checkout -b \u0026lt;NEW_BRANCH\u0026gt; 以某一分支为基础新建\ngit checkout -b 新分支 基础分支 放弃修改 # 放弃未commit的修改\ngit checkout -- filename 放弃所有未add到暂存区的修改\ngit checkout . "},{"id":124,"href":"/posts/git/git-log/","title":"Git Log","section":"Git","content":"git log 是查看 当前分支 的commit记录的工具。\n以树状图的形式查看log记录。可以清晰的看出commit之间的关系。\ngit log --graph 查看某个文件的历史修改记录\ngit log -p [FILE_PATH] 如果不带[FILE_PATH]， 则显示commit的整体修改记录。\n查看commit的简要修改记录\ngit log --name-status "},{"id":125,"href":"/posts/git/readme/","title":"Readme","section":"Git","content":" Git 的使用主要包含几个方面： # Git 版本控制 Git 协同开发 TODO # rebase合并commit: https://kinboyw.github.io/2019/04/09/Git-%E5%8E%8B%E7%BC%A9%E5%A4%9A%E4%B8%AAcommit%E4%B8%BA%E5%8D%95%E4%B8%AAcommit/ "},{"id":126,"href":"/posts/git/rebase/","title":"Rebase","section":"Git","content":" 参考文献： https://zhuanlan.zhihu.com/p/34197548\nrebase 常用于在分支之间进行合并，但是这个合并比merge要灵活很多。\n经常我们会创建新的分支feature来开发新的功能，有的时候我们的新功能要依赖于master上的新特性，或者为了master方便合并分支。我们需要拉去master上最新的代码。我们可以使用\ngit checkout feature git rebase master 以上的代码，会找到feature与master分支的最近公共祖先LCA结点。然后以master的最新分支为基础重新提交feature上所有LCA之后的修改。得到一个新的提交。宏观上来看，相当于换基。\ngit pull origin master --rebase 也可以使用这种方式来更新本地分支到最新。\n另一种用法 - 压缩本地commit # 在一个分支上开发的时候，经常会有多次commit，主要是为了方便进行回滚操作，但是对于提交来说，子分支带着过多的提交记录并不是一件好事情。因此我们可以将我们的一段线性提交压缩成一个提交。\ngit rebase -i [start_commit_id] [end_commit_id] 上述代码将会打开一个交互模式的编辑器，罗列start至end之间的所有commit，你可以手动配置每个commit的处理方式。具体的有：\np, pick \u0026lt;提交\u0026gt; = 使用提交 r, reword \u0026lt;提交\u0026gt; = 使用提交，但修改提交说明 e, edit \u0026lt;提交\u0026gt; = 使用提交，进入 shell 以便进行提交修补 s, squash \u0026lt;提交\u0026gt; = 使用提交，但融合到前一个提交 f, fixup \u0026lt;提交\u0026gt; = 类似于 \u0026ldquo;squash\u0026rdquo;，但丢弃提交说明日志 x, exec \u0026lt;命令\u0026gt; = 使用 shell 运行命令（此行剩余部分） b, break = 在此处停止（使用 \u0026lsquo;git rebase \u0026ndash;continue\u0026rsquo; 继续变基） d, drop \u0026lt;提交\u0026gt; = 删除提交 我们可以按照需求定制每个commit的去留。\n其中需要注意的是，start是不包含在内的，end是包含在内的。不写end默认就是当前head所指向的commit。所有的提交是按照实现从早到晚排序，所谓融合到前一个提交就是融合到时间较早的提交。\n"},{"id":127,"href":"/posts/git/reset/","title":"Reset","section":"Git","content":"reset 用于在仓库的历史版本中穿梭。但是要明确的一点，reset与工作区和暂存区没有半毛钱关系。仅仅是更改了仓库中的记录点。\nreset 有三种不同的模式：mixed（默认）、soft、hard\n场景1 - 希望删除最近几次的commit记录 # 注意这个场景仅仅是我们对于最近几次的commit记录的删除，而这几次commit所修改的内容是不会撤销的，依然体现在文件中。只是仓库的记录里没有这些改动。这些改动将会随着你的下一次commit重新提交到仓库。\ngit reset commit_id # 撤销最近一次的commit，修改记录回到工作区 git reset HEAD^ 场景2 - 希望所有的一切回退到某个历史时刻 # 这就需要使用hard模式，可以将历史的commit记录连同文件的修改都扔掉，包括你的工作区、暂存区。一切都回到某个commit的时刻。 慎用\ngit reset --hard commit_id 场景3 - 希望撤销某个文件的commit # 某个文件被误修改了一个空格，并且被带入了commit，因此要单独撤销某个文件的commit，回到之前的状态。\ngit reset e32535157ac44 src/server/Processor.hpp 总结 # 通过上面的使用，我们可以发现，mixed就是将所有的变动都放入工作区，hard是将所有的变动删除，soft则是将commit的变动放入暂存区，工作区不动。\nGit clean # 清除未被跟踪的文件。\ngit clean -n // 只查看将被删除的稳健列表，不真正删除。 "},{"id":128,"href":"/posts/git/summary/","title":"Summary","section":"Git","content":" Git 基本逻辑 # 几个核心的概念要把握住：工作区、暂存区、仓库\n"},{"id":129,"href":"/posts/idea/readme/","title":"Readme","section":"ID Ea","content":" IDEA 配置远程同步 # 经常使用mac系统进行开发，但是需要项目在Linux系统上进行编译、运行。可以使用JetBrains家的Remote Deployment的功能。\n1. 设置远程服务器 # Settings -\u0026gt; Build,Execution,Deployment -\u0026gt; Deployment -\u0026gt; +(添加)\n设置SFTP, 使用ssh configuration的更多设置，设置好登陆的ssh-key登陆密钥。\n最后一步最重要，选中这个remote deployment，右键，Use As Default\n2. 设置自动上传 # 同样在Depolyment下面，找到Upload changed files automatically to the default server 选择Always。\n3. 第一次需要手动触发 # 选择项目结构的根目录，然后右键在最下方找到Deployment，选择刚刚设置的Remote Server即可第一次触发自动上传。\n4. 日常使用 # 自动上传可以将本地的变化同步到远程server，实时性非常高。 编译的操作直接登陆远程服务器进行编译，一般写成GNU风格的脚本一键编译、测试等。编译产生的文件不会反向回传到本地。 "},{"id":130,"href":"/posts/java/java-test-powermockito/","title":"Java Test Power Mockito","section":"Java","content":" 基础测试 # PowerMockito 测试：https://www.cnblogs.com/hunterCecil/p/5721468.html\n可以对每个对象以及对象的函数进行虚拟化，拦截填充数据。\n"},{"id":131,"href":"/posts/java/jdk/","title":"Jdk","section":"Java","content":" mac 上安装多个jdk和切换 # 参考：https://www.cjavapy.com/article/91/\n"},{"id":132,"href":"/posts/java/maven/","title":"Maven","section":"Java","content":" maven 生命周期 # clean： 清空build的产生的内容和缓存 compile： java编译成class test： 执行test package： 按照pom的约定打包成对应的jar/war等包 install： 将包安装到maven的仓库，一般是本地的中心仓库中。 deploy： 发布包 命令行打包：\nmvn clean -U compile package 执行特定的测试(指定的TestClass中的TestFunc)：\nmvn -Dtest=xxxTestClass#xxTestFunc test Maven带依赖jar打包 # 默认的jar包打包方式不会将dependency中的jar包打进最终的包里。war包会默认打进去。\n如果我们希望实现这样的需求，我们需要使用assembly插件。\n\u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-assembly-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;archive\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;mainClass\u0026gt;org.example.App\u0026lt;/mainClass\u0026gt; \u0026lt;!-- 指定启动类 --\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/archive\u0026gt; \u0026lt;descriptorRefs\u0026gt; \u0026lt;descriptorRef\u0026gt;jar-with-dependencies\u0026lt;/descriptorRef\u0026gt; \u0026lt;/descriptorRefs\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt;\u0026lt;!-- 配置执行器 --\u0026gt; \u0026lt;id\u0026gt;make-assembly\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt;\u0026lt;!-- 绑定到package生命周期阶段上 --\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;single\u0026lt;/goal\u0026gt;\u0026lt;!-- 只运行一次 --\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 上面配置执行器的部分一直没有成功，需要手动打包才行。使用assembly:single 来代替package\nmvn clean compile assembly:single "},{"id":133,"href":"/posts/java/netty-io/","title":"Netty Io","section":"Java","content":"Netty是 一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。\n前置历史 # 网络的处理分为两类，一类是Blocking IO(BIO, 阻塞式IO)和NO-blocking IO(NIO，非阻塞式IO)。 当然是NIO的CPU利用率要高一些。\n关于JAVA 原生NIO的介绍，可以看这一篇文章： https://mp.weixin.qq.com/s/GfV9w2B0mbT7PmeBS45xLw?spm=a2c6h.12873639.0.0.53064a61jNPjIo\n非阻塞式IO一般只用于网络IO，其核心的概念有三个：Buffer、channel、selector。\nBuffer: 用于缓存网络IO的数据。 Channel: 是与Buffer一起使用的数据传输通道，本身不存储数据。 selector: 选择器可以说是NIO的核心组件，它可以监听通道的状态，来实现异步非阻塞的IO。 但是原生的NIO元素过多，并不方便编写代码，Netty是以NIO为基础的优秀实践。\nNetty 使用入门 # 可以参考这篇文章的介绍： https://developer.aliyun.com/article/769587\nNetty 在服务端存在两个线程组：BossGroup、WorkerGroup， 前者负责处理链接，后者负责处理业务。有两个大的工厂类：Bootstrap与ServerBootStrap，分别是客户端和服务端的工厂类。\n服务端的代码如下： # public class MyServer { public static void main(String[] args) throws Exception { //创建两个线程组 boosGroup、workerGroup EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { //创建服务端的启动对象，设置参数 ServerBootstrap bootstrap = new ServerBootstrap(); //设置两个线程组boosGroup和workerGroup bootstrap.group(bossGroup, workerGroup) //设置服务端通道实现类型 .channel(NioServerSocketChannel.class) //设置线程队列得到连接个数 .option(ChannelOption.SO_BACKLOG, 128) //设置保持活动连接状态 .childOption(ChannelOption.SO_KEEPALIVE, true) //使用匿名内部类的形式初始化通道对象 .childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel socketChannel) throws Exception { //给pipeline管道设置处理器 socketChannel.pipeline().addLast(new MyServerHandler()); } });//给workerGroup的EventLoop对应的管道设置处理器 System.out.println(\u0026#34;java技术爱好者的服务端已经准备就绪...\u0026#34;); //绑定端口号，启动服务端 ChannelFuture channelFuture = bootstrap.bind(6666).sync(); //对关闭通道进行监听 channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } } // 对应的MyServerHandler /** * 自定义的Handler需要继承Netty规定好的HandlerAdapter * 才能被Netty框架所关联，有点类似SpringMVC的适配器模式 **/ public class MyServerHandler extends ChannelInboundHandlerAdapter { @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //获取客户端发送过来的消息 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\u0026#34;收到客户端\u0026#34; + ctx.channel().remoteAddress() + \u0026#34;发送的消息：\u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { //发送消息给客户端 ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;服务端已收到消息，并给你发送一个问号?\u0026#34;, CharsetUtil.UTF_8)); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { //发生异常，关闭通道 ctx.close(); } } 以上是一个基础的代码，其中最不好理解的部分就是boostrap中配置的handler。\nNioEventLoopGroup is a multithreaded event loop that handles I/O operation. Boss 线程将会建立连接，并交给worker线程来匹配给对应的channel。 NioServerSocketChannel 是诸多种channel的一种实现，一种异步的server端的socket通道。还有很多其他的通道，这里不展开介绍。 ChannelInitializer 是channel的初始化类，一个匿名类，为channel配置了pipline的handler。 客户端代码 # public class MyClient { public static void main(String[] args) throws Exception { // 事件轮询线程 NioEventLoopGroup eventExecutors = new NioEventLoopGroup(); try { //创建bootstrap对象，配置参数 Bootstrap bootstrap = new Bootstrap(); //设置线程组 bootstrap.group(eventExecutors) //设置客户端的通道实现类型 .channel(NioSocketChannel.class) //使用匿名内部类初始化通道 .handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { @Override protected void initChannel(SocketChannel ch) throws Exception { //添加客户端通道的处理器 ch.pipeline().addLast(new MyClientHandler()); } }); System.out.println(\u0026#34;客户端准备就绪，随时可以起飞~\u0026#34;); //连接服务端 ChannelFuture channelFuture = bootstrap.connect(\u0026#34;127.0.0.1\u0026#34;, 6666).sync(); //对通道关闭进行监听 channelFuture.channel().closeFuture().sync(); } finally { //关闭线程组 eventExecutors.shutdownGracefully(); } } } public class MyClientHandler extends ChannelInboundHandlerAdapter { @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { //发送消息到服务端 ctx.writeAndFlush(Unpooled.copiedBuffer(\u0026#34;歪比巴卜~茉莉~Are you good~马来西亚~\u0026#34;, CharsetUtil.UTF_8)); } @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { //接收服务端发送过来的消息 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\u0026#34;收到服务端\u0026#34; + ctx.channel().remoteAddress() + \u0026#34;的消息：\u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } } 以上是简单的server和client的处理。关于Netty更底层的设计逻辑，下一个小结来讨论。\n底层逻辑与流程图 # // TODO\n"},{"id":134,"href":"/posts/java/spring-boot/","title":"Spring Boot","section":"Java","content":"百技的Hackathon第一次接触了Spring Boot这个框架，总的来说没有特别难的点，确实是工程拆分的好东西。\nSpring boot 与 Spring 简介 # Spring boot 是在spring基础上开发的一套框架，主要是简化了Spring框架复杂的xml配置，简化了依赖的管理，由于我也没有配置过spring框架的xml因此没有体会。\nSpring 框架实现了两个主要的设计模式：IOC和AOP， 这是我之前就了解过的，不过并没有对此有任何实践。只记得要对bean类做很多依赖注入的配置，非常繁琐。\nSpring boot 的基础使用 # 使用Spring boot可以将web应用直接打包成jar包，内部包含serverlet容器，直接使用:java -jar xxxxx.jar 的方式启动。\n使用maven添加依赖(pom.xml)： \u0026lt;project\u0026gt; ... \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.4.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; ... \u0026lt;/project\u0026gt; 重点就是引入了一个parent和两个starter。\n创建应用的启动类： package com.xxxxx.xx; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class HelloWorldApplication { public static void main(String[] args) { SpringApplication.run(helloWorldApplication.class, args); } } 打包的pom.xml中要配置主启动类。 \u0026lt;project\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;!-- 指定该Main Class为全局的唯一入口 --\u0026gt; \u0026lt;mainClass\u0026gt;com.xxx.xxx.HelloWorldWebApplication\u0026lt;/mainClass\u0026gt; \u0026lt;layout\u0026gt;ZIP\u0026lt;/layout\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;repackage\u0026lt;/goal\u0026gt;\u0026lt;!--可以把依赖的包都打包到生成的Jar包中--\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; "},{"id":135,"href":"/posts/java/util-concurrent/","title":"Util Concurrent","section":"Java","content":" java.util.concurrent 概览 # java.util.concurrent 是一个用于编写并行程序的java包， 包括异步Task框架。\n参考文献 # [1]. https://www.baeldung.com/java-util-concurrent "},{"id":136,"href":"/posts/rocksdb/summary/","title":"Summary","section":"Rocks Db","content":" rocksDB 的逻辑框架 # 作为一个单机版的基于LSM-Tree模式的K-V数据库，具有较好的写入性能。其核心结构包含三个部分：memTable(缓存表), SSTable(持久化表), WAL(命令日志, write ahead log)。\n其核心的部分就是写入链路。\nwrite 写入链路 # "},{"id":137,"href":"/posts/self/%E4%B8%A4%E7%B1%BB%E4%BA%BA/","title":"两类人","section":"Self","content":" 有一些道理只流传了一半，举个例子：百善孝为先，论心不论迹，论迹天下无孝子；万恶淫为首，论迹不论心，论人世间无完人。大多数只听到的前一半，所以全都以孝行约束自己的行为。儿子尽孝放弃了自己人生的发展，父母拿着这句话心安理得。一个引申的当下的例子，都说孩子以后只要开心就好。但是如果只拿着这句话，势必会分成三类人：1. 不认同；2. 拿这个空洞的道理安慰自己，并且放弃对孩子的教诲。3. 听从了这个道理，放任自流。但是这个道理应该是孩子以后只要做他自己喜欢的事情就可以，这样就会开心，但是要认真对待自己喜欢的事情，并尽力做出优秀的成果。 "},{"id":138,"href":"/posts/self/%E7%A4%BE%E4%BC%9A%E5%88%86%E5%B7%A5/","title":"社会分工","section":"Self","content":"工业社会的典型特征就是精细化分工 + 全球协作。其期望达成一个高效的。（还是语音录制比较快）\n"},{"id":139,"href":"/posts/vim/install/","title":"Install","section":"Vim","content":" MacOS Monterey 上编译安装vim # 由于部分插件是依赖于py3的，所以需要自己手动编译打开py3的支持。\nmac 自带的/usr/bin/python3是阉割版本的，没有python3的开发包。因此我们是一定要自己安装一个python3的。一般使用brew安装即可。\n安装完python后，\n./configure --with-features=huge\\ --enable-multibyte \\ --enable-rubyinterp=dynamic \\ --with-ruby-command=/usr/bin/ruby \\ --enable-pythoninterp=dynamic \\ --with-python-config-dir=/usr/lib/python2.7/config \\ --enable-python3interp=3.7 \\ --with-python3-config-dir=$(python3.7-config --configdir) \\ --enable-cscope \\ --enable-gui=auto \\ --enable-gtk2-check \\ --enable-fontset \\ --enable-largefile \\ --disable-netbeans \\ --with-compiledby=\u0026#34;paladnix@outlook.com\u0026#34; \\ --enable-fail-if-missing \\ --prefix=/usr/local "},{"id":140,"href":"/posts/vim/readme/","title":"Readme","section":"Vim","content":" 常用的快捷键与配置 # 映射插入模式下的ESC，避免左手跑很远去按ESC。坏处就是连续输入ff的时候会卡顿。需要等待。\ninoremap ff \u0026lt;ESC\u0026gt; 配置YCM与Sulti # "},{"id":141,"href":"/shark/2.28/","title":"2.28","section":"Shark","content":" TODO # 为账户添加权限，细粒度到具体的操作类型。 机器人监听群消息，自动提取TODO消息。接入Task自动提醒。 设置一个enginer页面负责具体文档。 快速进入管理页面的通道。 填表位置使用快速补全的方式优化使用。 logo 引入svg的问题，周末处理，需要自己ps来处理一下。 article 页面的重构工作。 根据用户是否报名过某个课程，是否通过某个lesson来给course卡片定标签。 markdown 渲染文本样式： https://westar.io/blog/rust_web_framework_compare/ eslint + prettier 自动格式处理: https://segmentfault.com/a/1190000020379876 "},{"id":142,"href":"/shark/algorithm-a/","title":"Algorithm A","section":"Shark","content":"写在前面：\n此表是知识点分割表，其中一些是在讲题目的时候讲过，但是这些视频没有被挑出来，没有明确他们的核心作用。\n无论是用已有的，还是新录制，需要将这些视频与单独的题解视频区分开。这些视频需要强对应知识点。\nLesson - 1 枚举基础 # 算法复杂度：$O(n)$, $O(n^2), $$O(\\sqrt n)$, $O(log_2 n)$等。 (应当放在语言班)一些名词解释：序列、子序列、子段、子串、排列、矩阵、子矩阵、公共序列、上升、非升、区间。 Lesson - 2 枚举优化 # 本节只能就题论题。题解\nlesson - 前缀和 # 容斥思想 前缀和的写法与注意事项。 题解 lesson - 二分法 # 二分法模版，算法复杂度计算 二分查找库函数(lower_bound)：数组版，vector版。 二分答案的适用范围、模版写法、复杂度分析。选一个典型题讲解。 lesson - 动态规划 # 以题为中心，解释单向依赖、重叠子问题，最优子结构，无后效性。 以题为中心，解释动态规划的状态，状态转移，初始化。 lesson - 树结构 # 邻接矩阵和邻接表 有根树与无根树：DFS遍历 二叉树的前中后序 lesson - 图 # 有向图与无向图：存储 BFS 遍历图 拓扑序、拓扑序模版 优先队列 # STL中优先队列的使用、注意事项 堆结构的原理 "},{"id":143,"href":"/shark/atcoder/","title":"Atcoder","section":"Shark","content":"abc231_d 图论判断是否成链\n"},{"id":144,"href":"/shark/mui-v4-to-v5/","title":"Mui V4 to V5","section":"Shark","content":" 关于MUIv4与v5的差异 # v4 与v5在组件上的差异不大，但是组包方式有重大的更改。同时组件的样式注入改为了emotion库。\n目前MUI-v5的包有如下几个：(https://mui.com/zh/guides/understand-mui-packages/)\n@mui/material， 核心组件库 @mui/system， @mui/base， 是一个unstyled components， 你可以认为material部分的组件是用styled-engine修饰过的base组件。 @mui/styled-engine， 样式设计引擎emotion的封装 @mui/styled-engine-sc， 样式设计引擎，styled-components的封装，与上一条可以按需使用。 @mui/styles, 即将被删除 emotion是system部分默认使用的样式引擎，即官方推荐使用的是@mui/styled-engine。后面介绍emotion的特性。\n传统的JSS-in-CSS，\n对于用户来说，我们直接接触的部分其实就是@mui/material， 一切都从这个包里获取。\nMUI-v5响应式改造 # 响应式改造主要是按照宽度自动调节：字体大小、间距、宽度、排版方向、可见性等。以此实现在不同大小的设备上都有良好的展示效果。\n前端代码规范 # emotion # "},{"id":145,"href":"/shark/testing-stl/","title":"Testing Stl","section":"Shark","content":"以下关于vector的说法正确的是：\nvector是容器，一个vector内部可以存储不同类型的数据 vector的长度可以动态变化，并非在声明时固定长度。 "},{"id":146,"href":"/shark/testing2-4/","title":"Testing2 4","section":"Shark","content":"测试的核心思路是测试孩子是否具有阅读理解的能力，是否具有理解概念的能力。介绍一些概念，并对概念描述的问题进行判断，是否理解了概念，区别概念中描述的细节差异。这是学习能力的至关重要的基础能力。\n有一类特殊的数字叫做“回文数字”， “回文数字” 是从左向右读和从右向左读一摸一样的数字，例如：11、121、7887 都是“回文数字”; 而 12、988、771都不是\u0026quot;回文数字\u0026quot;。\n下面不是回文数字的是：\n1001 228 11111 1212 学校的食堂里有2种不同的主食：馒头、米饭；有3种不同的蔬菜：土豆、茄子、青菜，小Y同学每一顿饭要选一种主食和一种蔬菜，请问他有多少种不同的搭配方法。例如：米饭+青菜、米饭+土豆是两种不同的搭配方法。\n定义一种新的运算符: $\\odot$, 运算规则如下：$a \\odot b = aab$, 例如：$32 \\odot 4 = 32324$， 即将a部分复制2遍和b拼接在一起。请你写下$(33 \\odot 54$ 的结果。\n4年级\n定义一种新的运算符: $\\odot$, 运算规则如下：$a \\odot b = aab$, 例如：$32 \\odot 4 = 32324$， 即将a部分复制2遍和b拼接在一起。请你写下$(2 \\odot 1) \\odot 5$ 的结果。\n找规律\n请你找出下面的规律，并写出接下来的数字：$1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, ___$\n中位数是指在一些数字中大小处于中间位置的数字。例如：$3，5, 3, 9, 23$ 的中位数是 $5$。请你写出下列数字中的中位数：$10, 2, 13, 12, 2, 5, 1, 99, 75$。\n桌子上有一排卡片，如图所示。他们按照顺序排列在一起，我们用 -\u0026gt;nxt 表示一个卡片的下一个卡片。例如：5-\u0026gt;nxt 则表示6号卡片。有如下的指令：\nA 指向 6号卡片。 A 指向 A-\u0026gt;nxt B 指向 A-\u0026gt;nxt 当我们按照顺序执行上面的三个指令，此时B指向几号卡片（只需要填写数字）。\n逻辑题\n甲、乙、丙三个人各自在自己卡片上写了一个数字，他们只能看自己手里的卡片，不能看其他两个人的卡片。已知三个数字之和是14，现在他们先后说了下面几句话，请你猜出丙手里的数字是多少。\n甲说：乙和丙卡片上的数字一定不相同 乙对甲说：我和你的数字也一定不相同 丙说：那我知道你们两个的数字分别是多少了。 请问丙手中的数字是多少？\n"},{"id":147,"href":"/shark/week_11.8-12/","title":"Week 11.8 12","section":"Shark","content":" 11 月第二周Daily Mark # 开发红线（高危，需注明，等回复）：\n后台改动API层的参数、方法、路径、返回数据类型等。 后台改动基础架构代码：redisTableBase 前段改动基础组件代码：libs/ 开发报备：\n改动已有的文件 开发日报包括 # git log \u0026ndash;state， 中所有修改的文件列表。 结果截图 测试记录 简要说明代码结构和设计逻辑，重用了哪些代码模块，新建了哪些代码模块。 工作会议 # 文档工作大于代码工作。以最小单元行进。\n笔试题目 # 以下代码的复杂度是：\nfor(int i = 0; i \u0026lt; n; i++) { for(int j = 0; j \u0026lt; n; j++) { continue; } } for(int i = 0; i \u0026lt; n; i++) { for(int j = 0; j \u0026lt; n; j++){ break; } } "},{"id":148,"href":"/shark/work-record/2022-q4/","title":"2022 Q4","section":"Shark","content":" 第四季度 # 以应用易用性为基础做工作，简化工作操作流程。\n优化微信群通知类消息的展示形式，转化为图片形式：代码、题解等。 权限角色系统接入细化到操作级别。 答题的步进式提示。 教师统计类信息快速获取。 用户行为判断、监控、提醒。 同学博客建设。 页面聊天室打通微信，接入自动答疑机器人自动处理。 数据文件提取ID仅提取前缀/后缀，如果没有就默认是大数据。 技术演进 # 网站做区域隔离，对外供给学校、机构等。 "},{"id":149,"href":"/posts/docker/k8s/","title":"k8s 入门","section":"Docker","content":"Docker 作为一种资源虚拟化的技术，并不具备资源调度的能力。因此如何管理调度大量的容器，则需要容器编排技术。K8s就是容器编排引擎。\nKubernetes作为一种资源编排引擎，除了预定义的pod资源外，也可以自定义资源，k8s则对这些资源进行调度。包括创建、销毁、变更等。\n# "},{"id":150,"href":"/_drafts/latex/","title":"Tutorial of Latex - The difference with .cls and .sty","section":"_drafts","content":"总的来说，.cls 和.sty 文件都是用来增强latex功能的。\n二者的最主要的区别就是：\n.cls 文件使用\\documentclass{} 的方式引入 .sty 文件使用\\usepackage{} 的方式引入 .cls文件用于确定的描述一个文档的结构，一个文档只能引入一个。.sty 文件是可选的，功能隔离的包，当我们需要某些功能的时候我们就引入。 二者都包含任意的tex或是latex代码，都是文档的功能的补充。\n"}]